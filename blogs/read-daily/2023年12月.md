# 20231231 《Elon Musk》22 Kwaj SpaceX, 2005–2006
- Catch-22（第22条军规）
   - Musk试图建立一种文化，质疑规则，并假设要求都是愚蠢的，直到证明其合理
   - 卫星太重，必须在赤道附近发射，因为赤道地区地球表面的自转速度更快，可以提供必需的额外推力。
   - Musk邀请Mango去一家高级餐厅用餐，Mango咨询了政府道德官员，被告知他必须自己付账，所以他们去了Applebee's餐厅
- 天堂的另一面
   - Musk事后承认搬到Kwaj是个错误，并解释了他本可以等待Vandenberg可用，但因为缺乏耐心而选择了Kwaj
   - “在Kwaj度过的那四年锻造了我们，让我们紧密团结，教会我们如何团队合作。”
   - 甚至在清晨穿T恤也可能晒伤
# 20231230 Hugging Face Course USING 🤗 TRANSFORMERS 下

- A high-dimensional vector（高维矢量）的三个维度：
   - 批次大小
   - 序列长度
   - 隐藏大小：这个就是所谓的高纬度，768算少的，一般是3072甚至更多
- Transformer模型的注意力层在处理每个token时会考虑其上下文
# 20231230 《Elon Musk》The Roadster Tesla, 2004–2006

- Cobbling together pieces
   - Musk的决策，即Tesla应该自主制造关键零部件，而不依赖独立供应商
   - 但是一开始并非这样，第一辆车Roadster时，公司选择了外包制造过程，并采用了来自外部供应商制造的零部件。这一决策后来成为公司的一大问题
   - Lotus公司同意提供稍微改型版本的Elise跑车车身，而Tesla则负责装备电动发动机和动力系统，这成为了Tesla Roadster的制造基础。
   - Musk的试驾，他感受到了车辆的超快但无声的加速，之后同意再次投资900万美元到公司
- Whose company?
   - 在一些情况下，强势的领导者可能会压制其他创始人或合作伙伴，例如Steve Jobs 和Steve Wozniak、Bill Gates 和Paul Allen之间的情况
   - Musk 和 Eberhard 很像，他们都是刻苦、高度紧张、注重细节的工程师，对那些他们认为是傻瓜的人可以极其冷酷地对待
   - Musk向斯Straubel寻求建议，最终解雇了Wright，并且由此引发了他对Eberhard的怀疑，同时也让他更加积极地参与了Tesla的管理
- Design decisions
   - Eberhard试图抵制Musk的建议，因为他担心这些建议会增加成本和导致延迟。然而，Musk坚信推出一款让客户印象深刻的跑车是唤醒特斯拉的关键
   - 尽管Musk的专业是计算机软件，而不是工业设计，但他开始花费大量时间研究Roadster的美学
   - Musk的设计修改通常正确但昂贵的
   - “如果你买一辆跑车，那是因为它很漂亮，”Musk告诉团队。“所以这不是小事。”
   - Musk能够将在SpaceX学到的技术应用到特斯拉上，反之亦然
   - 购买特斯拉Roadster的人无论车门把手是普通的还是电动的，都会购买，”Eberhard争辩道。这是他对Musk大多数设计更改提出的论点
   - Musk和Eberhard在仪表盘设计问题上的冲突，Eberhard对于改进仪表盘的困难和成本提出担忧，最终，Musk让步，决定将改进仪表盘的工作推迟到第一批车辆投入生产后
   - 通过修改如此多的元素，Tesla失去了仅使用经过碰撞测试的Lotus Elise车身所带来的成本优势,这也增加了供应链的复杂性
- Raising more capital
   - VantagePoint Capital成为了一轮融资中的主要投资者，金额为4000万美元，融资在2006年5月结束
   - Alan Salzman表示对Eberhard和Musk的双重管理结构感到担忧，但后来认识到这是项目的一部分
- Getting credit
   - 做为迷因（memes）的大师，Musk对如何通过引发争议和在社交媒体上搏斗来获得免费宣传有着聪明的直觉
   - "memes" 不是指特定的人物，而是指一种广泛流行的文化元素，通常是指在互联网上传播的图像、视频、文字或概念，它们经常被创造和分享，以传达幽默、社会观点或文化内涵。
   - Musk对于被认可和获得赞誉的敏感性。他非常敏感于有人错误地认为他成功是因为继承的财富，或者声称他不应该被称为公司的创始人。这种情况发生在PayPal和特斯拉，并且最终导致了法律诉讼
- The unveiling
   - Eberhard强调了快速和电动的结合是推动电动车流行的关键。Musk在演讲中表现出一些尴尬，但他的真诚和不做作的特点吸引了记者们。他宣布过去的电动车都不好，并表示购买Roadster将有助于为特斯拉提供资金，以制造更加经济实惠的汽车
   - 纽约时报发表了一篇赞美Tesla的文章，题为 'Zero to 60 in 4 Seconds'，甚至没有提到Musk
   - Tesla的使命促进从化石燃料经济向太阳能电力经济的转变。使这一目标成为现实的关键是一款没有妥协的电动汽车
   - Tesla的战略是从高端市场入手，然后降低价格，以实现更高的销售量和更低的价格，从而推动电动汽车的普及
   - Robert Downey Jr. 要求在电影中的斯塔克工作室场景中放置一辆Tesla跑车。Musk随后在《钢铁侠2》中以自己的身份短暂出现
arzenegger for a test drive in a Roadster
# 20231229 《Elon Musk》20 Founders Tesla, 2003–2004

- JB Straubel
   - 杰里·布莱恩·斯特劳贝尔，以JB为人所知，JB在高中时进行的一次实验，意外发生爆炸，导致他脸上留下了伤疤
   - JB将一辆旧保时捷改装成了一辆全电动汽车，使用传统的铅酸电池作为能源，有惊人的加速性能，但续航里程只能达到三十英里
   - Musk认为，建立汽车公司的方式是首先制造高价汽车，然后逐渐发展成大众市场模型
- Martin Eberhard
   - 2001年，当身材高瘦、面容清瘦、性格高能的硅谷企业家Martin Eberhard正在克服一次糟糕的离婚时，他决定，正如他所形容的那样，“像每个陷入中年危机的男人一样，买一辆跑车给自己。”
   - Martin Eberhard告诉Gage，如果他们换成锂离子电池，他将投资15万美元到公司
   - Martin Eberhard认为这辆汽车将使用所谓的感应电动机，所以他想到了以这个设备的发明者Nikola Tesla的名字来命名它的主意
- Chairman Musk
   - 这次会议在Musk在SpaceX的小隔间内进行，原计划持续半小时，但Musk不停地向他们提问，偶尔还大声叫助手取消他的下一个会议。两个小时里，他们分享了他们对一款超级电动汽车的愿景，讨论了从传动系统和电机到商业计划的一切细节
   - Musk领导Tesla首轮融资，投资640万美元，并担任董事会主席
   - Tarpenning感到震撼的是，Musk将重点放在任务的重要性上，而不是企业的潜力上。Musk已经得出结论，电动化汽车是实现可持续未来的关键
   - Eberhard担任CEO，Tarpenning担任总裁，Straubel担任首席技术官，Wright担任首席运营官，而Musk则担任董事会主席和主要资助人。经过多年的发展，尽管有很多争议和诉讼，他们最终同意将所有五人称为共同创始人
# 20231228 《Elon Musk》19 Mr. Musk Goes to Washington SpaceX, 2002–2003

- Gwynne Shotwell
   - Musk不喜欢分享权力
   - Shotwell因挑战者号的爆炸而情绪受到极大影响，以至于未能成功获得工作，并且她怀疑自己在面试中表现不佳
   - Shotwell经过三个星期的思考后认为，SpaceX具有将火箭行业变革为创新型产业的潜力
   - Shotwell的丈夫患有亚斯伯格症，这一情况帮助她更好地理解和处理Musk的行为
   - 亚斯伯格症可能导致一个人表现出缺乏同理心的特征
   - Shotwell不试图改变马斯克的本性，而是尽力帮助那些因为他的言行而受伤的人
- 吸引NASA
   - Musk在2004年5月与NASA总部的官员会面，并无视了Shotwell的建议，决定对Kistler合同提起诉讼
   - 对Nasa诉讼案的胜利是一个巨大的意外，想象一下，就像是十对一的赔率下的弱势赢家。它让每个人都感到震惊
- 固定价格合约
   - 这场胜利不仅对SpaceX而言至关重要，也对美国的太空计划具有重要意义
   - Musk认为成本加成制度的问题在于它抑制了创新，使用成本加成制度无法实现重大目标，如到达火星，因为这种制度没有完成项目的动力
   - 公司冒着自己的资本风险，只有在达到特定里程碑时才会得到支付,种以结果为基础的、固定价格的合同允许私营公司在广泛的参数内控制其火箭的设计和建造方式,如果它建造了一种成本高效的成功火箭，可以赚取大量利润，但如果失败，也会损失大量资金
# 20231227 Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT
![image.png](https://cdn.nlark.com/yuque/0/2023/png/250863/1703651520747-acbfd6bc-4d24-4d23-9ea9-641c06b79c4a.png#averageHue=%23f4f3ef&clientId=u02490789-5a7a-4&from=paste&height=554&id=ud55f507e&originHeight=1108&originWidth=1736&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1053709&status=done&style=none&taskId=u8d86cfc6-3c93-407f-8793-9966d915997&title=&width=868)

- ChatGPT 的成功可能揭示了关于人类思维本质的基本信息
-  ChatGPT 可以与 Wolfram|Alpha 进行交流，将自然语言转化为精确的符号计算语言，从而应用 Wolfram|Alpha 的计算知识能力

# 20231226 So … What Is ChatGPT Doing, and Why Does It Work?

- 人类语言（以及背后的思维模式）在结构上某种程度上比我们想象的更简单和更像“法则”
- ChatGPT与典型算法计算不同之处，即它在内部不包含循环或数据的重新计算。
- 为了应对这些intractable computation（不可化简的计算），大脑和像ChatGPT这样的系统都需要寻找外部工具
# 20231225 Andrej Karpathy: Intro to Large Language Models 3
[https://www.youtube.com/watch?v=zjkBMFhNj_g&list=PLCLQYuIgThNg4jFQmdlhJSyXVkEEXIouO&index=7&t=1204s](https://www.youtube.com/watch?v=zjkBMFhNj_g&list=PLCLQYuIgThNg4jFQmdlhJSyXVkEEXIouO&index=7&t=1204s)

- 可选的第三阶段就是RHF（reinforcement learning from Human feedback）
- 大语言模型的缩放规律: 指的是一种观察结果，即随着模型尺寸的增加，其性能（例如，在下一个单词预测任务中的准确性）呈现出相对平稳和良好的趋势
- 模型质量跟两个变量有关： 参数量 和 训练文本量
- 关于系统一和系统二思维类型的概念，这个概念源自书籍《思考，快与慢》
- 前大型语言模型只有系统一，它们只有这个本能的部分；语言模型不能进行复杂的思考和推理，类似于分析可能性树的过程
- 开放式语言建模领域，如何找到超越人类的等价物主要挑战在于缺乏一般情况下的奖励标准
-  在狭窄领域中，自我改进语言模型是可能的
- llm操作系统和传统操作系统之间存在许多相似性：
   - 多线程、多处理和推测执行在llm操作系统和传统操作系统之间的等同性
   - 硬盘/互联网访问相似性
   - 上下文窗口类比RAM
   - 上下文窗口类似于llm操作系统的用户空间，而内核进程则扮演了内核空间的角色
- 互联网上存在大量的 Base64 编码文本，模型通过学习建立了与其他语言的等价关系
- 通用可转移后缀（Universal Transferable Suffix）是一种文本片段，通常是一组单词或字符，可以添加到任何查询或提示之后，以欺骗大型语言模型，使其产生不安全或危险的回应。这种后缀的特点是，它在各种查询和上下文中都能有效，因此称为通用。
- 三种攻击方式：
   - Shieldbreak Attack（突破防护攻击）
   - Prompt Injection Attack（提示注入攻击）
   - Data Poisoning or Backdoor Attack（数据污染或后门攻击）
# 20231221 How GPT3 Works - Easily Explained with Animations
[https://www.youtube.com/watch?v=MQnJZuBGmSQ&t=74s](https://www.youtube.com/watch?v=MQnJZuBGmSQ&t=74s)

- 模型中的参数被整理成各种矩阵，生成预测的过程，即通过将不同的矩阵与模型在每个标记处获取的输入相乘来实现
- 每个单词，每个标记都会经过一个轨道
- 在"深度学习"（Deep Learning）中，"深度"（Deep）多个隐藏层（中间层）这使其能够学习和表示更复杂的模式和特征。gpt3 有96层。
- 想要了解transform架构，可以看这个GTP2图解[https://jalammar.github.io/illustrated-gpt2/](https://jalammar.github.io/illustrated-gpt2/)
- GPT3 与的不同之处在于[交替全连接层](https://www.zhihu.com/search?q=%E4%BA%A4%E6%9B%BF%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3332714310%7D)和[稀疏自注意层](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1904.10509.pdf)。



# 20231220《Elon Musk》18 Musk’s Rules for Rocket-Building SpaceX, 2002–2003
![image.png](https://cdn.nlark.com/yuque/0/2023/png/250863/1703090996872-5b52a0b9-e242-4b7b-8ed8-2bdbdcad64eb.png#averageHue=%23658184&clientId=ud9c69982-5591-4&from=paste&height=512&id=u4cdefa58&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1971200&status=done&style=none&taskId=u49b154b2-85b9-41ed-abc2-922ca68d3ad&title=&width=512)

- Question every cost(质疑每一项成本)
   - 航空航天供应商为零部件收取的价格通常是汽车行业类似零部件的十倍以上
   - 天生的控制欲使Musk希望尽可能多地在内部制造零部件，而不是从供应商那里购买
   - 经过几年的努力，SpaceX已经能够自主制造火箭的70％零部件
   - Musk的理念，即所有的要求都应该被视为建议，只有那些由物理定律规定的要求是不可改变的
- 有一种疯狂的紧迫感
   - Mueller强调了面对Musk的要求时，学会不拒绝，而是表示愿意尝试.如果事情最终没有成功,并在后续解释原因
   - 紧迫感对于促使工程师进行首创性思维的积极作用
   - 但紧迫感也可能对工程团队产生腐蚀性的影响。Mueller指出，如果时间表过于不切实际，工程师会感到士气低落，这被视为马斯克的最大弱点
   - Musk和Jobs(现实扭曲力场)采取类似的策略，即设定不切实际的截止日期来激励团队
   - Mueller承认他们虽然未能达到所有目标，但仍然超越了同行，开发了成本最低、最令人印象深刻的火箭，对此感到自豪。
- 从失败中学习
   - 问题并不在于你如何避免问题，而在于你有多快地找出问题所在并加以修复
   - SpaceX是一家私营公司，并且Musk愿意打破规则，他们可以承担更多风险
   - 点燃火箭发动机并引发爆炸的活动，他们给这些爆炸起了一个幽默的名字："快速不计划的拆解"
- 随机应变
   - Mueller和他的团队会在McGregor测试引擎，每天工作12个小时，然后在Outback Steakhouse吃晚餐，接着进行深夜电话会议，与Musk讨论技术问题
   - Musk在工程师无法回答问题时表现出的愤怒情绪，类比为发动机燃烧的怒火
   - Musk对风险的宽容度，他鼓励团队寻找临时解决方案
   - A pattern was set: try new ideas and be willing to blow things up
# 20231219 大模型应用落地的一些思考和实践
[https://wulucxy.github.io/blog/llm-thinking-practice/](https://wulucxy.github.io/blog/llm-thinking-practice/)
![image.png](https://cdn.nlark.com/yuque/0/2023/png/250863/1702970877561-6db79765-d268-44b5-a632-9d427d883f1d.png#averageHue=%23f9f8f7&clientId=u7627194c-0926-4&from=paste&height=1135&id=u1e7b4eb9&originHeight=2270&originWidth=1903&originalType=binary&ratio=2&rotation=0&showTitle=false&size=2087584&status=done&style=none&taskId=uf0b60d5a-14d4-41dd-8b72-0ede8c8d7d4&title=&width=951.5)

- token 会对应一个唯一索引 id，id 越小就表示该字符越常用。
- 国外开源大模型训练数据集使用的中文来源较少，不太常用的字符会被拆分为 UTF-8 字节，在大模型文本识别时就容易出错
# 20231217 Your Tattoo is INSIDE Your Immune System. Literally
[https://www.youtube.com/watch?v=nGggU-Cxhv0](https://www.youtube.com/watch?v=nGggU-Cxhv0)

- 真正看到的是数以百万计的巨噬细胞，坐在你的真皮层，耐心地把墨水保持在适当的位置，保护你的身体免受毒害。你的免疫系统就是你永远纹身的原因
- 你现在知道了你内心的挣扎和你巨噬细胞伙伴的牺牲，只为了你能永远拥有这种艺术。
- 为了欣赏你惊人的免疫系统，你必须首先了解它——这同样适用于我们宇宙中发生的任何事情。

# 20231216 Hugging Face Course USING 🤗 TRANSFORMERS 上

- Transformers library  提供一个单一的 API，通过该 API 可以加载、训练和保存任何Transformer模型
- 模型不是建立在跨文件共享的模块上；相反，每个模型都有其自己的层。这个是跟其他ML libraries不一样的地方
- PyTorch和TensorFlow是目前最受欢迎的两个深度学习框架，而Flax则是一个新兴的框架
- 张量（Tensor）可以理解为一种可以在多个维度上扩展的数据结构，它是标量、向量和矩阵的泛化。张量的一个重要特点是它们可以在GPU（图形处理器）或其他专用硬件上高效运算，这对于加速深度学习模型的训练和推理是非常关键的。
- 在大型模型（如深度学习模型）中，"checkpoint"（检查点）通常指的是在训练过程中特定时刻的模型状态，包括模型参数、优化器状态以及其他相关信息的快照。
- 对数几率与损失函数的关系是基于提高训练效率的考虑。在训练过程中直接使用对数几率，并在计算损失时结合SoftMax和交叉熵损失，可以提高模型训练的速度和效率。而在模型用于预测时，则需要将对数几率转换为概率。
- 英语中有超过50万个单词
- Subword tokenization  ； Word-based  ； Character-based
- 代表性的黏着语包括土耳其语、芬兰语、韩语和日本语等。这些语言通过词缀的添加来形成复杂的词汇和语法结构，与像英语或汉语这样的孤立语（每个词汇主要以独立的单词形式存在，语法关系通过词序和辅助词来表达）有显著区别。
# 20231215《Elon Musk》17 Revving Up SpaceX, 2002

- Tom Mueller
   - Mueller外表看似粗犷如伐木工，但内心却像马斯克一样好学
   - Mueller的成绩并不出色，但他的热情具有感染力，这帮助他在TRW公司找到了一份工作
   - Mueller坚持的一件事是，Musk将预付两年的工资交由第三方托管
   - Musk认为不能要求把两年的薪水放在托管账户里，然后认为自己是共同创始人
- Ignition
   - 为什么Musk要求设计、工程和制造团队都应该聚集在一起: 如果你的手放在炉子上，感觉到热了，你会立刻把手拿开，但如果是别人的手放在炉子上，你做出反应就会慢一些。
   - Musk将他们正在建造的火箭命名为Falcon 1，名字源自《星球大战》中的宇宙飞船
   - 

# 20231214 Hugging Face Course Transformer models 2
[https://huggingface.co/learn/nlp-course/en/chapter1/5?fw=pt](https://huggingface.co/learn/nlp-course/en/chapter1/5?fw=pt)

- 编码器模型只使用变换器模型的编码器部分，其特点是在每个处理阶段，注意力层能够访问初始句子中的所有单词。
- 这种模型以其双向注意力机制而闻名，并且通常被称为自动编码模型。这反映了其在处理和理解文本时的广泛能力和灵活性。
- 编码器在提取携带序列有意义信息的向量方面非常强大，然后，这个向量可以通过额外的神经元层来处理，从而理解它们。
- 当你使用这些工具时，你需要在脑海中牢记，你所使用的Base Model很容易产生性别歧视、种族主义或同性恋恐惧的内容。fine-turn 并不会使这种内在的偏见消失。
# 20231213 Hugging Face Course Transformer models 1
[https://huggingface.co/learn/nlp-course/en/chapter1/1?fw=pt](https://huggingface.co/learn/nlp-course/en/chapter1/1?fw=pt)

- NLP: Natural Language Processing
-  NLP 并不局限于书面文本。它还处理语音识别和计算机视觉方面的复杂挑战，例如生成音频样本的文本或图像描述。
- Zero-shot classification : 这在现实世界的项目中是一个常见的场景，因为对文本进行注释通常很耗时，并且需要领域专家的帮助
- 三种类型的大模型：
   - GPT-like (_auto-regressive_ )：自回归派
   - BERT-like (_auto-encoding_)：编码器模型
   - BART/T5-like (_sequence-to-sequence_ )：
- Transformer都是Self-supervised learning的语言模型，意味着他们的训练不需要人类进行标注
- 原始的Transformer模型发展了对它所学语言的统计理解，但是对于特定的实际任务来说，它并不是非常有用，所以需要进行Transfer learning： 模型在监督下进行fine tuned ーー也就是说，使用人工标注的标签ーー对给定的任务进行微调。
- causal language modeling 因果语言模型： 产出取决于过去和现在的投入，而不是未来的投入。
- fine tuned 只需要更少的数据集 和 更少的时间 和 计算成本
- 你应该总是尝试利用一个预先训练好的模型ーー一个尽可能接近你手头任务的模型ーー并对它进行微调。
- 理解Transformer的关键是attention layers.（注意力层）
- Transformer架构最初是为翻译而设计的
- ImageNet 是一个广泛用于计算机视觉研究和深度学习的数据集。它是一个包含数百万张图像的庞大数据集，这些图像涵盖了来自各种不同类别的物体和场景
- 通常，迁移学习会保留模型的基础部分，然后替换头部，也就是最后几层，以适应特定任务，新的头部会随机初始化。
- 好事伴随着坏事，预训练模型不仅传递其知识，还可能传递其中包含的任何偏见
# 20231212 穷查理宝典 1.1 A Portrait of Charles T Munger By Michael Broggie

- "最接近重新过一遍生活的事情似乎是对生活的回忆，通过将这些回忆记录下来以尽量使其持久化。" - 本杰明·富兰克林
- 沃伦曾经称查理为'可恶的不同意者'
- 沃伦是国内最受尊敬和报道的商业领袖之一，但查理却有意避开了聚光灯，选择了相对的匿名
- 芒格比巴菲特大6岁
- 拼音法阅读（Phonetic Reading）是一种学习阅读的方法，它强调将文字的发音与字母或拼音符号相对应，以帮助学习者识别和发音单词
- 《金刚》，这是八岁的查理喜爱的电影之一
- 在大萧条时期，查理找到了一份无聊的工作，数着过路人，时薪四十美分。
- Roosevelt's bank holiday是指1933年3月6日，美国总统富兰克林·D·罗斯福（Franklin D. Roosevelt）签署的一项紧急政策，宣布全国性的银行休假。这个措施是为了应对当时的银行危机和大萧条的严重经济问题。
- 查理经常说，任何想要成功的人都应该学习物理学，因为它的概念和公式如此生动地展示了完善理论的力量
- 查理在学术上很成功，但由于他超常的智力和直率的性格，有时会引起一些不满。他的这种性格有时被误解为粗鲁，但实际上他只是比较匆忙，并不太关注课堂上的常规礼节
# 20231211 React Server Components vs SSR
[https://www.youtube.com/watch?v=jEJEFAc8tSI](https://www.youtube.com/watch?v=jEJEFAc8tSI)

- SSR 是关于初始页面的，它呈现所有的元素，并将它们作为纯 HTML 和 js 发送给客户端(一旦完成，你就有了交互性，例如你可以点击一个按钮)
- RSC是关于组件的，你可以将它们作为反应结构发送给客户端以显示一些数据(在服务器上获取和呈现) 
   - You can do fine-grained updates
   - There is less client-side code
   - Data Fetching is simpler
- "Islands of interactivity" 是一个在web开发和用户界面设计中使用的术语，特别是在讨论现代web应用的上下文中。这个术语描述的是一种设计模式，其中一个网页主要是静态的，但包含了一些交互式的、动态的部分，这些部分被称为“交互岛屿”（islands of interactivity）。
- Astro" 是一个现代的web开发框架，它在设计上就紧密结合了 "islands of interactivity" 的概念。
-  RSC 允许我们在不牺牲速度和安全性的情况下更新目标接口部分

# 20231211  Incrementally adopt the Next.js App Router
[https://www.youtube.com/watch?v=YQMSietiFm0](https://www.youtube.com/watch?v=YQMSietiFm0)

- 客户端和服务器组件的交织真正展示了这种架构的优点
- 可以利用客户端的最佳部分进行交互式应用程序以及服务器的最佳部分
# 20231211 Andrej Karpathy: Intro to Large Language Models 2

- 我们并不清楚这1000亿个参数的具体功能和协作方式
- 将神经网络视为经验性的工件，并需要进行复杂评估来处理这些模型
- 微调阶段通常需要人工标记的介入
- 微调阶段的数据集，强调了质量优于数量，数据集中包含少量但高质量的对话文档
- 预训练阶段主要是关于知识，而微调阶段是关于对齐和改变格式。
- 预训练阶段通常在公司内部执行，而且频率较低，可能一年一次或多个月一次。
- 微调成本更低，你可以每周、每天等等进行这样的操作
- 基本模型不能直接使用，因为它不会回答带答案的问题，如果你给它问题，它只会给你更多的问题，或者会做类似的事情，因为它只是一个互联网文档采样器
# 20231210 How to go great work 2
[http://paulgraham.com/greatwork.html](http://paulgraham.com/greatwork.html)

- 白日梦必须与深思熟虑的工作交织在一起，从而提出问题
- 只有当你了解什么是最优秀的工作，并且知道是什么因素使它们脱颖而出时，你才能明确自己的目标和追求
- 如果不努力成为最佳，甚至连基本的优秀都难以实现
- 努力成为最佳其实可以简化问题和决策过程。
- 风格是在不刻意追求的情况下以独特的方式做事。刻意追求则是造作
- 真诚不仅仅是行为上的诚实，更重要的是在思考和智力上的诚实；如果你在智力上不诚实，你怎能对真理有敏锐的洞察力呢？
- 承认错误之前，你必须承担错误的后果
- 不花费精力来表现自己的特点基本上就是书呆子的定义
- 要克服惯性和懒惰的影响，可以通过问自己是否愿意回到之前的状态来决定是否需要重新做某事。
# 20231209 Next.js 官方文档略读1
[https://nextjs.org/docs](https://nextjs.org/docs)

- Rending feature: Streaming on Edge and Node.js runtimes.
- DataFeting: request memoization, data caching and revalidation.
- App Router 和 Pages Router 
   - App Router: 
      - React's latest features, such as Server Components and Streaming
      - 是Pages Router 的自然过渡
      - 在app目录下
   - Pages Router : 
      - server-rendered React applications ,
      - 提供了到app的升级的方案，
      - 在page目录下
   - 这两部分的文档是可以切换的
   - 可以同时使用
   - 有一套不同于umi的文件规则
- 限制Layouts访问原始请求来提供性能
- React18 Streaming SSR :
   - Streaming HTML（流式渲染）：服务端可以分段传输 HTML 到浏览器
   - Selective Hydration（选择性注水）：只对已经完成渲染的区域做 hydration
- React18 server component
   - **React Server Comp**onent Payload (RSC) :呈现的 React Server 组件树的紧凑二进制表示形式
   - 三种渲染方式：
      - [Static Rendering (Default)](https://nextjs.org/docs/app/building-your-application/rendering/server-components#static-rendering-default)：当没有使用动态函数并且数据被缓存的时候
      - Dynamic Rendering : 使用动态函数 或者 数据没有缓存的时候
      - Streaming: 使用loading.js 和 React supense启用
- Fast refresh
   - 错误边界不应该太细粒度。它们是由React在生产中使用，并应始终是有意设计。
   - Class组建和匿名函数组建不支持热更新保持状态
   - useEffect, useMemo 会强制刷新
- Rendering
   - [Rendering Environments](https://nextjs.org/docs/app/building-your-application/rendering#rendering-environments)
   - Network Boundary:use client , use server
   - Hydration: 是将事件侦听器附加到 DOM 的过程，以使静态 HTML 具有交互性
   - 

# 20231208 Andrej Karpathy: Intro to Large Language Models 1
[https://www.bilibili.com/video/BV1NH4y1m78m/?spm_id_from=333.337.search-card.all.click&vd_source=ba233cc2ca5aa56e0c97eb7eec51cb2e](https://www.bilibili.com/video/BV1NH4y1m78m/?spm_id_from=333.337.search-card.all.click&vd_source=ba233cc2ca5aa56e0c97eb7eec51cb2e)

- 500 行C代码，没有其他依赖项，就可以实现神经网络架构
- llama 270b的训练成本：10 万亿字节的互联网文本数据，6,000 个 GPU，运行大约 12 天，花费大约 2 百万美元，得到140GB的参数文件，压缩率大概是100
- 可以数学上证明预测和压缩之间有非常紧密的关系
- 如果能够准确预测下一个单词，那么可以用来压缩数据集
- 下一个词预测任务虽然看似简单，但实际上非常强大，因为它迫使神经网络学习关于世界的大量信息
# 20231208《What Is ChatGPT Doing ... and Why Does It Work?》Semantic Grammar and the Power of Computational Language

- ChatGPT 的成功表明，人类语言实际上比我们想象的要结构化和简单得多，最终可能会有相当简单的规则来描述这种语言的组合方式
- 语义语法必然涉及某种“世界模型”—一种作为“骨架”的东西，语言可以在其上由实际单词构成
- “全局有意义”：计算更多关于实际世界或可能发生的事情，甚至可能是一致的虚构世界。
- 三段论逻辑本质上是关于以人类语言表达的陈述的一系列规则。随着形式逻辑的发展，原始的三段论逻辑构造现在可以用于构建更复杂的形式逻辑框架，包括现代数字电路等
- ChatGPT在某种程度上已经“钻研到了”能够以语义上有意义的方式“组织语言”，而不必担心不同的可能说法。
- 计算语言可以描述可能性，而ChatGPT则可以为文本生成提供强大的工具。将它们结合起来可以使ChatGPT不仅生成文本，还能评估文本的准确性和陈述的正确性。
# 20231207 Ghost introduction
[https://ghost.org/docs/introduction/](https://ghost.org/docs/introduction/) 

- 传统上，编写内容的人和编写代码的人很少就使用的最佳平台达成一致。
- 具有优秀编辑器的工具通常缺乏速度和可扩展性，而快速框架基本上总是牺牲用户体验。
- 编辑器目前不支持扩展插入内容
- 部署了一套系统，解决了一个域名解析的问题
# 20231204《Elon Musk》16 Fathers and Sons Los Angeles, 2002
[https://book.douban.com/subject/1662563/](https://book.douban.com/subject/1662563/)

- Baby Nevada
   - 突发性婴儿猝死综合症，这是发达国家中导致婴儿死亡的主要原因
   - 马斯克在面临困难和悲伤时会关闭自己的情感，这是他的生存方式
- Errol arrives
   - 看着自己的儿子去世让Elon渴望与父亲在一起
   - 个人关系网络比数字网络更复杂

# 20231203 How to go great work 1
[http://paulgraham.com/greatwork.html](http://paulgraham.com/greatwork.html)

- 选择的工作需要具备三个特质: 
   - 它必须是你有天赋的东西，
   - 你有深切的兴趣，
   - 提供范围做伟大的工作,这一点不用过于担心，因为雄心勃勃的人对此已经过于保守了
- 一些重大发现常常源于发现不同领域之间的联系和共通点
- 找出要工作的内容的方法是通过实际工作
- 不要将工作定义为他人要求你去做的事情，而是应该注重个人项目和创造性工作
- 你的项目兴趣和重要性会逐渐融合，随着时间的推移，你会更加关注那些既令人兴奋又重要的事情
- 大脑倾向于简化世界模型，而很多重大发现都来自于对被其他人视为理所当然的事情提出疑问
- 四个步骤：
   - 选择一个领域，
   - 学到足够的程度来达到前沿,需要艰苦的工作
   - 注意差距
   - 探索有前景的领域，需要艰苦的工作
- 在确定要从事的工作时，你需要自己做决定
- 通过保持好奇心、尝试新事物、结交人际关系、阅读书籍和提出问题来增加自己成为运气大目标的机会
- 随着学习的深入，一个领域应该变得越来越有趣，如果不是这样，可能不适合你
- 兴趣越奇怪，越能带来更好的结果，如果你在少数人曾经看过的地方寻找，你更有可能发现新事物
- 如果你在为人们制作东西，确保它是他们实际需要的东西，做到这一点的最佳方式是制作你自己想要的东西，写你想阅读的故事；制作你想使用的工具
- 一种常见的错误，即将自己的创作目标定位在想象中的受众需求上，而不是自己真正想要的内容
- 如果你感兴趣，你就不会迷失方向
- 工作也有一门技术，就像航海一样
- 你必须努力工作，但也有可能工作过度，如果这样做，你会发现你得到的回报逐渐减少：疲劳会让你变得愚蠢，最终甚至可能损害你的健康
- 开始工作可能比继续工作更难,不要担心这一点；这是工作的本质，而不是你性格上的缺陷,工作具有一种每天和每个项目的激活能量,由于这个门槛是虚假的，因为它比继续工作所需的能量更高，所以告诉自己一个相应大小的谎言来克服它是可以的
- 但在某些情况下，无知有时可以胜过知识，尽量完成你开始的事情，即使它事实上比你预期的工作量要大
- 完成事情不仅仅是整洁或自律的锻炼，而且在许多项目中，最佳工作往往发生在原本打算是最后阶段的时候。
- 拖延者通常不是无所作为，而是在勤奋地做其他事情，这使得拖延不容易被察觉
- 指数增长的问题在于一开始曲线看起来是平的，实际上它不是平的，它仍然是一个奇妙的指数曲线。但我们不能直观地理解这一点，因此我们低估了指数增长在早期阶段的价值
# 20231202《Elon Musk》15 Rocket Man 2002
[https://book.douban.com/subject/1662563/](https://book.douban.com/subject/1662563/)

- Russia
   - Musk的酒量并不怎么样，不会喝酒
   - 我们这个时代最大胆的设想：私人建造的火箭可以将卫星和人类送入轨道，并最终将其送往火星和更远的地方
- 第一性原理
   - “idiot index（白痴指数）”：用于计算成品相对于原材料的额外成本。这个指数表明，如果一个产品的成本大大超出其原材料成本，那么可以通过改进制造技术显著降低这种成本。
   - Musk对火箭的各种材料成本进行了详细的计算，发现使用现行制造方法生产的火箭，其成本至少是原材料成本的五十倍
- SpaceX
   - Musk转向使用火箭发射商业和政府卫星，以此实现项目的经济自给自足。这一转变成为了他职业生涯的一个重要标志。
   - 我们会做一些愚蠢的事情，但让我们不要在大规模上做愚蠢的事情
   - Musk成为了SpaceX的首席工程师
   - Musk在PayPal时期建立的传统，即设定看似不切实际的时间表，将看似疯狂的想法转化为现实，尽管这些实现往往会比原计划晚很多
# 20231201《Elon Musk》14 Mars
SpaceX, 2001
[https://book.douban.com/subject/1662563/](https://book.douban.com/subject/1662563/)

- Flying
   - 解释了他的工作风格，即以高度集中的方式完成任务
   - Musk采取了大胆的举措，购买了一架苏联集团军用喷气机
- Red planet
   - Musk最终意识到NASA并没有火星计划，这让他感到震惊
   - Musk说：“我要殖民火星。我的生命使命是使人类成为多星球文明。
- Why？
   - 可技术可能会停滞不前，甚至倒退
   - 殖民其他星球可以帮助确保人类文明和意识的生存，以防不测事件发生在脆弱的地球上
   - 费米悖论：如果宇宙中存在大量的外星智慧生命，为什么我们尚未观测到或接触到它们？
   - 生活不能仅仅是解决问题，还必须追求伟大的梦想。“这是让我们早上起床的原因。
- LosAnge
   - 由于跟Justine的婚姻关系，马斯克成为美国公民
- les
- sffdffd	

