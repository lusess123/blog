# The Future of Evals - Ankur Goyal, Braintrust
+ [https://www.youtube.com/watch?v=MC55hdWLq4o](https://www.youtube.com/watch?v=MC55hdWLq4o)
+ 一个在 **Brain Trust** 注册的平均组织每天几乎会运行 13 个 **evals**；我们有些客户每天运行的 **evals** 超过 3,000 个
+ 一些最前沿的公司每天在这个产品里会花超过两小时，逐一处理他们的 **evals**。
+ **Claude 4** 带来了真正的突破时刻，它的表现几乎比之前的领先模型好六倍。
+ **Loop** 在 **Brain Trust** 内部运行，能自动优化你的 **prompts**，一直扩展到非常复杂的 **agents**。
+ data sets + scorers + Prompt = Evals

# 20250809 GPT-5 Fails. AGI Cancelled. It's all over...
+ [https://www.youtube.com/watch?v=tL8CENSCd0w](https://www.youtube.com/watch?v=tL8CENSCd0w)
+ **Gary Marcus** 表示 **GPT5** 非常令人失望。其中很多只是炒作和营销。这不是通往 **AGI**（通用人工智能）的道路。
+ 们需要明白的一个重大问题是，**GPT5** 并不是单一模型。
+ **Matt Schumer** 指出，很多**不佳体验**来自把 **GPT5** 放进**尚未优化**的**agent harness**（运行框架/外壳） 里。
+ 若必须靠**纯文字思考**推出来，质量可能就**没那么好**。凡是能**默认转为写代码**来完成的任务，表现都会**更好**。
+ **GPT5** 的强项是**遵循指令（instruction following）**：理解你的**意图**并转化为**产出**；它也擅长**调用工具（tool calling）**，甚至用代码**自建工具**。
+ 在 **GPT5** 上，这已扩展到**中/长时程**任务——原本可能需要**人类实习生**花上**几小时**。
+ 有一些**趋缓（plateauing）**——像是**S 曲线**：先是**动能大涨**，现在**略有走平**。
+ **自动切换器（auto switcher）有问题——大半天都停摆（out of commission）**——所以“**GBT 5**”（应为 **GPT5**）看起来**变笨**了。

# 20250808  Prompting 101（下）
+ [https://www.youtube.com/watch?v=UjboGsztHd8](https://www.youtube.com/watch?v=UjboGsztHd8)
+ Claude 因为我们提供的额外上下文而变得更加自信
+ 你可以直接将一张图片进行 Base64 编码，并把它作为数据的一部分传入示例中。
+ 提供例子：
    - 示例充当具体的模板，能让 Claude 更容易理解并复现你想要的输出。
    - 在需要保持一致格式、使用特定术语或遵循行业标准的任务中，这一点尤为重要。
    - 与其用文字把所有细微之处都描述清楚，不如直接给 Claude 看一两个你期望的输出示例，往往更高效。
    - 相关性、多样性、数量（至少 3–5 个）。
+ 减少幻觉的几种方式：
    - 让 Claude 在不知道的时候说“我不知道”。
    - 告诉 Claude 只有在它对自己的回答非常有信心时才作答。
    - 让 Claude 在回答前先思考。
    - 请 Claude 从长文档中找到相关引用，然后用这些引用来回答。
+ 预填 Claude 的回复
    - 在“Assistant（助手）”字段/角色中先写好文本，用来预填 Claude 的回复。Claude 会从你停下的地方继续写。
    - 这样能让你：
        * 引导 Claude 的行为或回答
        * 对输出格式拥有更强的控制权
+ extend thinging 的缺点
    - 思考过程中可能需要“重新发明轮子”，这会导致更高的 token 消耗
    - 由于思考需要温度（temperature）设为 1，有时可复现性会较差

# 20250807  Prompting 101（上）
+ [https://www.youtube.com/watch?v=ysPbXH0LpIE](https://www.youtube.com/watch?v=ysPbXH0LpIE)
+ 提示工程在许多方面是一种高度迭代的、经验型的学科
+ 最后，我们通常建议重复强调一些对Claude理解任务特别重要的信息。也就是跟Claude回顾信息，强调一些特别重要的内容，然后告诉Claude：“好了，现在你可以开始工作了。”
+ 提示词结构：
    - Task context
    - Tone context
    - Background data, documents, and images
    - Detailed task description & rules
    - Examples
    - Conversation history
    - Immediate task description or request
    - Thinking step by step / take a deep breath
    - Output formatting
    - Prefilled response (if any)
+ 如何组织信息：
    - **Claude** 非常喜欢结构和条理，因此我们建议在你的提示里遵循一种标准结构。无序的结构难以理解
    - 使用类似XML标签的分隔符进行组织
    - Claude能理解各种类型的分隔符，但推荐使用XML，因为其边界明确且节省token

# 20250806 OpenAI Just Broke The Industry
+ [https://www.youtube.com/watch?v=NyW7EDFmWl4](https://www.youtube.com/watch?v=NyW7EDFmWl4)
+ GPT-OSS 1200亿参数模型，Codeforces 编程比赛的成绩，同于带工具的O3模型，以及带工具的O4 mini模型
+ 这是个重大举措。由于我们还在等待 GPT-5 的发布，我认为可以合理地说 GPT-5 将进入下一个级别。
+ OpenAI 正在使用的一些“秘方”级强化学习技术，其中一个特别重要的就是 **universal verifier**（通用验证器）。这个技术可能类似于 **proverifier**，这是 OpenAI 曾发表过的一篇论文。
+ 这个开源的1200亿参数模型在核心推理基准测试上几乎达到了与 OpenAI O4 Mini 相当的性能，而且能在单张80GB显存的 GPU 上高效运行，这简直不可思议。
+ 当这些模型经过对抗式微调（adversarial fine-tuning）后，其表现出的风险略高于 DeepSeek 模型。最近的 Kimmy 模型和 Quen-3 模型表现出了类似的风险潜力。
+ 他们对数据进行了分词（tokenize）处理，并且今天还将这个分词器（tokenizer）也开源了。
+ 这些模型的后续训练过程类似于 O4 Mini，包括监督式微调阶段和高性能多处理器（high-MP）计算强化学习阶段。
+ 这些模型还支持不同程度的推理强度——低、中、高三种级别，类似于 API 中的 O 系列模型。开发者可以通过在系统消息中简单的一句话轻松设置推理强度。
+ 就今天来说，这几乎抹平了目前最顶尖的私有闭源模型与最顶尖的开源模型之间的差距。
+ 在人类最终考试（humanity's last exam）基准测试上，差距较大。较大的开源模型得分为19，而 O3 模型得分接近25。
+ OpenAI 警告称，有时候惩罚模型的“坏想法”并不能阻止不良行为，反而只会让模型更好地隐藏真实意图。

# 20250803 Vibe coding in prod
+ [https://www.youtube.com/watch?v=fHWFF_pnqDk&t=302s](https://www.youtube.com/watch?v=fHWFF_pnqDk&t=302s)
+ 当你与AI模型保持着紧密的反馈循环时，这并不是真正的“vibe coding”。
+ vibe coding最关键的一点是，彻底忘记代码的存在
+ 而“vibe coding”的积极一面往往都是一些风险较低的事情。
+ AI能够完成的任务长度每7个月就会翻一倍。目前我们能够达到的任务长度大约是一小时
+ 在某个阶段，你将必须处理足够大的系统，而到那时你不得不开始信任整个系统。
+ 我认为未来几年我给整个软件行业的挑战，就是我们如何安全地在生产环境中进行“vibe coding”？
+ 我们会忘记代码的存在，但绝不会忘记产品本身的存在。
+ 不懂具体实现细节却又要管理的情况，其实和人类文明一样古老。就像我们作为软件工程师一样，逐渐放弃了对底层汇编代码等细节的深入了解。
+ 在确保安全和负责任的同时做到这一点的方法，就是找到一个抽象层，即便不了解底层实现，也可以对其进行验证。
+ tech debt（技术债务），是极少数只能靠自身具备底层实现的专业知识才能有效验证的领域之一。
+ 我们必须非常聪明、有针对性地，清楚地知道在哪些地方可以充分利用自动化编码。
+ 当我和**Claude**一起开发功能时，我通常会花15到20分钟把指导信息集中成一个提示（prompt），然后让**Claude**自行发挥。这15到20分钟并不是单纯我手动写提示，而经常是与**Claude**进行单独的交流、来回沟通。
+ 考虑可验证性，即如何在不亲自阅读代码的情况下确认变更是正确的。
+ vibe coding的总结建议：
    - 成为**Claude**的产品经理，不要问**Claude**能为你做什么，而要问你能为**Claude**做些什么。
    - 把你的vibe coding集中在叶子节点，而非核心架构和底层系统，这样即使产生技术债务，也能被有效控制，不会影响关键部分。
    - 考虑可验证性，即如何在不亲自阅读代码的情况下确认变更是正确的。
    - 最后，请记住指数级增长的趋势。
+ 我们的模型在没有被过度约束的情况下表现最佳。因此，我不会花太多精力去制定非常严格的格式或类似的东西。
+ 指数级增长的真正含义不仅是它们会持续改善，而是它们改善的速度会远超我们的想象。
+ 我喜欢在 Claude 到达一个较好的暂停点时进行压缩或直接开启新的会话。就像人类程序员那样，达到一个合适的阶段就暂停一下，休息一下，也许吃个午餐再回来。
+ 我通常会用 Claude code 开始编写代码，然后再用 Cursor 进行修补完善。

# 20250802 Claude Code best practices
+ [https://www.youtube.com/watch?v=gv0WHhKelSE](https://www.youtube.com/watch?v=gv0WHhKelSE)
+ **applied AI** 的团队，使命就是帮助客户和合作伙伴在 **Claude** 平台之上构建出色的产品和功能。
+ **Claude Code** 团队内部其实搭建了一个排行榜，记录所有 **Anthropic** 员工使用该工具的情况。
+ **Anthropic**，我们始终遵循的原则是：“选择简单有效的方法。”对 **Cloud Code** 而言，这意味着它是我们所称的“非常纯粹的智能体（agent）”。**Cloud Code** 的本质：它就是一些强大就像是那种所有事情都在终端（terminal）里完成的同事。
+ 在 **Anthropic**，我们说到智能体（agents）时，真正指的是一系列指令（instructions）、一些强大的工具，让模型不断地循环执行，直至模型自主认为任务完成。
+ Cloud Code不使用任何形式的索引。是通过“智能体式搜索”（agentic search）实现的，使用的工具和我们人类常用的类似，比如 **glob**、**grep**
+ 还有一点我认为被大家低估了，就是你可以把 **Cloud Code** 当成一个思考伙伴（thought partner），而不只是急于直接开始工作。
+ 在我们 **Cloud Code** 团队的代码库中，我们的单元测试覆盖率异常高。这是因为 **Cloud Code** 使得编写单元测试变得极其简单和直观。
+ 把 **Cloud Code** 提供给客户并与他们交流时，有一点我们并未预料到：很多客户或潜在客户表示，“我们一直在推迟对大型代码库的迁移。”使用 **Cloud Code** 这样的工具可以让类似项目变得更容易消化和实现。
+ **Claude** 极其擅长终端操作，这意味着它也非常擅长各种命令行工具（CLI）。
+ 最佳实践：
    - 环境安装和配置
        * 使用 claude.md
            + 当我们启动**claw**时，如果当前目录中存在**claw.md**文件，它会被直接放入上下文中。
            + 你可以将**cloud.md**文件放在不同位置，比如放在项目中并提交（check in），这样你的所有队友都可以共享。
        * 调整权限管理
            + 自动接受模式（autoaccept mode），当你使用cloud code时，只需按下Shift-Tab键，Claude就会自动开始执行任务。
            + 对于特定的bash命令，你可以设置为始终自动允许。
        * 命令行集成
            + 最大化利用**cloud code**的一点，就是要记住它在终端（terminal）中表现非常出色
            + 选择CLI工具或安装本地软件并连接MCP服务器之间时，优先使用知名且文档完善的CLI工具。
        * 上下文管理（context management）
            + 可以执行`/cle`命令重新开始，这将清除所有内容，除了**claude.md**文件。
            + 执行`/compact`命令，这相当于插入一条用户消息：“我需要总结一下我们做过的所有事情，然后交给另一个开发人员继续工作”。
    - Effective workflows
        * planning and to-dos
            + 如果你一直关注这个待办清单，发现有任何奇怪或不合理的地方，你可以按下Escape键并告诉Claude：“嘿，我们调整一下待办清单吧，我觉得你的方向错了。”
        * smart vibe coding
            + 建议采用测试驱动开发（TDD）
            + 使用截图（screenshots）来指导和调试（debug）
    - 高级技巧
        * 我知道在Anthropic以及一些客户那里，有人同时运行4个Claude实例
        * 隐藏功能，知道的人不多，按两次Escape键，可以回退到对话中之前的位置
        * 通过接口调用使用 claude code , 已经在 github actions 上很好的实践
        * 我们发布更新的速度非常快，你要时刻掌握最新动态
        * tool call 可以deep think 了，我鼓励大家在做任务和解决 bug 时，加入一个 **think hard** 命令
        * IDE 插件已经可以集成感知当前文件和选中文本的能力了
        * 我们修改了设置，使得不会自动读取所有子目录的 cloud MD 文件，所以你可以给他提示去读子目录的
        * 我们有一个新功能，可以在 cloud MD 文件中使用 @ 引用其他文件
        * 你可能需要所有智能体把信息写到一个共享的 markdown 文件里，这样它们就可以相互沟通并同步状态。

# 20250801  "AlphaGo Moment" For Self Improving AI... can this be real?（上）
+ [https://www.youtube.com/watch?v=QGeql15rcLo](https://www.youtube.com/watch?v=QGeql15rcLo)
+ 人工智能研究中最大的问题就是人类本身，我们就是那个拖慢一切进展的因素。
+ 他们正试图让AI改进自身的架构，寻找从零开始更好地构建自己的方法。他们正在引入一种从自动优化到自动创新的范式转变。
+ 它提出了1773种用于改善人工智能大脑中神经架构这一特定过程的构想，进行了实验来区分有效与无效的方法，最终得到了106种业界领先（即截至当时最佳）的新方法，在本例中即为线性注意力架构。
+ 他们首次建立了科学发现自身的经验缩放定律。
+ 大部分的突破性进展来自于特定的几种方法，这些方法并非随机出现，也非随机分布的。
+ 非最优模型，也就是那些未能取得最佳结果的模型，表现出更严重的长尾问题。

