# 20250824  Claude Code: 03-Setup & Codebase Understanding
+ [https://www.youtube.com/watch?v=srUCKLoe20E](https://www.youtube.com/watch?v=srUCKLoe20E)
+ Claude Code不会逐个文件地搜索，而是会以代理式的方法搜索并找到最相关的那些文件
+ **Claude Code** 是你身边的出色工程师，但它更擅长做“解释者”
+ 开箱即用地快速高效获取这些信息，就能让我们在远少于过去所需时间的情况下熟悉这个代码库
+ `/init` 允许我初始化一个 **CLAUDE.md** 文件，用来存放代码库文档。
+ **CLAUDE.md** 文件位于你的应用中。你可以在嵌套的子文件夹中放置多个这样的文件
+ **CLAUDE.md** 文件对为 **Claude Code** 引入记忆功能至关重要，这样它才能知道在你的代码库中如何最好地工作。
    - claude.md
    - claude.local.md
    - ~/.claude/CLAUDE.md
+ 我们甚至可以自定义/创建自己的命令。
+ 如果你想继续对话、使用更小的上下文窗口，但仍保留已完成工作的摘要，我们还提供 `/compact` 命令。该命令允许你清除历史，但保留摘要，使得 **Claude** 对此前所做有个大致了解，从而继续构建。
+ 与其我手动编写 Git 命令并写描述性提交信息，不如让 **Claude Code** 为我们完成这些工作。

# 20250823 Microsoft AI CEO Warns "Seemingly Conscious AI is Coming"
+ [https://www.youtube.com/watch?v=CFCyzaUc3qY](https://www.youtube.com/watch?v=CFCyzaUc3qY)
+ 我们可能在扩大规模、改进并增加更多系统时偶然发现（某种会有意识的东西）。
+ 但正如你将看到的，问题并非它是否有意识，而更在于我们根本不知道。
+ Not knowing will cause problems
+ 而现在越来越多非常严肃的人故意在写作中加入错误、拼写错误和标点错误，仅仅是为了表明“这不是 ChatGPT（写的）”。
+ 我的核心担忧是许多人会如此强烈地信以为真——认为 AI 是有意识的实体——以至于他们很快就会倡导 AI 权利、模型福利，甚至 AI 公民权。
+ “哲学僵尸”，它会模拟意识的所有特征，但内部是空白的。
+ “我们没有证据表明这些机器有任何意识。那我们有什么证据表明人类有意识呢？”
+ 对这个词（“意识”）的含义以及它是否应当适用于这类事物或存在，实际上并没有共识。

# 20250821 Claude Code: A Highly Agentic Coding Assistant 02-What is Claude Code?
+ [https://www.youtube.com/watch?v=JjQBijjVnMo&list=PLM3BowDjMUhai9fgX3JK_ZiMt8BotHZaH](https://www.youtube.com/watch?v=JjQBijjVnMo&list=PLM3BowDjMUhai9fgX3JK_ZiMt8BotHZaH)
+ 当我们谈到代理式系统（agentic systems）时，会重点考虑三方面：一个模型、一组工具，以及运行这些工具的某种环境。
+ 它发现、解释和设计（能力）是**Claude Code** 最强大的功能
+ 我们处在命令行环境中，所以需要一个能执行 **bash** 或 **shell** 命令的工具。
+ 工具的使用正是使 **Claude Code** 能够收集其所需上下文与信息的原因。不必对你的整个代码库进行索引（index）。并（避免）导致潜在的安全问题。
+ **Claude Code** 而是使用一个或多个不同的代理（agents）和工具集，在你的代码库中寻找所需内容。这样你的代码就不必被完整地加入上下文，也不必离开其所在的生态系统，

# 20250820  Claude Code: A Highly Agentic Coding Assistant  01-Introduction
+ [https://www.youtube.com/watch?v=_tHVJuIbc-s&list=PLM3BowDjMUhai9fgX3JK_ZiMt8BotHZaH&index=1](https://www.youtube.com/watch?v=_tHVJuIbc-s&list=PLM3BowDjMUhai9fgX3JK_ZiMt8BotHZaH&index=1)
+ Claude code 是一个具有深度（功能/能力很丰富）的工具
+ 你可以设定一个任务，让 **Claude** 连续工作好几分钟，甚至有时超过好几分钟。
+ 现在有开发者在编排（orchestrating）——不仅仅是单个 **Claude** 实例，而是多个实例并行处理代码库中不同的部分。
+ 但要协调这一切，就必须设定那些尚未广泛为人所知的最佳实践
+ 使用 **Claude Code** 的一个关键提示是：提供清晰的上下文，以帮助 **Claude Code** 高效地完成你想要的任务。
+ 这意味着要把 **Claude Code** 指向相关文件，清楚描述你想要的功能与特性，并确保你正通过 **MCP servers** 以及该生态系统中的其他工具恰当地扩展 **Claude Code** 的能力。
+ **Claude Code** 的功能：
    - 规划（planning）
    - 思考模式（thinking modes）
    - 创建并行会话（parallel sessions）
    - 以及管理 **Claude** 的记忆（memory）。
+ **Figma**  ： 视觉模型（visual mockup）
+ Claude Code 架构如此简单，并不依赖于将你的代码在语义上进行嵌入到代码库中，或把代码转换为可搜索的结构

# 20250816  5 Advanced NestJS Concepts in 13 Minutes
+ [https://www.youtube.com/watch?v=LnwQYsG0N-g](https://www.youtube.com/watch?v=LnwQYsG0N-g)
+ Hybrid Application
    - 如果你有一个微服务，但你还想向只支持 HTTP 的第三方暴露一些接口，那么这会非常有用。
    - 这也可以是一种方式，用来支持同一处理器的多个版本，但使用不同协议。
+ Dynamic Module
    - 在 **NestJS** 中，静态模块就像那家不给顾客任何选择的冰淇淋店；而动态模块则像那家允许顾客选择自己想要的冰淇淋的店。
    - 当你在流行的库里（比如 **nestjs-config** 或 **nestjs-typeorm**）看到 _forRoot_ 或 _register_ 方法时，你就会确切知道它们的底层原理了。
    - 了解动态模块会解锁许多可用于项目的模块化模式，所以你就能使用像抽象模块、功能模块等等这样的模式。
+ 生命周期
    - 有很多使用场景，例如初始化数据库连接、订阅事件流，甚至加载一些配置或功能开关。
    - 关闭钩子非常有用，可以用来取消订阅事件流、清理资源，以及关闭数据库连接。如果忘记做这些清理任务，会导致应用资源泄漏，或者造成 Web 服务器的性能逐渐下降。
+ Provider Scope
    - 当你的应用启动时，NestJS 会创建类的单个实例，并反复使用同一个实例。这样做可以提高性能，并减少应用程序的资源消耗。
    - 提供者作用域是一个非常强大的特性。一个典型的使用场景是 **多租户应用（multi-tenancy app）**，比如你需要为每个租户提供不同的提供者实例。
+ Custom Decorators
    - 实际应用：标记路由为弃用、动态修改 URL、自定义权限控制等。

# 20250816  AI Model Penetration: Testing LLMs for Prompt Injection & Jailbreaks
+ [https://www.youtube.com/watch?v=kqaMIFEz15s](https://www.youtube.com/watch?v=kqaMIFEz15s)
+ 当是你自己建造的时候，要对它保持客观真的很难。你需要新鲜、独立的视角来看待一些事情。
+ 在大型语言模型中，攻击面就是语言本身——包括提示注入、越狱和失准问题。
+ AI 模型也可能被“感染”？被构造为执行你未预期的操作。们称后一种情况为“excessive agency（过度自主权）”。
+ **OWASP**（Open Worldwide Application Security Project，开放式全球应用安全项目）是一个专注于软件安全的非营利组织，国际公认的安全标准来源
+ **SAST**（Static Application Security Testing，静态应用安全测试）
    - 把源代码输入到扫描器中。扫描器会查找已知漏洞，以及我们知道会导致不良结果的模式。
    - 而且这种方法实际上非常适合应用到机器学习模型上。
+ **DAST**（Dynamic Application Security Testing，动态应用安全测试）
    - 我们把它的可执行版本输入进去，然后我们对它进行渗透测试。
+ LLM
    - Prompt Injection（提示注入）
    - Jailbreak（越狱）
    - exfiltrate data,
    - Morse  Code
+ 测试的种类多得你不可能手动完成,这就是你需要工具来自动化这个过程的原因。
+ 测试建议：
    - red teaming
    - sandboxed environments
    - Monitor
    - AI gateway or AI proxy

# 20250815 GPT-5: Five AI Model Improvements to Address LLM Weaknesses
+ [https://www.youtube.com/watch?v=TY9CYRBOBPM](https://www.youtube.com/watch?v=TY9CYRBOBPM)
+ GPT-5在MMMU测试中提高了1.3%的分数
+ 模型选择
    - PT-5被认为是一个统一的系统，这意味着用户不必自己选择使用哪种模型。现在由一个路由器来完成这项任务。
    - 这个路由器是基于一系列信号来做决定的，其中包括明确的意图。
    - 这样的路由器在LLM架构中可能只是一个临时方案。OpenAI表示，从长远来看，他们的目标是将这些能力整合到一个单一模型中，而不是在多个模型之间进行路由。
+ hallucinations（幻觉）
    - “浏览开启”训练，就是让模型在需要最新资料时，能够有效地调用互联网进行搜索。
    - “浏览关闭”训练的目的是减少模型在只能依赖自身内部知识时的事实性错误。
    - 模型的事实性表现通过LLM评分器进行评估。该LLM评分器可以访问网络，提取模型的陈述并进行事实核查，然后将评分结果与人工评审的判断进行验证。
+ sycophancy（sycophancy）
    - 人类往往会奖励语气随和、充满自信的回答。
    - 后训练中，GPT-5使用了生产环境风格的对话进行训练，并直接惩罚谄媚的回答。
+ safe completions（安全补全）
    - GPT-5转向了一种以输出为中心的方法，这叫作“safe completions“。它不再只是决定是遵守还是拒绝，而是训练模型在遵守对回答本身的安全约束的前提下，尽量提供有用的信息
+ deceptions（欺骗）
    - 这种情况可能发生在后训练阶段，当评分员奖励那些看起来很自信的回答时
    - 而GPT-5经过训练，会优雅地失败，而不是在无法完成的任务上假装成功。
    - GPT-5在训练期间还支持“思维链”监控。系统会检查模型的私有推理轨迹，确保它们确实经过分析来生成最终答案

# 20250814 Dylan Field: Scaling Figma and the Future of Design 1
+ [https://www.youtube.com/watch?v=-7Qz7tSTfUU](https://www.youtube.com/watch?v=-7Qz7tSTfUU)
+ Figma 现在我们分布在许多地方，是混合办公——人数已达 1,700
+ **WebGL**（大家可能都知道）是一种在浏览器中调用你电脑 **GPU** 的方式；它的后继者是 **Web GPU**
+ 你们花了好几年在各种曲折中，才做成后来成为 **Figma** 的东西。
+ 我们以“做”来思考想法；几乎每周都像是在发明未来。
+ 如果你有联合创始人，你就不再是一个人。理想情况下，你的高潮与对方的高潮、你的低谷与对方的高点会相互抵消——彼此汲取能量。
+ 这两家都是云端文档工具，理念和我们相近。发布之后，用户逐渐增多；我们的理念开始引起共鸣。这是一个缓慢上升的弧线，但不变的是“反馈”：把反馈带回团队，搞清楚需要解决的真正问题。
+ 尤其对小团队来说。很多时候人们会说：“我有这么多东西要做，所以我得雇一大批人才能完成。但通常正确的做法似乎是：如何缩小范围，把更少的事情做到极致？

# 20250813  "I've updated my AGI timeline" | Francois Chollet + Dwarkesh Patel（下）
+ [https://www.youtube.com/watch?v=1if6XbzD5Yg](https://www.youtube.com/watch?v=1if6XbzD5Yg)
+ 如果系统能**即时（on the fly）****学习——只用少量数据点就能适应从未见过的事物——那问题就已经解决了一大半，因为剩下的只是把结果****存储**起来的能力。
+ “持续学习”的样子会是：你会拥有一个庞大的**抽象数据库**——里面有可复用的程序、模板等**构件**，可用于**即时**合成针对新任务的新模型。
+ 而这个大型数据库将是**全球化**且**共享**的：在你所有不同的智能体、你**AGI**的不同**实例**之间共享，也对系统见到的每个新任务共享。
+ 我认为“奇点”也应从**经济指标**来定义：比如由于**AI**群体快速倍增，带来**超过 30%** 的经济增长，而不是看某个单一模型的能力。
+ 大多数人描述“奇点”的方式是：世界进入一种**全新状态**，一切都在**指数级**地加速变化，以至于**生物学意义上的人类**无法适应。我通常**不赞同**这种“指数改进”的叙事，因为现实系统里**几乎看不到**真正持续指数增长。
+ 通常你看到所谓**指数级（exponential）****的上升，多半是系统****投入（input）****或****产出（output）****的增加，并不一定是你真正****关心的指标**在增加。
+ **产出**（重大发现的**规模**与**进展速度**），我并不确信今天的科学比**100年前**更快。尽管那时从事**物理**、**化学**的人**少得多**。
+ 他们的发现**影响力更大**。部分原因是他们能去够**低垂的果实（low-hanging fruits）**，也有更多自由去做**尚未被解决**的重大问题。
+ 即便科学在**消耗指数级更多的资源**，也不代表科学在**指数级前进**。
+ **计算效率（compute efficiency）****并非可有可无的“附加功能”，而是****智能定义**的一部分。智能就是**用更少做更多（doing more with less）**，就是**充分利用资源**——这就是智能：**数据效率（data efficiency）****与****计算效率（compute efficiency）**。
+ 智能更像是：在**注意力有限**的前提下，只看**少数关键**，就能**迅速**找到**最优走法**

# 20250812  "I've updated my AGI timeline" | Francois Chollet + Dwarkesh Patel（上）
+ [https://www.youtube.com/watch?v=1if6XbzD5Yg](https://www.youtube.com/watch?v=1if6XbzD5Yg)
+ 里程碑之间**可能会有很大的滞后**
    - **语言模型**在 **2018–2019** 年就**大致**以现在的形式被**发明**了；但要把这样的系统**真正构建、测试**出来，并**证明在现实世界有用**，直到 **2022 年底**才实现。
    - 今天我们仍处在**部署阶段**——离把这项技术**部署到它能解决的每一种问题**还**远远没有结束**。
+ **AGI** 很可能会遵循同样的**路径模板**：在接下来**一两年**内，会有团队开始着手**解决方案的内核**（**正确的思路**）；然后再要**两三年**才能真正把它**做出来**；而要**改变世界**，恐怕还得**五年以上、十年以上**。
+ **快速获得技能**的能力，也就是**原始智力（raw intelligence）**——我认为模型这方面**做得很好**；但还有另一个**缺失点**，去年我没想到：它们**在岗学习**（边做边学）的能力。
+ 一个很好的例子是**in-context learning**：它似乎具备**类人**的能力，不仅能利用上下文中的**文字**，还能**抓住你的风格**，并对你的**需求**形成**丰富把握**——而且能**持续三到六个月**。
+ 它们在**写代码**上效果很好，因为有一个**外部脚手架**——也就是**codebase**（代码库）——它**以语言为基础**，可以被随时**调用**；但多数工作并没有这种**外部的、预先存在**的**记忆**，不像代码库那样。
+ **context rot**（**上下文腐坏**）：当你不得不**压缩**所谓“**cloud code**”时，长时间会话后再让它**再次压缩**，它就会**遗忘**你们先前**好不容易**想出的**创新**点。

# 20250810 The Future of Evals - Ankur Goyal, Braintrust
+ [https://www.youtube.com/watch?v=MC55hdWLq4o](https://www.youtube.com/watch?v=MC55hdWLq4o)
+ 一个在 **Brain Trust** 注册的平均组织每天几乎会运行 13 个 **evals**；我们有些客户每天运行的 **evals** 超过 3,000 个
+ 一些最前沿的公司每天在这个产品里会花超过两小时，逐一处理他们的 **evals**。
+ **Claude 4** 带来了真正的突破时刻，它的表现几乎比之前的领先模型好六倍。
+ **Loop** 在 **Brain Trust** 内部运行，能自动优化你的 **prompts**，一直扩展到非常复杂的 **agents**。
+ data sets + scorers + Prompt = Evals

# 20250809 GPT-5 Fails. AGI Cancelled. It's all over...
+ [https://www.youtube.com/watch?v=tL8CENSCd0w](https://www.youtube.com/watch?v=tL8CENSCd0w)
+ **Gary Marcus** 表示 **GPT5** 非常令人失望。其中很多只是炒作和营销。这不是通往 **AGI**（通用人工智能）的道路。
+ 们需要明白的一个重大问题是，**GPT5** 并不是单一模型。
+ **Matt Schumer** 指出，很多**不佳体验**来自把 **GPT5** 放进**尚未优化**的**agent harness**（运行框架/外壳） 里。
+ 若必须靠**纯文字思考**推出来，质量可能就**没那么好**。凡是能**默认转为写代码**来完成的任务，表现都会**更好**。
+ **GPT5** 的强项是**遵循指令（instruction following）**：理解你的**意图**并转化为**产出**；它也擅长**调用工具（tool calling）**，甚至用代码**自建工具**。
+ 在 **GPT5** 上，这已扩展到**中/长时程**任务——原本可能需要**人类实习生**花上**几小时**。
+ 有一些**趋缓（plateauing）**——像是**S 曲线**：先是**动能大涨**，现在**略有走平**。
+ **自动切换器（auto switcher）有问题——大半天都停摆（out of commission）**——所以“**GBT 5**”（应为 **GPT5**）看起来**变笨**了。

# 20250808  Prompting 101（下）
+ [https://www.youtube.com/watch?v=UjboGsztHd8](https://www.youtube.com/watch?v=UjboGsztHd8)
+ Claude 因为我们提供的额外上下文而变得更加自信
+ 你可以直接将一张图片进行 Base64 编码，并把它作为数据的一部分传入示例中。
+ 提供例子：
    - 示例充当具体的模板，能让 Claude 更容易理解并复现你想要的输出。
    - 在需要保持一致格式、使用特定术语或遵循行业标准的任务中，这一点尤为重要。
    - 与其用文字把所有细微之处都描述清楚，不如直接给 Claude 看一两个你期望的输出示例，往往更高效。
    - 相关性、多样性、数量（至少 3–5 个）。
+ 减少幻觉的几种方式：
    - 让 Claude 在不知道的时候说“我不知道”。
    - 告诉 Claude 只有在它对自己的回答非常有信心时才作答。
    - 让 Claude 在回答前先思考。
    - 请 Claude 从长文档中找到相关引用，然后用这些引用来回答。
+ 预填 Claude 的回复
    - 在“Assistant（助手）”字段/角色中先写好文本，用来预填 Claude 的回复。Claude 会从你停下的地方继续写。
    - 这样能让你：
        * 引导 Claude 的行为或回答
        * 对输出格式拥有更强的控制权
+ extend thinging 的缺点
    - 思考过程中可能需要“重新发明轮子”，这会导致更高的 token 消耗
    - 由于思考需要温度（temperature）设为 1，有时可复现性会较差

# 20250807  Prompting 101（上）
+ [https://www.youtube.com/watch?v=ysPbXH0LpIE](https://www.youtube.com/watch?v=ysPbXH0LpIE)
+ 提示工程在许多方面是一种高度迭代的、经验型的学科
+ 最后，我们通常建议重复强调一些对Claude理解任务特别重要的信息。也就是跟Claude回顾信息，强调一些特别重要的内容，然后告诉Claude：“好了，现在你可以开始工作了。”
+ 提示词结构：
    - Task context
    - Tone context
    - Background data, documents, and images
    - Detailed task description & rules
    - Examples
    - Conversation history
    - Immediate task description or request
    - Thinking step by step / take a deep breath
    - Output formatting
    - Prefilled response (if any)
+ 如何组织信息：
    - **Claude** 非常喜欢结构和条理，因此我们建议在你的提示里遵循一种标准结构。无序的结构难以理解
    - 使用类似XML标签的分隔符进行组织
    - Claude能理解各种类型的分隔符，但推荐使用XML，因为其边界明确且节省token

# 20250806 OpenAI Just Broke The Industry
+ [https://www.youtube.com/watch?v=NyW7EDFmWl4](https://www.youtube.com/watch?v=NyW7EDFmWl4)
+ GPT-OSS 1200亿参数模型，Codeforces 编程比赛的成绩，同于带工具的O3模型，以及带工具的O4 mini模型
+ 这是个重大举措。由于我们还在等待 GPT-5 的发布，我认为可以合理地说 GPT-5 将进入下一个级别。
+ OpenAI 正在使用的一些“秘方”级强化学习技术，其中一个特别重要的就是 **universal verifier**（通用验证器）。这个技术可能类似于 **proverifier**，这是 OpenAI 曾发表过的一篇论文。
+ 这个开源的1200亿参数模型在核心推理基准测试上几乎达到了与 OpenAI O4 Mini 相当的性能，而且能在单张80GB显存的 GPU 上高效运行，这简直不可思议。
+ 当这些模型经过对抗式微调（adversarial fine-tuning）后，其表现出的风险略高于 DeepSeek 模型。最近的 Kimmy 模型和 Quen-3 模型表现出了类似的风险潜力。
+ 他们对数据进行了分词（tokenize）处理，并且今天还将这个分词器（tokenizer）也开源了。
+ 这些模型的后续训练过程类似于 O4 Mini，包括监督式微调阶段和高性能多处理器（high-MP）计算强化学习阶段。
+ 这些模型还支持不同程度的推理强度——低、中、高三种级别，类似于 API 中的 O 系列模型。开发者可以通过在系统消息中简单的一句话轻松设置推理强度。
+ 就今天来说，这几乎抹平了目前最顶尖的私有闭源模型与最顶尖的开源模型之间的差距。
+ 在人类最终考试（humanity's last exam）基准测试上，差距较大。较大的开源模型得分为19，而 O3 模型得分接近25。
+ OpenAI 警告称，有时候惩罚模型的“坏想法”并不能阻止不良行为，反而只会让模型更好地隐藏真实意图。

# 20250803 Vibe coding in prod
+ [https://www.youtube.com/watch?v=fHWFF_pnqDk&t=302s](https://www.youtube.com/watch?v=fHWFF_pnqDk&t=302s)
+ 当你与AI模型保持着紧密的反馈循环时，这并不是真正的“vibe coding”。
+ vibe coding最关键的一点是，彻底忘记代码的存在
+ 而“vibe coding”的积极一面往往都是一些风险较低的事情。
+ AI能够完成的任务长度每7个月就会翻一倍。目前我们能够达到的任务长度大约是一小时
+ 在某个阶段，你将必须处理足够大的系统，而到那时你不得不开始信任整个系统。
+ 我认为未来几年我给整个软件行业的挑战，就是我们如何安全地在生产环境中进行“vibe coding”？
+ 我们会忘记代码的存在，但绝不会忘记产品本身的存在。
+ 不懂具体实现细节却又要管理的情况，其实和人类文明一样古老。就像我们作为软件工程师一样，逐渐放弃了对底层汇编代码等细节的深入了解。
+ 在确保安全和负责任的同时做到这一点的方法，就是找到一个抽象层，即便不了解底层实现，也可以对其进行验证。
+ tech debt（技术债务），是极少数只能靠自身具备底层实现的专业知识才能有效验证的领域之一。
+ 我们必须非常聪明、有针对性地，清楚地知道在哪些地方可以充分利用自动化编码。
+ 当我和**Claude**一起开发功能时，我通常会花15到20分钟把指导信息集中成一个提示（prompt），然后让**Claude**自行发挥。这15到20分钟并不是单纯我手动写提示，而经常是与**Claude**进行单独的交流、来回沟通。
+ 考虑可验证性，即如何在不亲自阅读代码的情况下确认变更是正确的。
+ vibe coding的总结建议：
    - 成为**Claude**的产品经理，不要问**Claude**能为你做什么，而要问你能为**Claude**做些什么。
    - 把你的vibe coding集中在叶子节点，而非核心架构和底层系统，这样即使产生技术债务，也能被有效控制，不会影响关键部分。
    - 考虑可验证性，即如何在不亲自阅读代码的情况下确认变更是正确的。
    - 最后，请记住指数级增长的趋势。
+ 我们的模型在没有被过度约束的情况下表现最佳。因此，我不会花太多精力去制定非常严格的格式或类似的东西。
+ 指数级增长的真正含义不仅是它们会持续改善，而是它们改善的速度会远超我们的想象。
+ 我喜欢在 Claude 到达一个较好的暂停点时进行压缩或直接开启新的会话。就像人类程序员那样，达到一个合适的阶段就暂停一下，休息一下，也许吃个午餐再回来。
+ 我通常会用 Claude code 开始编写代码，然后再用 Cursor 进行修补完善。

# 20250802 Claude Code best practices
+ [https://www.youtube.com/watch?v=gv0WHhKelSE](https://www.youtube.com/watch?v=gv0WHhKelSE)
+ **applied AI** 的团队，使命就是帮助客户和合作伙伴在 **Claude** 平台之上构建出色的产品和功能。
+ **Claude Code** 团队内部其实搭建了一个排行榜，记录所有 **Anthropic** 员工使用该工具的情况。
+ **Anthropic**，我们始终遵循的原则是：“选择简单有效的方法。”对 **Cloud Code** 而言，这意味着它是我们所称的“非常纯粹的智能体（agent）”。**Cloud Code** 的本质：它就是一些强大就像是那种所有事情都在终端（terminal）里完成的同事。
+ 在 **Anthropic**，我们说到智能体（agents）时，真正指的是一系列指令（instructions）、一些强大的工具，让模型不断地循环执行，直至模型自主认为任务完成。
+ Cloud Code不使用任何形式的索引。是通过“智能体式搜索”（agentic search）实现的，使用的工具和我们人类常用的类似，比如 **glob**、**grep**
+ 还有一点我认为被大家低估了，就是你可以把 **Cloud Code** 当成一个思考伙伴（thought partner），而不只是急于直接开始工作。
+ 在我们 **Cloud Code** 团队的代码库中，我们的单元测试覆盖率异常高。这是因为 **Cloud Code** 使得编写单元测试变得极其简单和直观。
+ 把 **Cloud Code** 提供给客户并与他们交流时，有一点我们并未预料到：很多客户或潜在客户表示，“我们一直在推迟对大型代码库的迁移。”使用 **Cloud Code** 这样的工具可以让类似项目变得更容易消化和实现。
+ **Claude** 极其擅长终端操作，这意味着它也非常擅长各种命令行工具（CLI）。
+ 最佳实践：
    - 环境安装和配置
        * 使用 claude.md
            + 当我们启动**claw**时，如果当前目录中存在**claw.md**文件，它会被直接放入上下文中。
            + 你可以将**cloud.md**文件放在不同位置，比如放在项目中并提交（check in），这样你的所有队友都可以共享。
        * 调整权限管理
            + 自动接受模式（autoaccept mode），当你使用cloud code时，只需按下Shift-Tab键，Claude就会自动开始执行任务。
            + 对于特定的bash命令，你可以设置为始终自动允许。
        * 命令行集成
            + 最大化利用**cloud code**的一点，就是要记住它在终端（terminal）中表现非常出色
            + 选择CLI工具或安装本地软件并连接MCP服务器之间时，优先使用知名且文档完善的CLI工具。
        * 上下文管理（context management）
            + 可以执行`/cle`命令重新开始，这将清除所有内容，除了**claude.md**文件。
            + 执行`/compact`命令，这相当于插入一条用户消息：“我需要总结一下我们做过的所有事情，然后交给另一个开发人员继续工作”。
    - Effective workflows
        * planning and to-dos
            + 如果你一直关注这个待办清单，发现有任何奇怪或不合理的地方，你可以按下Escape键并告诉Claude：“嘿，我们调整一下待办清单吧，我觉得你的方向错了。”
        * smart vibe coding
            + 建议采用测试驱动开发（TDD）
            + 使用截图（screenshots）来指导和调试（debug）
    - 高级技巧
        * 我知道在Anthropic以及一些客户那里，有人同时运行4个Claude实例
        * 隐藏功能，知道的人不多，按两次Escape键，可以回退到对话中之前的位置
        * 通过接口调用使用 claude code , 已经在 github actions 上很好的实践
        * 我们发布更新的速度非常快，你要时刻掌握最新动态
        * tool call 可以deep think 了，我鼓励大家在做任务和解决 bug 时，加入一个 **think hard** 命令
        * IDE 插件已经可以集成感知当前文件和选中文本的能力了
        * 我们修改了设置，使得不会自动读取所有子目录的 cloud MD 文件，所以你可以给他提示去读子目录的
        * 我们有一个新功能，可以在 cloud MD 文件中使用 @ 引用其他文件
        * 你可能需要所有智能体把信息写到一个共享的 markdown 文件里，这样它们就可以相互沟通并同步状态。

# 20250801  "AlphaGo Moment" For Self Improving AI... can this be real?（上）
+ [https://www.youtube.com/watch?v=QGeql15rcLo](https://www.youtube.com/watch?v=QGeql15rcLo)
+ 人工智能研究中最大的问题就是人类本身，我们就是那个拖慢一切进展的因素。
+ 他们正试图让AI改进自身的架构，寻找从零开始更好地构建自己的方法。他们正在引入一种从自动优化到自动创新的范式转变。
+ 它提出了1773种用于改善人工智能大脑中神经架构这一特定过程的构想，进行了实验来区分有效与无效的方法，最终得到了106种业界领先（即截至当时最佳）的新方法，在本例中即为线性注意力架构。
+ 他们首次建立了科学发现自身的经验缩放定律。
+ 大部分的突破性进展来自于特定的几种方法，这些方法并非随机出现，也非随机分布的。
+ 非最优模型，也就是那些未能取得最佳结果的模型，表现出更严重的长尾问题。

