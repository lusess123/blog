# 20250807  Prompting 101（上）
+ [https://www.youtube.com/watch?v=ysPbXH0LpIE](https://www.youtube.com/watch?v=ysPbXH0LpIE)
+ 提示工程在许多方面是一种高度迭代的、经验型的学科
+ 最后，我们通常建议重复强调一些对Claude理解任务特别重要的信息。也就是跟Claude回顾信息，强调一些特别重要的内容，然后告诉Claude：“好了，现在你可以开始工作了。”
+ 提示词结构：
    - Task context
    - Tone context
    - Background data, documents, and images
    - Detailed task description & rules
    - Examples
    - Conversation history
    - Immediate task description or request
    - Thinking step by step / take a deep breath
    - Output formatting
    - Prefilled response (if any)
+ 如何组织信息：
    - **Claude** 非常喜欢结构和条理，因此我们建议在你的提示里遵循一种标准结构。无序的结构难以理解
    - 使用类似XML标签的分隔符进行组织
    - Claude能理解各种类型的分隔符，但推荐使用XML，因为其边界明确且节省token

# 20250806 OpenAI Just Broke The Industry
+ [https://www.youtube.com/watch?v=NyW7EDFmWl4](https://www.youtube.com/watch?v=NyW7EDFmWl4)
+ GPT-OSS 1200亿参数模型，Codeforces 编程比赛的成绩，同于带工具的O3模型，以及带工具的O4 mini模型
+ 这是个重大举措。由于我们还在等待 GPT-5 的发布，我认为可以合理地说 GPT-5 将进入下一个级别。
+ OpenAI 正在使用的一些“秘方”级强化学习技术，其中一个特别重要的就是 **universal verifier**（通用验证器）。这个技术可能类似于 **proverifier**，这是 OpenAI 曾发表过的一篇论文。
+ 这个开源的1200亿参数模型在核心推理基准测试上几乎达到了与 OpenAI O4 Mini 相当的性能，而且能在单张80GB显存的 GPU 上高效运行，这简直不可思议。
+ 当这些模型经过对抗式微调（adversarial fine-tuning）后，其表现出的风险略高于 DeepSeek 模型。最近的 Kimmy 模型和 Quen-3 模型表现出了类似的风险潜力。
+ 他们对数据进行了分词（tokenize）处理，并且今天还将这个分词器（tokenizer）也开源了。
+ 这些模型的后续训练过程类似于 O4 Mini，包括监督式微调阶段和高性能多处理器（high-MP）计算强化学习阶段。
+ 这些模型还支持不同程度的推理强度——低、中、高三种级别，类似于 API 中的 O 系列模型。开发者可以通过在系统消息中简单的一句话轻松设置推理强度。
+ 就今天来说，这几乎抹平了目前最顶尖的私有闭源模型与最顶尖的开源模型之间的差距。
+ 在人类最终考试（humanity's last exam）基准测试上，差距较大。较大的开源模型得分为19，而 O3 模型得分接近25。
+ OpenAI 警告称，有时候惩罚模型的“坏想法”并不能阻止不良行为，反而只会让模型更好地隐藏真实意图。

# 20250803 Vibe coding in prod
+ [https://www.youtube.com/watch?v=fHWFF_pnqDk&t=302s](https://www.youtube.com/watch?v=fHWFF_pnqDk&t=302s)
+ 当你与AI模型保持着紧密的反馈循环时，这并不是真正的“vibe coding”。
+ vibe coding最关键的一点是，彻底忘记代码的存在
+ 而“vibe coding”的积极一面往往都是一些风险较低的事情。
+ AI能够完成的任务长度每7个月就会翻一倍。目前我们能够达到的任务长度大约是一小时
+ 在某个阶段，你将必须处理足够大的系统，而到那时你不得不开始信任整个系统。
+ 我认为未来几年我给整个软件行业的挑战，就是我们如何安全地在生产环境中进行“vibe coding”？
+ 我们会忘记代码的存在，但绝不会忘记产品本身的存在。
+ 不懂具体实现细节却又要管理的情况，其实和人类文明一样古老。就像我们作为软件工程师一样，逐渐放弃了对底层汇编代码等细节的深入了解。
+ 在确保安全和负责任的同时做到这一点的方法，就是找到一个抽象层，即便不了解底层实现，也可以对其进行验证。
+ tech debt（技术债务），是极少数只能靠自身具备底层实现的专业知识才能有效验证的领域之一。
+ 我们必须非常聪明、有针对性地，清楚地知道在哪些地方可以充分利用自动化编码。
+ 当我和**Claude**一起开发功能时，我通常会花15到20分钟把指导信息集中成一个提示（prompt），然后让**Claude**自行发挥。这15到20分钟并不是单纯我手动写提示，而经常是与**Claude**进行单独的交流、来回沟通。
+ 考虑可验证性，即如何在不亲自阅读代码的情况下确认变更是正确的。
+ vibe coding的总结建议：
    - 成为**Claude**的产品经理，不要问**Claude**能为你做什么，而要问你能为**Claude**做些什么。
    - 把你的vibe coding集中在叶子节点，而非核心架构和底层系统，这样即使产生技术债务，也能被有效控制，不会影响关键部分。
    - 考虑可验证性，即如何在不亲自阅读代码的情况下确认变更是正确的。
    - 最后，请记住指数级增长的趋势。
+ 我们的模型在没有被过度约束的情况下表现最佳。因此，我不会花太多精力去制定非常严格的格式或类似的东西。
+ 指数级增长的真正含义不仅是它们会持续改善，而是它们改善的速度会远超我们的想象。
+ 我喜欢在 Claude 到达一个较好的暂停点时进行压缩或直接开启新的会话。就像人类程序员那样，达到一个合适的阶段就暂停一下，休息一下，也许吃个午餐再回来。
+ 我通常会用 Claude code 开始编写代码，然后再用 Cursor 进行修补完善。

# 20250802 Claude Code best practices
+ [https://www.youtube.com/watch?v=gv0WHhKelSE](https://www.youtube.com/watch?v=gv0WHhKelSE)
+ **applied AI** 的团队，使命就是帮助客户和合作伙伴在 **Claude** 平台之上构建出色的产品和功能。
+ **Claude Code** 团队内部其实搭建了一个排行榜，记录所有 **Anthropic** 员工使用该工具的情况。
+ **Anthropic**，我们始终遵循的原则是：“选择简单有效的方法。”对 **Cloud Code** 而言，这意味着它是我们所称的“非常纯粹的智能体（agent）”。**Cloud Code** 的本质：它就是一些强大就像是那种所有事情都在终端（terminal）里完成的同事。
+ 在 **Anthropic**，我们说到智能体（agents）时，真正指的是一系列指令（instructions）、一些强大的工具，让模型不断地循环执行，直至模型自主认为任务完成。
+ Cloud Code不使用任何形式的索引。是通过“智能体式搜索”（agentic search）实现的，使用的工具和我们人类常用的类似，比如 **glob**、**grep**
+ 还有一点我认为被大家低估了，就是你可以把 **Cloud Code** 当成一个思考伙伴（thought partner），而不只是急于直接开始工作。
+ 在我们 **Cloud Code** 团队的代码库中，我们的单元测试覆盖率异常高。这是因为 **Cloud Code** 使得编写单元测试变得极其简单和直观。
+ 把 **Cloud Code** 提供给客户并与他们交流时，有一点我们并未预料到：很多客户或潜在客户表示，“我们一直在推迟对大型代码库的迁移。”使用 **Cloud Code** 这样的工具可以让类似项目变得更容易消化和实现。
+ **Claude** 极其擅长终端操作，这意味着它也非常擅长各种命令行工具（CLI）。
+ 最佳实践：
    - 环境安装和配置
        * 使用 claude.md
            + 当我们启动**claw**时，如果当前目录中存在**claw.md**文件，它会被直接放入上下文中。
            + 你可以将**cloud.md**文件放在不同位置，比如放在项目中并提交（check in），这样你的所有队友都可以共享。
        * 调整权限管理
            + 自动接受模式（autoaccept mode），当你使用cloud code时，只需按下Shift-Tab键，Claude就会自动开始执行任务。
            + 对于特定的bash命令，你可以设置为始终自动允许。
        * 命令行集成
            + 最大化利用**cloud code**的一点，就是要记住它在终端（terminal）中表现非常出色
            + 选择CLI工具或安装本地软件并连接MCP服务器之间时，优先使用知名且文档完善的CLI工具。
        * 上下文管理（context management）
            + 可以执行`/cle`命令重新开始，这将清除所有内容，除了**claude.md**文件。
            + 执行`/compact`命令，这相当于插入一条用户消息：“我需要总结一下我们做过的所有事情，然后交给另一个开发人员继续工作”。
    - Effective workflows
        * planning and to-dos
            + 如果你一直关注这个待办清单，发现有任何奇怪或不合理的地方，你可以按下Escape键并告诉Claude：“嘿，我们调整一下待办清单吧，我觉得你的方向错了。”
        * smart vibe coding
            + 建议采用测试驱动开发（TDD）
            + 使用截图（screenshots）来指导和调试（debug）
    - 高级技巧
        * 我知道在Anthropic以及一些客户那里，有人同时运行4个Claude实例
        * 隐藏功能，知道的人不多，按两次Escape键，可以回退到对话中之前的位置
        * 通过接口调用使用 claude code , 已经在 github actions 上很好的实践
        * 我们发布更新的速度非常快，你要时刻掌握最新动态
        * tool call 可以deep think 了，我鼓励大家在做任务和解决 bug 时，加入一个 **think hard** 命令
        * IDE 插件已经可以集成感知当前文件和选中文本的能力了
        * 我们修改了设置，使得不会自动读取所有子目录的 cloud MD 文件，所以你可以给他提示去读子目录的
        * 我们有一个新功能，可以在 cloud MD 文件中使用 @ 引用其他文件
        * 你可能需要所有智能体把信息写到一个共享的 markdown 文件里，这样它们就可以相互沟通并同步状态。

# 20250801  "AlphaGo Moment" For Self Improving AI... can this be real?（上）
+ [https://www.youtube.com/watch?v=QGeql15rcLo](https://www.youtube.com/watch?v=QGeql15rcLo)
+ 人工智能研究中最大的问题就是人类本身，我们就是那个拖慢一切进展的因素。
+ 他们正试图让AI改进自身的架构，寻找从零开始更好地构建自己的方法。他们正在引入一种从自动优化到自动创新的范式转变。
+ 它提出了1773种用于改善人工智能大脑中神经架构这一特定过程的构想，进行了实验来区分有效与无效的方法，最终得到了106种业界领先（即截至当时最佳）的新方法，在本例中即为线性注意力架构。
+ 他们首次建立了科学发现自身的经验缩放定律。
+ 大部分的突破性进展来自于特定的几种方法，这些方法并非随机出现，也非随机分布的。
+ 非最优模型，也就是那些未能取得最佳结果的模型，表现出更严重的长尾问题。

