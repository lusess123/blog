# 20251014  OpenAI's new AI chip
+ [https://www.youtube.com/watch?v=9btw343FHb4](https://www.youtube.com/watch?v=9btw343FHb4)
+ **OpenAI**与**Broadcom**宣布达成战略合作，将部署**10 gigawatts**（10吉瓦）规模、由**OpenAI**设计的**AI accelerators**（**AI**加速器
+ 从很多角度看现在的基础设施建设者，你会说：这是人类历史上规模最大的联合工业项目。我们正在定义文明的下一代“操作系统”。‘
+ 当我们意识到全球对产能——尤其是**推理产能（inference capacity）**——的需求之大时，我们开始思考：能否做一颗**专门**面向这种高度特定负载的芯片？
+ 让我如此兴奋的原因之一是：通过**全栈优化**，我们能获得巨大的效率提升；由此带来更好的性能、更快的模型、更低成本的模型
+ 我们甚至把自家的模型用在这颗芯片的设计上，**提前了进度（pull in the schedule）**，并实现了**大幅面积缩减**
+ 把人类已经优化过的部件拿来，再**倾注算力（compute）**进去，模型就能给出它自己的优化方案。
+ 有一批即将出现的技术——其中一些由我们推动，例如**Snowcap**——承诺**能效提升100倍**：把**1 GW**数据中心的能力压缩到**10 MW**能耗实现。不仅是**Snowcap**，整套**颠覆性**技术将在本十年后半段开始落地。

# 20251011 Building with MCP and the Claude API
+ [https://www.youtube.com/watch?v=aZLr962R6Ag](https://www.youtube.com/watch?v=aZLr962R6Ag)
+ “实现一次，处处配置”。**Claude Code** 与 **Claude.ai** 上的网页搜索功能保持一致。也就是在有大量应用需要类似连接时，打造“通用兼容性”。
+ 它可能是“史上增长最快的开源协议”。— 哇。— 增长相当“平流层级”的快，需求极其旺盛……
+ “恍然大悟”的转折是支持远程 **MCP**：过去一切都得用户本地跑，提供方无法托管。原生支持远程托管后，配置成本大幅下降，用户可快速上手。
+ **Context7**：通过抓取并维护最新文档（如 **Next.js**、我们的 **API**），弥补模型的知识截止；配置一次，**Claude** 即可获取最新内容。
+ 喜欢把 **Playwright** 当 **MCP** 服务器，让 **Claude** 能像用户一样点击操作浏览器。它原本能读 **CSS/HTML**，但不能“看”页面；**Playwright** 补上了这点。
+ 每次请求最终都会拼成“一条提示词”——连 **JSON** 的描述字符串也会进入发给 **Claude** 的最终提示。
+ 反模式：把请求塞满工具/服务器——既费 **token** 又让模型混淆（如 **Linear** 与 **Asana** 都有 _get project status_）。要“确定性”，只保留当下相关的；旧话题应裁剪。
+ 不存在“神奇上限”：上下文窗口有限；每个服务器都会带来函数定义吞噬 **token**；更少但更相关的工具通常更好。
+ **MCP** 接口设计不同于传统 **API**。在 **LLM** 语境下，用少量工具（如“**get info**”）+ 良好的自然语言描述，可替代一堆细粒度端点；更友好也更高效。
+ 会有“魔法感”：增加服务器的组合会出现意料之外的涌现特性。
+ 我们做了一个知识图谱服务器，只有两个工具（“创建记忆”“连接记忆”），界面极简。

# 20251007 Claude Coded: Sonnet 4.5, Claude Code 2.0, and more.
+ [https://www.youtube.com/watch?v=Yct0MvNtdfU](https://www.youtube.com/watch?v=Yct0MvNtdfU)
+ **Claudson 4.5** 已经在所有你能获取 **Claude** 的地方上线了，而且它是当今世界上最强的代码模型
    - SweetBench** 基准上处于领先地位，经过验证的得分为 77.2%。
    - 在复杂任务上能持续专注超过 30 个小时。
    - **OS World** 测试上——这是一项评估 AI 能否像人类一样实际使用电脑的测试——**Claude** 的成绩从 4 个月前的 42% 跃升到如今的 61% 以上。
    - VsCode 插件，你通过专用的侧边栏面板实时查看 **Claude** 所做的更改，该面板能以内联差异的形式展示修改内容。
    - 一个全新的 **checkpoints** 功能，它让你可以放心地运行大型任务，并在需要时瞬间回滚到先前状态。
+ **Context editing** 会在接近 Token 上限时，自动清理上下文窗口中陈旧的工具调用与返回结果
+ **memory tool** 允许 **Claude** 通过基于文件的系统，将信息存储在上下文窗口之外并进行查阅。
+ **Cloud Agent SDK**（由原 **Cloud Code SDK** 更名而来）向你开放与 **Cloud Code** 同等的核心工具、上下文管理系统与权限框架，帮助你构建自有智能体。

# 20251006 they are lying to you about AI development 2
+ 2026 年年中，模型将能**自主**连续工作**整整一个工作日（8 小时）**
+ **在 2026 年底之前**，至少会有一种模型在**多个行业**达到人类专家的表现。而到 2027 年底，模型将在许多任务上**经常**胜过专家。
+ whistleblower：吹哨人（揭露机构不当行为者）
+ **Goodhart’s law**（古德哈特定律）：当**指标**变成**目标**而非参考时，麻烦就来了。评测基准在大家开始**对着考点刷分**之前还算可信；一旦“高分”成了目的，体系就会失真。
+ “**心智的自行车**”（常归因于 **Steve Jobs**）：人类本身并不快，但有了**自行车**效率奇高；计算机是**心智的自行车**——我们创造的工具让我们更强。
+ “**AI 不是工具，而是竞争者**”AI 越强，人类越不值钱
+ 为什么**计算机**曾加剧不平等，而“**Chad GBT**（指 **ChatGPT**）”似乎在改善？90 年代计算机扩大了**工资差距**；而现在不少研究发现 **AI** 对**弱势/困难群体**的帮助**大于**对专家的帮助。
    - 想想你用 **ChatGPT** 的方式：**迭代**、**打磨**、**发现改进机会**。
    - 不是一问了之，而是来回对话半小时，直到确认答案**正确**。
+ 研究者把**认知工作**拆成三部分：**执行**、**机会判断**、**收益判断**。
+ **AI** 在**执行**上越强，你的**判断力**就越有价值。这是**乘法效应**，而非**替代效应**
+ 数学证明了一个**反直觉**结论：工具越强，会**扩大**能**发现机会**者与不能者之间的差距。
+ 为什么 **AI** 眼下看起来在**走向不平等**？因为我们仍在**第一阶段**——它主要在**弥补技能差异**。**处境艰难的员工**获得了巨大的提升；而**专家**本就擅长**执行**
+ **ADHD** 人群从 **ChatGPT** 等聊天机器人中**受益显著**。这类工具帮助他们**弥补因 ADHD 形成的能力缺口**，在多方面**跨越障碍**，并提升他们的**可及性/可达性**。
+ **第二阶段**将要到来：当**执行几乎免费**（人人能设计/写代码/写作）时，**唯一关键**的是*_判断力_
+ **AI 越强，完全自动化反而**更**不可能**。原因：**自动化系统**的判断是**固定的**，**难以适应**。**实时调节判断**是**人类独有**，工具越强，这点越**稀缺且增值**。
+ **AI** 越强，**决策权**应从“擅长**执行**的人”转向“擅长**看见机会**的人”。
+ 能**看见可改进之处**就是你的**护城河**。研究者称之为 **opportunity judgment（机会判断）**，它将成为**最有价值**的经济技能。
+ 单说“**AI 取代岗位**”**偏题**了：他们衡量的是**当下**的工作，而 **AI** 正在**改变“工作”的定义**。
+ 真正的问题不是“**AI 会不会替代我**”，而是“**我是否在培养驾驶更强大‘自行车’的判断力**？”——而这些“车”**很快会更快**。

# 20251005 they are lying to you about AI development
+ [https://www.youtube.com/watch?v=6Iahem_Ihr8](https://www.youtube.com/watch?v=6Iahem_Ihr8)
+ 关于AI整体走向，有些常被忽略的事实——它要比许多人预期的更“细腻复杂”。
+ 在**黑箱技术**下，其极限是**双重指数级（doubly exponential）**。而他们是借助 **Chad GPT**——确切说是 **GPT5**——完成关键步骤的。
+ **2025 年 9 月**，他认为 **AI** 已经能涉足“在人类智识活动中最具人类特质”的一项：**证明量子复杂度类之间的 oracle separation**。**GPT5** 也许写不完整篇论文，但它能**帮你解套卡点**——这是一个绝佳“甜蜜点（sweet spot）”。
+ 能“补上你**理应**想到的那点洞见”的 **AI** 是**大事**：它加速的是**发现过程本身**，而不只是 **LaTeX** 排版或参考文献。本文只是“成千上万案例中的一个缩影”。——事实是，聊天模型正帮助研究者推动**新的科学发现**。
+ **Google Deep Mind** 的 **Alpha Evolve** 展示了类似案例：改进 **Gemini** 训练流程，提高数据中心效率，节省数百万成本；并在数周内优化硬件规格，对比人类工程师可能需要六个月。
+ 之所以很多人“感觉不出模型在进步”，是因为模型的智力在某个时刻已经**超过**了**X/Twitter** 的平均用户。我这里转述可能不够准确，但核心是：仅凭聊天感受不出提升，并**不意味着**模型没有提升。像 **Julian**、**Scott Aronson** 这样的人**能**察觉到差异。
+ **Meter Research**。他们**衡量**模型完成**长任务**的能力，发现模型**可完成的任务时长**大约**每 7 个月翻一倍**。
+ **“每 7 个月翻倍”是在追溯到 2020 年之前**时的趋势；若只看 **2024 年以来**（红线），斜率更陡——**每 4 个月翻倍**。

# 20251004  Building the future of agents with Claude
+ [https://www.youtube.com/watch?v=XuvKFsktX0Q](https://www.youtube.com/watch?v=XuvKFsktX0Q)
+ Claude Developer Platform ，以前叫 **Anthropic API**
+ “智能体”几乎已经成了一个**热词**：现在好像人人都在做“智能体”，而当一个行业术语热到这种程度，**定义**就会变得模糊，仿佛什么都能叫智能体。
+ 在 **Anthropic**，我们更看重的一点是：**模型具备一定自主性**——能自己选择要调用的工具、发起调用、处理结果，并据此决定**下一步**。作为一家**基础研究实验室**，我们更关注模型的**推理过程**及其“如何作出决策”，这也是我们认为**智能体**的关键要素。
+ “**agentic** 的做法”更妙的一点在于：随着模型每隔几个月升级一次、**智能上限**提高，如果采用更**纯粹的智能体范式**，这些服务**会随之变得更好**。相反，若你的工作流里**脚手架（scaffolding）****太多，就等于给模型套上了****边界**；某些情况下没问题，但这样可能**无法充分利用**下一代模型带来的**更高智能**。
+ 围绕模型的**框架**演进很快，用来**编排（orchestrate）****智能体、榨取模型能力。但行业里的共识在于：不少框架****过重**、**意见过强（opinionated）**，于是又有人回到“一个循环就够了”的主张。
+ 我们的立场是：许多场景里**确实是一个循环**，但我们能做的“独门功夫”在于**提供工具与特性**。我们希望提供**适度有观点**但**不至于过重**的框架/工具，避免**挡住**模型本该发挥的能力。
+ 我们称之为**“给模型解开镣铐（unhobble）”**。模型本来就有很多能力；即便是**现世代模型**，其智能仍**未被完全解锁**。只要把**需要的工具**给它，让它**自由使用**，就能获得很好的结果。
+ **智能施用位置**的转移：从**开发者主导**转向**模型自我摸索**。
+ —— 这很令人兴奋：作为开发者，我的创意总有边界、能想到的用例有限；但模型会自己**想办法**把事做成。所以，**“解束缚”模型**真的很棒。
+ **操作层面**，首推 **Claude Code SDK**。我们围绕模型构建了一个**智能体“挽具”（harness）****来驱动那个循环，自动完成****工具调用**与**功能使用**。它最初为**编码场景**而生，但我们很快意识到它其实是一个**通用的智能体“挽具”**。这个 **SDK** 提供了**开箱即用（out-of-the-box）****的方式来****原型化**智能体，你无需亲自搭循环、写工具调用。它构建在 **Messages API** 和前面提到的那些工具之上。
+ 当你把其他一切都移除后，剩下的就是**智能体循环（agentic loop）**，而你真正需要的只是一个**极简**的内核。
+ **在 ****Claude Code SDK**** 之前，大家都在各自实现某种**提示缓存（prompt caching）、**工具调用**与**循环**的管理方案。
+ 能**清晰表述**你对智能体项目的**预期产出**，非常有助于**界定智能体边界/范围**。
+ **SDK** 提供的是一个可部署在任意位置的**智能体循环运行时**。我们把 **SDK** 解锁的能力**上推到“更高阶抽象”**：把**循环**与**工具调用自动化**都**交到你手里**，再据此打磨**开箱即用、可规模化**的**场景化解决方案**。
+ 帮助用户**抬高智能上限**，拿到**最佳结果**。更高阶抽象不仅仅是为了“更容易”，也因为我们**贴近研究与推理（inference）**，能确保我们的**抽象**与**智能体循环**与 **Claude** 的协同**极强**。
+ 随着任务**变长**、工具**增多**，一个持续的大问题是：**长任务的可观测性（observability**。大家都想要好结果，但可能需要**纠偏（steering）**、**提示调优（prompt tuning）****或****重构工具调用**。我们有能力**在平台上逐步提供可观测性**——这是我们的**重点方向**。
+ 我们新增了**上下文管理**能力：在智能体循环里，你可能会发起 **10–100** 次**工具调用**，单次消耗 **100–1000** 个 **token**。我们允许**模型**移除**较早且不再需要**的**工具调用痕迹**。**清理提示（declutter the prompt）** 后，模型往往**更能聚焦**。
+ 我们还加入了**智能体记忆**：人类**重复执行**任务会**越做越好**，因为会总结**启发式**（比如“这个检索用 **Wikipedia** 更好”）。我们给模型一个**记笔记的记忆工具**；当**卡住（stumped）或开始新任务**时，它可以**回看笔记**。

