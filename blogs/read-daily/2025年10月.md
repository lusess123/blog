# 20251016 Building Voice AI Like the Human Brain With Scott Stephenson from Deepgram 下
+ [https://www.youtube.com/watch?v=pmcR9mkI33E](https://www.youtube.com/watch?v=pmcR9mkI33E)
+ 这些系统的工作方式是，确实有某种东西在响应外部世界，这个，你知道的，感知层，发布-订阅的思维方式但同时还有一个内部的实时计算，就像是试图保持机器人存活一样，基本上是一个独立运行的程序。
    - 假如它在行走时有些绊了一下，它会先处理这个问题——“不、不，我得先别摔倒”；但它仍会“听着”外部指令，比如“向左转”等。优先级是：先不摔倒，然后再去左转
    - **voice agents** 也需要构建类似的体系
    - 你会同时收到很多输入，**CRM** 的信息在不断“触发”，诸如此类。这时系统就得想：“等等等等，我得做一个好的对话者，持续把对话接下去；后台进程在运行，我会在合适的时机插话。”
+ 类似 **L1、L2、L3、L4、L5** 这种分级思维方式，对**voice agents** 也很适用。
+ 我们现在有点处在我称之为按顺序串联 **text-to-speech** 和 **speech-to-text** 的阶段；这有点等同于用 **Python** 去控制一个 **servo**（伺服电机）那样的简单控制。
+ 我认为距离 **Boston Dynamics** 那种高级形态，路径其实很短，但我们必须解决许多问题：比如如何真正设计**fallbacks**（降级/兜底）；如何打造支持那种自主程度的**UX**（用户体验）？
+ 在**self-driving**（自动驾驶）里我们见过这样的趋势：先把很多模型**结合**起来；等摸清“什么组合有效”，再把它们**分离**；然后又**结合**、再**分离**，来回摆动。
+ 这种“钟摆式的来回摆动”恰是行业前进之道——既**尽可能捕获信号**，又保持**职责分离**。
+ 这里会反复经历“**融化—凝结**”的过程；你要根据手头的数据、客户需求、新出现的技术、可用 **GPUs**，以及为让模型更好运行而新发现的**knowhow**（诀窍）不断重构。
+ 一切**end‑to‑end** 的最终形态尚待观察
+ 但你无法摆脱**tool use**（工具调用）与**agents**（智能体），所以谈到工具调用时就不存在纯粹的端到端——现实并非如此运作。
+ 大家得接受一个事实：无论如何，到处都会是**hybrid system**（混合式系统）。
+ 问题在于：**何时**、**把什么** 组合在一起；而这由你的约束决定——你需要更快？更好、更准？有更多数据吗？等等。
+ 语音领域很酷的一点是用例极多，因此并不存在唯一正确答案。
+ **turn detection**（轮次检测）会强烈依赖你的场景：不同的**vocal patterns**（发声模式）、言语困难的人群、年长用户……这时通用方案未必好。
+ 实时适合部分场景，却不够可控；而要推动语音能力的边界，没有**tool use** 和多样化用例，很难做到。
+ 我认为未来多数 **AI** 都会是**real time**（比如 10 年后）；而现在**token count** 的大头还在**interactive**（交互式）或**batch**（批处理）模式；语音是对话领域第一个成熟的实时用例。
+ 因此必须发生一次大的转型：让实时做到低时延、高准确。实时与交互/批处理的**tool use** 本质不同：后者倾向“越大越好、参数越多越好，把数据往里**cram**（塞）”。
    - “第一次失败也无所谓——再试一次”的心态与实时完全不同；实时要求“极低时延且**always work**（始终可用）”。
    - 十年后，我们可能会说 80% 的 **AI** 都是实时的：网站实时生成，我的所作所为都由遍在的实时 **AI** 支撑。
+ 我们的 **Nova 3** 模型（以及 **Nova 2** 与更早的 **deep** 模型）本质上都是**batch**（批处理）模型，只是被“挤压改造”去以实时方式工作。
+ 用 **Flux** 会觉得“天啊，完全不同”，因为它是**real‑time‑first** 的范式。许多**transcription**（转写）与 **text‑to‑speech** 模型来自“实时不重要”的旧时代——更偏向音频**post‑processing**（后处理）或为电影/媒体生成音频。
+ 关键在**real‑time factor**：在实时回应人的同时，你转写的速度有多快？看起来相似，实则本质不同。
+ **neuroplex** 的总体路线是：为语音智能体栈的每个子组件加入**multitrack**（多轨）。
    - 在 **speech‑to‑text**（感知部分）里，文本是一条轨，**turn detection** 是另一条，所说**language**（语言）又是一条，再加上一块“**other/asterisk**”，最佳的理解方式是一个**embedding space**（嵌入空间）。
    - 若想传递**完整上下文**，就要摆脱仅限“人类可读”的表示：感知模型要接收上述多轨再加一个随时间变化的开放式**embedding**，并输出这些轨与嵌入。
    - 这如何与 **LLM** 协同？**LMs** 得重写：它们虽然逐**token** 流式生成，但几乎不支持**流式接收**——基本不存在**bidirectional streaming LLM**（双向流式 LLM）。
    - 这听起来可能“烧脑”，而且一度会很乱；就像 **AWS** 早先只有十来个选项，如今多得吓人——似乎会“永远很乱”。它会乱上一阵子，然后又**congeal**（凝聚）起来；大家会说“我需要**streaming‑embedding** 输入，是 128 维还是 256 维？”——我们将学会一套新的**vernacular**（行业术语）。
    - 客户会向所有供应商提出这些要求；要想携带**完整上下文**并实现优秀的**tool use**，整个技术栈都得重审。
    - 下一步：把这些能力注入到**perception / understanding / generation** 各环节。
    - 本质上就是全系统**speech‑to‑speech** 且保持完整上下文，但同时保留清晰的“分界”，人类可在这些离散接口处**检查**、**解释**、**调试**，甚至**施加偏置**；不同于那种完全“黑箱式”的端到端语音到语音……
    - 由对话型模型在后台**orchestrate**（编排），像机器人先处理“绊倒”那样；大约 **80% tokens** 由它承担，必要时再调用离散工具或其他模型。
+ **LLMs** 主要训练于互联网文本，但那并不是人类实际说话的方式。**Notebook LLM** 做得很出色——显然针对特定说话风格做了**tuning**（调优），效果极佳。
+ 你确实可以**风格化**某种说话模式；**podcasting** 的语气与客服通话或谈判完全不同——这对**logistics**（流程/执行组织）也有影响。
+ 仍欠缺一种“**self‑driving** 式”模型，既有**可控性**与**编排**，又能实现高**autonomy**，并具备**failovers**（故障切换）、**redundancy**（冗余）与**reliability**（可靠性）以支撑生产。

# 20251015 Building Voice AI Like the Human Brain With Scott Stephenson from Deepgram 1
+ [https://www.youtube.com/watch?v=pmcR9mkI33E](https://www.youtube.com/watch?v=pmcR9mkI33E)
+ **Deepgram ****最初从****transcription**（语音转写）起步，但现在为技术**stack**的各个“层”构建各种不同的语音模型。很早以前我们就把**end-to-end deep learning**（端到端深度学习）带进了语音领域
+ 我们团队要解决的问题是**latency**（时延）与**interruptions**（打断）之间的**trade-off**（权衡）。
+ 当下**voice agents**最大的问题之一就是“打断”。大家会尽量**crank down**（调低/压紧）**end-of-thought models**（**EOT**模型，判断一句话“思路结束”的模型）来降低**latency**，于是“时延—打断”的权衡几乎成了一个基本矛盾。
+ 如果模型只看**text output**，或只看**silence**，或只是一个**VAD detector**，就会出现大量**edge cases**（边缘情形），导致系统不是等待过久，就是误判打断。
+ **Dgram**要发布的新模型叫**Flux**。它的代号曾是**river**，因为它就像一种新的“**stream**”（流式）.它是一个**streaming-first**（优先面向流式）的模型，从零开始构建
    - **latency**被**显著降低**。而且它还包含**end-of-turn detector**（回合结束检测器）等能力。
    - 些信号都**随流式**送达，因此如果你不想，**不必**再额外配置**VAD**或其他**EOT**检测器。
    - 很多时候难以看出巨大提升，因为现在的语音已经很“像真人”；但**Flux**的**速度**和**回合结束检测**的效果**立竿见影**。
    - 回合检测**与**转写**同时进行，本身就**大幅改进**了体验
+ **Flux**是我们世界观/架构观的第一步，即我们的**neuroplex architecture**（**Neuroplex**架构）。**Flux**是其中的第一块，给整段对话提供更多**context**（上下文）
+ 把当下常见的**cascaded system**（级联系统）类比成人脑，它只在“灰质”里各干各的，彼此并不通过“白质”对话；因此**context**只能靠**text streams**（文本流水线）传递。
    - 于是就成了**speech-to-text**输入、文本输出，但**无法**传达全部信息：现在轮到谁说话、所用语言、说话者是否兴奋、语速快慢……这些额外信号被**flattened out**（被压平成单一文本）而**丢失**。
    - 而在**Neuroplex**里，**STT**、**LLM**、**TTS**等每个阶段都会让**context**在其中**流动**：既**接收**上下文，也**输出**上下文。每一层还提供**good / better / best**的档位，因此你可以在**速度/质量/成本**之间灵活**伸缩**
+ 我觉得这和**自动驾驶（self-driving）****系统的演进非常相似：你需要****perception**（感知）外界正在发生什么；接着预测“别人下一步会做什么”、我“该说什么”（**planning** 规划）；然后是“我该如何说出来”（**controls** 控制，或 **text to speech** 文本转语音）。而且这些模型往往都是**nondeterministic**（非确定性的），还要**in parallel**（并行）工作，以实现**autonomous**（自主性）
+ 你们正在走向一种与自动驾驶很相似的架构——不是“一个模型把结果**传递**给下一个”，而是各个模型都在**publishing**（发布）消息，其他模型再去**subscribe**（订阅）。
+ 可以把人脑也看作一种“模型”，但更像**pub-sub**：各模块都在“发布我所感知到的世界”。然后每个模块自己决定：我是否要关注**empathy**（共情）、**tone**（语气/语调）、**background noise**（背景噪声）？比如在自动驾驶里，有警笛声（音频），但当你要决定怎样**刹车（brake）**时，可能并不需要那路音频信号。
+ 广义的**robotics**（机器人学）——比如**自动驾驶**——让这些想法落地，也为我们开路。如果想看**voice agent**在**real time**（实时）里该如何运作，可以借鉴这些系统——像会走路的仿生狗，**unitry**／**Boston Dynamics** 等等。

# 20251014  OpenAI's new AI chip
+ [https://www.youtube.com/watch?v=9btw343FHb4](https://www.youtube.com/watch?v=9btw343FHb4)
+ **OpenAI**与**Broadcom**宣布达成战略合作，将部署**10 gigawatts**（10吉瓦）规模、由**OpenAI**设计的**AI accelerators**（**AI**加速器
+ 从很多角度看现在的基础设施建设者，你会说：这是人类历史上规模最大的联合工业项目。我们正在定义文明的下一代“操作系统”。‘
+ 当我们意识到全球对产能——尤其是**推理产能（inference capacity）**——的需求之大时，我们开始思考：能否做一颗**专门**面向这种高度特定负载的芯片？
+ 让我如此兴奋的原因之一是：通过**全栈优化**，我们能获得巨大的效率提升；由此带来更好的性能、更快的模型、更低成本的模型
+ 我们甚至把自家的模型用在这颗芯片的设计上，**提前了进度（pull in the schedule）**，并实现了**大幅面积缩减**
+ 把人类已经优化过的部件拿来，再**倾注算力（compute）**进去，模型就能给出它自己的优化方案。
+ 有一批即将出现的技术——其中一些由我们推动，例如**Snowcap**——承诺**能效提升100倍**：把**1 GW**数据中心的能力压缩到**10 MW**能耗实现。不仅是**Snowcap**，整套**颠覆性**技术将在本十年后半段开始落地。

# 20251011 Building with MCP and the Claude API
+ [https://www.youtube.com/watch?v=aZLr962R6Ag](https://www.youtube.com/watch?v=aZLr962R6Ag)
+ “实现一次，处处配置”。**Claude Code** 与 **Claude.ai** 上的网页搜索功能保持一致。也就是在有大量应用需要类似连接时，打造“通用兼容性”。
+ 它可能是“史上增长最快的开源协议”。— 哇。— 增长相当“平流层级”的快，需求极其旺盛……
+ “恍然大悟”的转折是支持远程 **MCP**：过去一切都得用户本地跑，提供方无法托管。原生支持远程托管后，配置成本大幅下降，用户可快速上手。
+ **Context7**：通过抓取并维护最新文档（如 **Next.js**、我们的 **API**），弥补模型的知识截止；配置一次，**Claude** 即可获取最新内容。
+ 喜欢把 **Playwright** 当 **MCP** 服务器，让 **Claude** 能像用户一样点击操作浏览器。它原本能读 **CSS/HTML**，但不能“看”页面；**Playwright** 补上了这点。
+ 每次请求最终都会拼成“一条提示词”——连 **JSON** 的描述字符串也会进入发给 **Claude** 的最终提示。
+ 反模式：把请求塞满工具/服务器——既费 **token** 又让模型混淆（如 **Linear** 与 **Asana** 都有 _get project status_）。要“确定性”，只保留当下相关的；旧话题应裁剪。
+ 不存在“神奇上限”：上下文窗口有限；每个服务器都会带来函数定义吞噬 **token**；更少但更相关的工具通常更好。
+ **MCP** 接口设计不同于传统 **API**。在 **LLM** 语境下，用少量工具（如“**get info**”）+ 良好的自然语言描述，可替代一堆细粒度端点；更友好也更高效。
+ 会有“魔法感”：增加服务器的组合会出现意料之外的涌现特性。
+ 我们做了一个知识图谱服务器，只有两个工具（“创建记忆”“连接记忆”），界面极简。

# 20251007 Claude Coded: Sonnet 4.5, Claude Code 2.0, and more.
+ [https://www.youtube.com/watch?v=Yct0MvNtdfU](https://www.youtube.com/watch?v=Yct0MvNtdfU)
+ **Claudson 4.5** 已经在所有你能获取 **Claude** 的地方上线了，而且它是当今世界上最强的代码模型
    - SweetBench** 基准上处于领先地位，经过验证的得分为 77.2%。
    - 在复杂任务上能持续专注超过 30 个小时。
    - **OS World** 测试上——这是一项评估 AI 能否像人类一样实际使用电脑的测试——**Claude** 的成绩从 4 个月前的 42% 跃升到如今的 61% 以上。
    - VsCode 插件，你通过专用的侧边栏面板实时查看 **Claude** 所做的更改，该面板能以内联差异的形式展示修改内容。
    - 一个全新的 **checkpoints** 功能，它让你可以放心地运行大型任务，并在需要时瞬间回滚到先前状态。
+ **Context editing** 会在接近 Token 上限时，自动清理上下文窗口中陈旧的工具调用与返回结果
+ **memory tool** 允许 **Claude** 通过基于文件的系统，将信息存储在上下文窗口之外并进行查阅。
+ **Cloud Agent SDK**（由原 **Cloud Code SDK** 更名而来）向你开放与 **Cloud Code** 同等的核心工具、上下文管理系统与权限框架，帮助你构建自有智能体。

# 20251006 they are lying to you about AI development 2
+ 2026 年年中，模型将能**自主**连续工作**整整一个工作日（8 小时）**
+ **在 2026 年底之前**，至少会有一种模型在**多个行业**达到人类专家的表现。而到 2027 年底，模型将在许多任务上**经常**胜过专家。
+ whistleblower：吹哨人（揭露机构不当行为者）
+ **Goodhart’s law**（古德哈特定律）：当**指标**变成**目标**而非参考时，麻烦就来了。评测基准在大家开始**对着考点刷分**之前还算可信；一旦“高分”成了目的，体系就会失真。
+ “**心智的自行车**”（常归因于 **Steve Jobs**）：人类本身并不快，但有了**自行车**效率奇高；计算机是**心智的自行车**——我们创造的工具让我们更强。
+ “**AI 不是工具，而是竞争者**”AI 越强，人类越不值钱
+ 为什么**计算机**曾加剧不平等，而“**Chad GBT**（指 **ChatGPT**）”似乎在改善？90 年代计算机扩大了**工资差距**；而现在不少研究发现 **AI** 对**弱势/困难群体**的帮助**大于**对专家的帮助。
    - 想想你用 **ChatGPT** 的方式：**迭代**、**打磨**、**发现改进机会**。
    - 不是一问了之，而是来回对话半小时，直到确认答案**正确**。
+ 研究者把**认知工作**拆成三部分：**执行**、**机会判断**、**收益判断**。
+ **AI** 在**执行**上越强，你的**判断力**就越有价值。这是**乘法效应**，而非**替代效应**
+ 数学证明了一个**反直觉**结论：工具越强，会**扩大**能**发现机会**者与不能者之间的差距。
+ 为什么 **AI** 眼下看起来在**走向不平等**？因为我们仍在**第一阶段**——它主要在**弥补技能差异**。**处境艰难的员工**获得了巨大的提升；而**专家**本就擅长**执行**
+ **ADHD** 人群从 **ChatGPT** 等聊天机器人中**受益显著**。这类工具帮助他们**弥补因 ADHD 形成的能力缺口**，在多方面**跨越障碍**，并提升他们的**可及性/可达性**。
+ **第二阶段**将要到来：当**执行几乎免费**（人人能设计/写代码/写作）时，**唯一关键**的是*_判断力_
+ **AI 越强，完全自动化反而**更**不可能**。原因：**自动化系统**的判断是**固定的**，**难以适应**。**实时调节判断**是**人类独有**，工具越强，这点越**稀缺且增值**。
+ **AI** 越强，**决策权**应从“擅长**执行**的人”转向“擅长**看见机会**的人”。
+ 能**看见可改进之处**就是你的**护城河**。研究者称之为 **opportunity judgment（机会判断）**，它将成为**最有价值**的经济技能。
+ 单说“**AI 取代岗位**”**偏题**了：他们衡量的是**当下**的工作，而 **AI** 正在**改变“工作”的定义**。
+ 真正的问题不是“**AI 会不会替代我**”，而是“**我是否在培养驾驶更强大‘自行车’的判断力**？”——而这些“车”**很快会更快**。

# 20251005 they are lying to you about AI development
+ [https://www.youtube.com/watch?v=6Iahem_Ihr8](https://www.youtube.com/watch?v=6Iahem_Ihr8)
+ 关于AI整体走向，有些常被忽略的事实——它要比许多人预期的更“细腻复杂”。
+ 在**黑箱技术**下，其极限是**双重指数级（doubly exponential）**。而他们是借助 **Chad GPT**——确切说是 **GPT5**——完成关键步骤的。
+ **2025 年 9 月**，他认为 **AI** 已经能涉足“在人类智识活动中最具人类特质”的一项：**证明量子复杂度类之间的 oracle separation**。**GPT5** 也许写不完整篇论文，但它能**帮你解套卡点**——这是一个绝佳“甜蜜点（sweet spot）”。
+ 能“补上你**理应**想到的那点洞见”的 **AI** 是**大事**：它加速的是**发现过程本身**，而不只是 **LaTeX** 排版或参考文献。本文只是“成千上万案例中的一个缩影”。——事实是，聊天模型正帮助研究者推动**新的科学发现**。
+ **Google Deep Mind** 的 **Alpha Evolve** 展示了类似案例：改进 **Gemini** 训练流程，提高数据中心效率，节省数百万成本；并在数周内优化硬件规格，对比人类工程师可能需要六个月。
+ 之所以很多人“感觉不出模型在进步”，是因为模型的智力在某个时刻已经**超过**了**X/Twitter** 的平均用户。我这里转述可能不够准确，但核心是：仅凭聊天感受不出提升，并**不意味着**模型没有提升。像 **Julian**、**Scott Aronson** 这样的人**能**察觉到差异。
+ **Meter Research**。他们**衡量**模型完成**长任务**的能力，发现模型**可完成的任务时长**大约**每 7 个月翻一倍**。
+ **“每 7 个月翻倍”是在追溯到 2020 年之前**时的趋势；若只看 **2024 年以来**（红线），斜率更陡——**每 4 个月翻倍**。

# 20251004  Building the future of agents with Claude
+ [https://www.youtube.com/watch?v=XuvKFsktX0Q](https://www.youtube.com/watch?v=XuvKFsktX0Q)
+ Claude Developer Platform ，以前叫 **Anthropic API**
+ “智能体”几乎已经成了一个**热词**：现在好像人人都在做“智能体”，而当一个行业术语热到这种程度，**定义**就会变得模糊，仿佛什么都能叫智能体。
+ 在 **Anthropic**，我们更看重的一点是：**模型具备一定自主性**——能自己选择要调用的工具、发起调用、处理结果，并据此决定**下一步**。作为一家**基础研究实验室**，我们更关注模型的**推理过程**及其“如何作出决策”，这也是我们认为**智能体**的关键要素。
+ “**agentic** 的做法”更妙的一点在于：随着模型每隔几个月升级一次、**智能上限**提高，如果采用更**纯粹的智能体范式**，这些服务**会随之变得更好**。相反，若你的工作流里**脚手架（scaffolding）****太多，就等于给模型套上了****边界**；某些情况下没问题，但这样可能**无法充分利用**下一代模型带来的**更高智能**。
+ 围绕模型的**框架**演进很快，用来**编排（orchestrate）****智能体、榨取模型能力。但行业里的共识在于：不少框架****过重**、**意见过强（opinionated）**，于是又有人回到“一个循环就够了”的主张。
+ 我们的立场是：许多场景里**确实是一个循环**，但我们能做的“独门功夫”在于**提供工具与特性**。我们希望提供**适度有观点**但**不至于过重**的框架/工具，避免**挡住**模型本该发挥的能力。
+ 我们称之为**“给模型解开镣铐（unhobble）”**。模型本来就有很多能力；即便是**现世代模型**，其智能仍**未被完全解锁**。只要把**需要的工具**给它，让它**自由使用**，就能获得很好的结果。
+ **智能施用位置**的转移：从**开发者主导**转向**模型自我摸索**。
+ —— 这很令人兴奋：作为开发者，我的创意总有边界、能想到的用例有限；但模型会自己**想办法**把事做成。所以，**“解束缚”模型**真的很棒。
+ **操作层面**，首推 **Claude Code SDK**。我们围绕模型构建了一个**智能体“挽具”（harness）****来驱动那个循环，自动完成****工具调用**与**功能使用**。它最初为**编码场景**而生，但我们很快意识到它其实是一个**通用的智能体“挽具”**。这个 **SDK** 提供了**开箱即用（out-of-the-box）****的方式来****原型化**智能体，你无需亲自搭循环、写工具调用。它构建在 **Messages API** 和前面提到的那些工具之上。
+ 当你把其他一切都移除后，剩下的就是**智能体循环（agentic loop）**，而你真正需要的只是一个**极简**的内核。
+ **在 ****Claude Code SDK**** 之前，大家都在各自实现某种**提示缓存（prompt caching）、**工具调用**与**循环**的管理方案。
+ 能**清晰表述**你对智能体项目的**预期产出**，非常有助于**界定智能体边界/范围**。
+ **SDK** 提供的是一个可部署在任意位置的**智能体循环运行时**。我们把 **SDK** 解锁的能力**上推到“更高阶抽象”**：把**循环**与**工具调用自动化**都**交到你手里**，再据此打磨**开箱即用、可规模化**的**场景化解决方案**。
+ 帮助用户**抬高智能上限**，拿到**最佳结果**。更高阶抽象不仅仅是为了“更容易”，也因为我们**贴近研究与推理（inference）**，能确保我们的**抽象**与**智能体循环**与 **Claude** 的协同**极强**。
+ 随着任务**变长**、工具**增多**，一个持续的大问题是：**长任务的可观测性（observability**。大家都想要好结果，但可能需要**纠偏（steering）**、**提示调优（prompt tuning）****或****重构工具调用**。我们有能力**在平台上逐步提供可观测性**——这是我们的**重点方向**。
+ 我们新增了**上下文管理**能力：在智能体循环里，你可能会发起 **10–100** 次**工具调用**，单次消耗 **100–1000** 个 **token**。我们允许**模型**移除**较早且不再需要**的**工具调用痕迹**。**清理提示（declutter the prompt）** 后，模型往往**更能聚焦**。
+ 我们还加入了**智能体记忆**：人类**重复执行**任务会**越做越好**，因为会总结**启发式**（比如“这个检索用 **Wikipedia** 更好”）。我们给模型一个**记笔记的记忆工具**；当**卡住（stumped）或开始新任务**时，它可以**回看笔记**。

