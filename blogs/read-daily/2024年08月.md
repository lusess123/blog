# 20240831《Elon Musk》42 Solar Tesla Energy 2004–2016 #每日阅读
+ Peter说，全家族都遵循同一个格言：“风险是一种燃料。”
+ Lyndon 他们开发出了自己的软件来自动化许多任务，这帮助他们将公司卖给了Dell Computers
+ “我们意识到消费者的体验很糟糕，高昂的前期成本是一个巨大的障碍。”
+ 客户会拨打一个免费电话，销售团队会使用卫星图像来测量屋顶的大小及其接受的阳光量，然后公司会提供一份合同，详细说明成本、公用事业节省和融资条款。
+ 在2015年4月Powerwall发布时，他说：“Tesla不仅仅是一家汽车公司，它是一家能源创新公司。”
+ 让Tesla收购SolarCity可以实现两件事：让他整合家庭能源业务，并拯救他堂兄弟们摇摇欲坠的企业
+ “Tesla Motors的总体目标是加速从以开采和燃烧碳氢化合物为基础的经济向太阳能电力经济的转变。”
+ 这是一个崇高的愿景，但它付出了个人代价。在一年内，Peter和Lyndon Rive都离开了公司。

# 20240831 AI Doom | Google's STUNNING Videogame Generation Model BREAKS the Videogame Industry... #每日陪读
+ [https://www.youtube.com/watch?v=nw_1dUtLXFw](https://www.youtube.com/watch?v=nw_1dUtLXFw)
+ 2024年3月，Nvidia的CEO **Jensen Huang** 说我们可能在不到10年的时间里看到由AI生成的游戏，这意味着AI神经网络将会在玩家进行游戏的同时，实时地逐像素生成游戏。
+ 《Doom》被修改后可以在《Minecraft》中运行，就像电影《Inception》**一样——这是一个游戏中的游戏
+ Doom 创世人 John Carmack最近创立了一家公司，名叫Keen AGI，其使命声明是：AGI或破产
+ VizDoom——这是一种让AI代理玩**《Doom》**的方式，配备了常规视角，以及一个可以看到游戏中标记物体的视角，还有一个深度缓冲器，帮助它们更容易理解它们所处的3D空间，还有一个俯视地图。
+ 训狗与机器学习的过程类似——我们也可以通过正面和负面强化让AI模型做我们想要的事情。
+ Cesar Millan 是一位著名的训犬师，以其在训练和行为矫正方面的技巧而闻名。他的训练方法主要集中在建立人与狗之间的正确关系，强调主人作为“领袖”的地位。
+ ASMR（Autonomous Sensory Meridian Response，自主感觉经络反应）是一种感官体验，通常由某些声音或视觉刺激引发，给人一种愉悦的、放松的感觉
+ “总体而言，我们的方法在长时间轨迹上达到了与原始游戏相当的模拟质量，在短时间轨迹上，在区分模拟和实际游戏片段方面，人类评估者仅略微优于随机选择。”

# 20240828 BREAKING: OpenAI's SHOCKING "ORION" Model! 🔥 Feds get involved 🔥 All details exposed 🔥 It is over...
+ [https://www.youtube.com/watch?v=My4Fj3fxct4](https://www.youtube.com/watch?v=My4Fj3fxct4)
+ 有关OpenAI的一些令人震惊的发展：关于他们秘密的Strawberry模型的传闻是真的
+ Strawberry背后的技术正在被用于构建下一代模型，称为Orion
+ Strawberry项目就是QAR，它们是同一个东西
+ star使AI模型能够通过迭代生成自己的训练数据，来引导自己进入更高的智能水平。
+ 他们已经在互联网上搜罗了训练数据，现在已经用完了；就是这样，我们将进入一个AI寒冬，进展将放缓。
+ Meta CEO Mark Zuckerberg所主张的：开源可以带来更好的安全性，因为当代码公开时，更多的人可以审查它，发现漏洞，并在它们成为问题之前修复它们。
+ 很明显我们正处在AI的新纪元的开端——在这个时代，利益攸关更大，挑战更多，正面和负面结果的潜力都非常巨大。
+ Strawberry最重要的应用之一是为Orion生成高质量的训练数据。Orion是OpenAI正在开发的下一个旗舰大型语言模型。
+ STAR: Self-Taught Reasoner 意味着模型自我学习，Reasoner意味着，你知道，有时你通过说话来解释某件事，这有助于你理解发生的事情
+ 合成数据用于训练下一代模型，特别是为了对其进行微调，而不是从头开始训练。
+ 训练和推理之间的界限正在变得模糊
+ 我们正处于AI发展中一个令人着迷的阶段，可能性似乎是无限的，但随之而来的责任和挑战也是如此。
+ Orca 2模型匹敌或超越了所有其他模型，包括那些大五到十倍的模型
+ 根据一些员工的泄露，OpenAI似乎打算以聊天机器人的形式发布Strawberry
+ Quiet-STAR，语言模型可以教自己在说话前思考
+ 由MidJourney生成的合成数据被用于训练Adobe Firefly
+ 据报道，OpenAI的全能推理模型Strawberry内部已经可用，但尚未发布。
+ 我不认为Orion会向公众发布

# 20240827 Grok 2 Large is Smart, Uncensored and has "DANGEROUS POTENTIAL"...
+ [https://www.youtube.com/watch?v=o1iZ4QOveLk&t=20s](https://www.youtube.com/watch?v=o1iZ4QOveLk&t=20s)
+ Wason选择问题：它故意试图通过我们的偏见让人类得到错误的答案
+ GPT-40做错了，旧版本GPT-4却做对了
+ 大型语言模型无法生成一个潜在的答案，然后思考、反思并在需要时进行修改。
+ 类似填字游戏这样的任务几乎是不可能完成的，除非你使用类似“树状思维搜索”这样的复杂提示机
+ 大型语言模型不愿意生成某些脚本，而Grok到目前为止做得很好；它没有拒绝生成那些内容，似乎限制更少。
+ CLAE的编程能力远远超过了我迄今为止见过的其他任何东西



# 20240822 Black Myth Wukong - Ending & Son Wukong Final Boss Fight
+ [https://www.youtube.com/watch?v=yywQMkJDoOo](https://www.youtube.com/watch?v=yywQMkJDoOo)
+ 难道生命本身不是一趟单程旅行吗？一旦踏上旅程，就无法回头。
+ 那些经常谈论爱的人，总有一天会后悔。
+ 命运的青睐需要决心断绝一切欲望
+ 心是六感之首。它是每个生命独有的精华，因此注定在生命结束时消逝。



# 20240821 AI News is getting INSANE! Mass Production Robots, OpenAI Rumor Mill and Unreal AI Video...
+ [https://www.youtube.com/watch?v=9pV0tDNwCdU](https://www.youtube.com/watch?v=9pV0tDNwCdU)
+ 全面自动化的机器人未来可能比我们最初预期的更接近。
+ 9 万美元到1 千 6 百美元，假设你有一个60个月的贷款期——也就是五年，每月支付330美元
+ 在苹果发布新产品之前，通常会有很多谣言和猜测。
+ 如果OpenAI发布GPT-5，它表现不佳，我认为这将对市场产生非常大的降温效应，真的会让市场冷却下来
+ 如果OpenAI确实有这么一个东西，它领先其他人好几年，但他们知道，一旦发布，其他人会在六个月内复制他们
+ 一旦OpenAI发布GPT-5，就会开始一个倒计时，直到有人推出一个接近它的模型。而如果他们不发布，就会需要更长的时间。
+ 有一家公司帮助第三世界的农民，在资本非常有限的地方。这有点像社交网络，使他们能够分享知识并进行买卖。
+ OpenAI现在正在做的事情。表面上看似乎没有很多活动，但当你看到所有的合同和幕后正在进行的谈判时，实际上有很多。
+ 每次有人在排行榜上超过他们时，他们就发布一个新模型，刚好超越对手
+ 他们正在做最低限度的工作来保持他们在排行榜上的霸主地位，同时进行土地抢占，试图融入未来将受益于AI的任何大行业。
+ 但到目前为止，我们还没有看到任何像下一代模型或Strawberry那样擅长推理的东西
+ Runway ML自己发布的消息中提到，他们的模型几乎可以被视为物理模拟器。
+ 它们学会了我们并没有明确告诉它们的东西——它们只是通过大量数据的训练自己摸索出来的。



# 20240819 宇宙之卵- 短篇小说 #每日陪读
+ [https://www.youtube.com/watch?v=h6fcK_fRYaI](https://www.youtube.com/watch?v=h6fcK_fRYaI)
+ 你的灵魂比你能想象的更加宏伟、美丽和庞大。
+ 人类的思想只能容纳你的一小部分。这就像把手指插入一杯水中，看看水是热的还是冷的。
+ 你把自己的一小部分放进容器里，当你把它拿出来时，你就获得了它所有的经验。
+ 如果我在不同的时间地点转世，我可能在某些时候和自己互动过
+ 生命的意义，我创造这个宇宙的原因，是为了让你成长。
+ 每一个人类曾经或将要经历的快乐和悲伤时刻，都是你经历过或将要经历的。
+ 一旦你经历了所有人类的一生，你就会成长到足够成熟，得以诞生。

# 20240818 The AI Scientist | Fully Automated Open-Ended Scientific Discovery #AI #每日陪读
+ [https://www.youtube.com/watch?v=_3o3U5qBPJM](https://www.youtube.com/watch?v=_3o3U5qBPJM)
+ AI要对世界产生巨大的影响，并不需要能够做所有的事情。它不需要能够自动化所有的事情，实际上只需要一件事情，而那件事情就是**AI研究**
+ **Sakana AI**开发，是朝向完全自动化开放式科学发现的**AI科学家**
+ 每个想法以每篇大约15美元的成本被实现并发展成一篇完整的论文。
+ 2027年底，**AI**研究人员的水平可能会超越人类的能力
+ 该**AI科学家**项目的推出标志着实现**AI**在科学研究中全部潜力的一个重要步骤。
+ 我们不认为人类科学家的角色会被削弱；他们只会在“食物链”中上移，去做更高端的任务
+ 在2017年，**Google**发明了**Transformer架构**，启动了整个**AI**热潮
+ 我们可能会在不到一年的时间内从**AGI**（通用人工智能）迅速跃升到超级智能。

# 20240817《Elon Musk》 41  The Launch of Autopilot Tesla, 2014–2016 #每日阅读
+ **Google** 的自动驾驶项目，最终命名为 **Waymo**，使用了一种称为 **LiDAR** 的激光雷达装置，这个词是“light detection and ranging”（光探测和测距）的首字母缩写。
+ **Musk** 抵制使用 **LiDAR** 和其他类似雷达的仪器，坚持认为自动驾驶系统应该只使用来自摄像头的视觉数据。
    - 这是一个**first principles**（第一性原理）的案例：人类驾驶仅使用视觉数据，因此机器也应该能够做到。
    - 这也是一个成本问题。像往常一样，**Musk** 关注的不仅是产品的设计，还包括如何大规模制造它。
    - 最好有一个光学系统，基本上是摄像头加上能够通过观察来理解情况的软件
+ 每一辆新的Model S不仅配备了八个摄像头，还配备了十二个超声波传感器和一个能够穿透雨雾的前向雷达
+ Musk 坚持认为，该系统的评判标准不应该是它是否防止了事故，而是它是否减少了事故。这是一种合乎逻辑的立场，但它忽略了情感上的现实，即被Autopilot系统导致的死亡会比一百起由驾驶员失误引起的死亡引发更多的恐惧。
+ Elon有工程师的思维，而非对人类情感的敏感。
+ 与他其他以使命为驱动的执着（包括去火星的旅行）一样，他做出了最终被证明是荒谬的时间预测。在2016年10月与记者的电话会议上，他宣称，到下一年底，一辆 Tesla 将能够从洛杉矶开到纽约，期间“无需触碰”方向盘。
+ 几乎每年，Musk 都会再次预测Full Self-Driving 只需一到两年就能实现。
+ Von Holzhausen 在2022年底说：“如果他松懈下来并承认这需要很长时间，那么就不会有人聚集在这个项目周围，我们也不会设计需要自动驾驶的车辆。”
+ 他说：“最终，关键在于，要解决Full Self-Driving，你实际上必须解决现实世界的人工智能问题。”

# 20240816 Ex-Google CEO's BANNED Interview | Eric Schmidt
+ [https://www.youtube.com/watch?v=WOLrv-ypfXc](https://www.youtube.com/watch?v=WOLrv-ypfXc)
+ Eric Schmidt，前Google CEO，被人们认为有点像未来主义者。经常能够相当准确地预测技术的发展方向
+ Eric 说，可能在接下来的两年左右，可能很快看到一个拥有一千万个词汇的上下文窗口
+ agent 的另一个定义是从语言到python
+ 把Cuda看作AI的C编程语言
+ top3的前沿模型的差距跟其他模型的差距正在拉大
+ GPU并不一定是AI最好的架构
+ Lisa Su，是AMD的，她是Nvidia的竞争对手之一，她和团队经过长时间的努力，构建了一个可以将Cuda架构转换为他们自己的架构的东西，叫做ROCm
+ 美国在亚5纳米技术方面大约有10年的芯片优势
+ Federated training：你可以构建不同部分的大型语言模型或AI系统；你可以分别训练这些部分，然后将它们联合在一起。
+ 关于战争的一个要知道的事情是，进攻总是占优势，因为你总是可以压倒防御系统。
+ 我们将拥有一些我们无法完全描述的知识系统，但我们理解它们的边界
+ 需要弄清楚如何攻击这些大型模型并理解它们的工作原理，这将是为下一代培养一种重要技能。
+ 有一个Twitter SLX账号，Pini the Prompter，他通常在这些模型发布后的几天内就破解了它们。
+ 链式思维推理，人们相信在未来几年内，你将能够生成一千步的链式思维推理
+ 资本成本如此巨大，它可能从根本上改变了软件的构建方式。
+ 上下文扩展、代理和文本到行动的结合将带来难以想象的影响
+ 上下文窗口可以解决新近性的问题
    - 当前的模型需要一年的时间来训练——大约6到18个月：6个月的准备，6个月的训练和6个月的微调——所以它们总是过时的。
    - 在一个非常强大的上下文中；它变得像谷歌一样即时。
+ 我认为这些系统与其他任何技术浪潮没有什么不同；那些危险的工作和需要极少人类判断的工作将会被取代。
+ 随着上下文窗口扩展到1000万个tokens，这肯定会改变我们对训练前和训练后的思考方式，或者换句话说，一旦模型训练完成，它并不会停止学习

# 20240820 Google DeepMind Creates Robotic Table Tennis Champion #AI #每日陪读
+ [https://www.youtube.com/watch?v=TQMhCifLhxU](https://www.youtube.com/watch?v=TQMhCifLhxU)
+ 在现实世界任务中实现人类水平的速度和性能是机器人研究领域的"North star"（北极星,来指代机器人研究领域的终极目标)
+ 一旦它们在仿真中、在数字世界里学会了如何做某事，你如何将这些应用到我们真实物理世界中的现实任务上
+ 这个AI系统能够泛化到未见过的对手，对它以前从未见过的不同技能水平的人，以不同的方式击球。
+ 在GitHub上，谷歌Deep Mind发布了这个名为MuJoCo的软件。它是一个具有接触的多体动力学，一个通用的物理模拟器。
+ 游戏分解为机器人赢的游戏与机器人输的游戏
+ 如果你想提高你的游戏水平，可以特别设计一个机器人来提高你的游戏水平

# 20240819 The spelled-out intro to language modeling: building makemore (下1) #AI #每日陪读
+ [https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2&t=4862s](https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2&t=4862s)
+ 从神经网络中输出计数也不是一个好选择。所以我们使用对数，然后再使用指数运算
+ exponentiation 指数：
        * 它接受的是正数或负数；覆盖整个实数线；
        * 你输入负数，你会得到e的x次方，它总是小于1
+ 当我展示这些概率时，你会看到这里的每一行当然都会加起来为一，因为它们已经normalized（归一化）
+ Differentiable Operation（可微操作）：是指在数学和计算中，函数或操作是可微的，即它在输入变量的某些范围内存在导数。这意味着对于这些操作，可以计算出输入的微小变化对输出的影响。可微操作在机器学习特别是深度学习中非常重要，因为它们允许通过反向传播算法来计算梯度，从而调整模型的参数以最小化损失函数
+ 我们是否可以优化并找到一个好的W，使得输出的概率相当好，而我们衡量”相当好”的方法是通过损失函数。
+ 前向传播，这就是我们如何让神经网络输出概率的过程.整个前向传播由可微分层组成
+ back propagate（反向传播）的核心是链式法则（Chain Rule），即通过将每一步的局部梯度乘以前一层的梯度，逐层计算并传播梯度。由于指数运算、求和和除法的导数形式比较简单和明确，这些操作在反向传播过程中容易处理，不会导致复杂的梯度计算，从而使得它们在神经网络训练中成为常用的操作
+ average negative log likelihood (平均负对数似然值 )就是 loss（损失）.
+ 这里的损失是 squared error (均方误差），所以我们只是简单地从真实值中减去预测值并将其平方，然后求和，这就是损失。损失是一个总结神经网络质量的单一数值。

# 20240811 OpenAI's MEMETIC warfare... GPT-4o LARGE. #AI #每日陪读
+ [https://www.youtube.com/watch?v=SQup5CeRGCM](https://www.youtube.com/watch?v=SQup5CeRGCM)
+ 当人们意识到GPT-4 Mini是80亿参数模型时，他们会失去理智
+ Curie，所以它就像LoRA，但他们称之为量化LM的有效微调，所以量化基本上是你可以将其视为只是降低精度
+ “Meme”（迷因）是指在文化中传播的一个想法、行为、风格或习俗。这个词最早由生物学家理查德·道金斯（Richard Dawkins）在1976年的书《自私的基因》（The Selfish Gene）中提出，用来描述类似于基因的文化传播单元。与基因通过生物遗传来传播不同，迷因通过模仿和传承在人与人之间传播。
+ STAR，自学成才的推理者，它使AI模型能够通过迭代地创建自己的训练数据，提升自己到更高智能水平。
+ 思考链提示和模型写出所有推理之间有很多相似之处，他们可以共同使用
+ 大模型自己教自己如何思考 [https://arxiv.org/pdf/2403.09629](https://arxiv.org/pdf/2403.09629)
+ Sussex column R是一个非常非常小的Open AI模型，使用Strawberry算法
+ 实际上有GPT下一个版本，内部称为GPTx，我们称之为GPT 5

# 20240810 The Potential for AI in Science and Mathematics - Terence Tao  #AI  #每日阅读
+ [https://www.youtube.com/watch?v=_sTDSO74D8Q](https://www.youtube.com/watch?v=_sTDSO74D8Q)
+ 如果你真正了解人工智能的基本原理，呃，你会发现其中有一些数学，但实际上，在大多数情况下，并不是最先进的数学
+ 其实现这种操作的方式在数学上相当普通，你知道，你只是拿起输入，拿起输入，将其分解成小块，呃，将每个词或其他内容编码成一个数字，然后将这些数字乘以权重并组合起来，也许你会截断它们，然后再乘以权重并组合。然后你做这件事几百次，呃，然后你就完成了，呃，其实在数学上相当无聊。
+ 如何找到这些权重，那就有趣得多了，呃，但它并不是魔法
+ 你发明了喷气发动机，你可以迅速构造出某种飞行器，但需要几十年才能真正达到对公众来说非常安全的状态。另一方面，尽管航空旅行显然是一项危险的技术，但今天每英里的航空旅行是最安全的
+ AI 在科研领域的应用：
    - 有许多科学领域的瓶颈在于找到解决问题的好候选者，比如药物，材料的测试和合成
        * 人们还在开发由人工智能驱动的实验室，整个合成危险化学品的过程现在可以以更自动化的方式完成。
    - 加速建模
            + 如果你想做出气候预测，这需要几个月的时间。现在只需要几小时
            + 在运行AI之前收集数据并将其格式化仍然是一个大问题
            + 何模拟成为瓶颈的地方都是另一个很好的应用案例
            + 但有了AI，你可以运行数千个情景，你可以得到更丰富的预测
+ 人工智能应用于数学的缺点比许多其他学科少得多。
+ 独立验证：在数学中，我们有一个标准来判断证明是正确还是不正确。你不必信任人工智能。
+ Proof assistants（证明助手）：是一种计算机软件，它实际上像一种计算机语言。他设计目的不是实际去做事情，而是去验证事情
+ “formalized”就是指将一个数学证明从传统的数学家书写形式转换为严格的、符合逻辑规则的形式语言，以便计算机可以进行验证和检查。
+ the four color theorem（四色定理）：它在70年代被证明，直到2000年代才被形式化
+ S of the C猜想在1998年被证明，但它如此复杂，以至于人们对证明的正确性产生了很多怀疑。所以作者Thomas Hales提出了一个为期20年的项目来将其形式化。但是两年内就完成了。
+ AI使得真正的大型数学项目成为可能。AI和数学将产生巨大的协同效应，而且将会有一个大数学的时代
+ 我设想，最终这将成为一种常见的做法，我们将通过向AI口述的方式来写证明。
+ 我认为AI研究实际上教会我们的一件事是，它与其说是人工智能，不如说是教我们人类的愚蠢。
+ 我认为，在某个时候，当论文达到一定规模时，他们将需要将论文中最技术的部分形式化。
+ 有时你证明了某件事，但你并不真正知道你是如何做到的，这有点让你自己感到惊讶
+ 形式化项目的一个伟大前景是，它们将高层次的概念技能与低层次的技术技能分离开来
+ 在小学和中学，很多重点实际上放在这些技术技能上，比如你如何准确计算这个导数，而不是教你概念
+ 几乎没有公民数学，但在其他学科中有公民科学，一个原因是说数学语言的技术难度，
+ 现在软件开发已经分成了许多不同的专业工作，我认为数学也会走同样的道路
+ L1最小化，效果很好，但没有人能解释为什么，实际上这是一个关于随机矩阵的纯数学问题
+ 只需要找到一两个有启发性的构造，然后他们应用一个更标准的代数求解工具来解决最终的问题
+ 解决一个非常难的数学问题最困难的一步往往是找到关键的中间步骤，这些步骤中的每一个都比原来的问题难度降低一半，这是一个重大进展。
+ 我们学到的是，许多我们认为是人类独有的能力实际上可以通过正确的技术被AI解决，我们对什么是困难的看法确实需要重新校准

# 20240809 OpenAI drops SUSPICIOUS new model. What did they UNLEASH? #AI #每日陪读
+ [https://www.youtube.com/watch?v=fmv2-dRgpoU&t=10s](https://www.youtube.com/watch?v=fmv2-dRgpoU&t=10s)
+ 路透社在7月15日发布了这篇文章：“OpenAI正在开发代号为Strawberry的新推理技术。
+ QAR等于Strawberry，也就是某种推理引擎，下一代的、下一水平的推理引擎。
+ Ethan Mollick说OpenAI是唯一一家其公司沟通策略由模糊提示、模棱两可的声明和适合冒险游戏的谜题组成的公司
+ 第2级AI是推理者
+ 三个草莓暗示第三个等级已经达成，超越了推理者，进入了代理的阶段
+ sus column R 在推理方面表现得出奇地好
+ Logan Kilpatrick  说 2025 年实现 agent

# 20240808 The spelled-out intro to language modeling: building makemore (中) #AI#每日陪读
+ [https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=3&t=58s](https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=3&t=58s)
+ 我们的训练任务是找到使the negative log likelihood loss（负对数似然损失）最小化的参数。
+ 我们的目标是最大化（likelihood）似然
+ 这是两个相同的优化问题，最大化对数似然等同于最小化负对数似然
+ “模型平滑”（model smoothing）：通过添加虚拟的伪计数（fake counts）来避免零概率的出现
+ "torch.tensor" 是自动推断数据类型，而 "torch.Tensor" 只返回浮点张量。
+ **独热编码**（One-hot encoding）是一种常用的数据预处理技术，将每个分类变量的不同取值转换为一个二进制向量。
+ `tanh` 是双曲正切函数（Hyperbolic Tangent Function）的缩写，它是在数学和机器学习中常用的一种非线性激活函数。这个函数的输出范围是 -1 到 1，而不是 0 到 1，这使得它在某些情况下比 `sigmoid` 函数更有优势，因为 `tanh` 函数的输出是零中心化的（centered around zero），这意味着正负输出值在数量上是平衡的

# 20240807 One BILLION Humanoid Robots and the OpenAI "Meltdown"
+ [https://www.youtube.com/watch?v=6Oc5RdarE88](https://www.youtube.com/watch?v=6Oc5RdarE88)
+ Greg Brockman 在 OpenAI是和Elon和Sam Altman一起的最早的一批人之一
+ figure O2 不需要联网，内置了与OpenAI合作训练的定制AI模型。可能是Omni模型的某个版本或微调或检查点
+ 能够以每小时1.66美元到3.33美元的价格获得一小时的体力劳动，无论具体是多少，这似乎都是巨大的
+ Musk说机器人的需求大致等于我们全球对汽车的需求
+ 类人机器人有许多独特的工程问题，例如布线
+ figure O2 采用外骨骼的方法
+ 所有的计算，所有的思考，所有的脑力和AI推理，正确的，AI神经网络做出的决定，全部都是内置的
+ 训练数据是另外在数据飞轮
+ 真正能扩展到现实的是现实本身
+ 制造业更可预测
+ 硬件不是软件，扩大硬件生产需要很长时间

# 20240806 lon Musk on HUMAN WILL vs AGI and Humanoid Robots...
+ [https://www.youtube.com/watch?v=WtSBJ1mStHE&t=2s](https://www.youtube.com/watch?v=WtSBJ1mStHE&t=2s)
+ 跟脑机接口比起来，键盘、鼠标、触控板、语音接口——所有这些很快就会显得缓慢和过时。
+ Dr. Jim Fan说最令人兴奋的三大机器人发展：
    - **Nvidia Project Groot** - 这是Nvidia的一项重要项目，涉及多种机器人技术的开发和应用。
    - **Figure 02** - 是Figure 01的改进版本，尤其是在手部设计上有显著提升。
    - **机器人和人类之间的结合** - 尤其是通过像Apple Vision Pro这样的技术来控制机器人，这种结合正在变得越来越紧密。
+ Figure 2 新版本改进了手指和手掌
+ 尽管外部的人认为 AI 是炒作，但是内部人正在加倍下注
+ Google 已经订购了超过 400,000 个 GB 200 芯片，这可能价值超过 100 亿美元，他们甚至不知道什么时候会拿到这些芯片。虽然谷歌有自己的芯片 TPU
+ 大约90%的分布式计算被人类用来找乐子
+ 如果我们的简单边缘系统提供了做某事的意志来源，那么它就会传递到我们的皮层，然后传递到我们的第三层计算层
+ Optimus 将成为最大的数据信源，因为现实是可扩展的，现实扩展到现实的规模
+ 从机电角度来看，手部可能占了 Optimus 所有工程的一半，人类的大部分智能都体现在我们用手做的事情上。
+ 如果输出率特别是大幅提高，我们可以更好地将集体人类意志与 AI 对齐。

# 20240805 The spelled-out intro to language modeling: building makemore (上) #AI#每日阅读
[https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2&t=6s](https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2&t=6s)

+ 字符级语言模型是在给定之前的一些具体字符序列的情况下预测序列中的下一个字符。
+ bigram language model : 双字模型中，我们总是一次处理两个字符
+ **bi-gram**和**bag-of-words**模型、multilayer perceptrons（多层感知器）、recurrent neural networks（循环神经网络），一直到现代的**transformers**，**DALL-E**, **Stable Diffusion**
+ **PyTorch**是一个深度学习神经网络框架，但它的一部分是**torch.tensor**，允许我们创建多维数组并有效地操作它们
+ (NLP)中有一种约定，使用这种括号来表示特殊的 tokens
+ **张量操作**技巧： **广播**（broadcasting）和**维度压缩**（squeeze）
+ 所谓的broadcasting rules，有一个特别的定义，说明这两个数组是否可以在二元操作中组合，例如除法
    - [https://pytorch.org/docs/stable/notes/broadcasting.html](https://pytorch.org/docs/stable/notes/broadcasting.html)
    - 每个张量必须至少有一个维度
    - 从最后一个维度开始，维度大小必须相等、其中一个是1，或者其中一个不存在
+ "**and element wise divides**" 是描述矩阵运算的一种用法，具体来说，它指的是**逐元素除法**（element-wise division）
+ `P = P / P.sum(1)` 和 `P /= P.sum(1)` 不一定， 后者是原地操作，性能更高
+ 如果你有一个非常好的模型，你会期望这些概率接近一。因为这意味着你的模型正在正确预测接下来的内容，特别是在训练集上，你在那里训练了你的模型
+ **最大似然估计**（Maximum Likelihood Estimation，简称 MLE）是一种统计方法，用于估计统计模型的参数
+ 为了方便，人们通常使用的不是likelihood（似然），而是所谓的对数likelihood（似然）
+ 对数是概率的单调变换，当你输入1时，得到的结果是0

# 20240804  What's a Tensor? #AI #每日阅读
+ [https://www.youtube.com/watch?v=f5liqUk0ZTw](https://www.youtube.com/watch?v=f5liqUk0ZTw)
+ 张量**的最佳途径是首先确保你对**向量**的理解非常扎实**
+ **理解**向量**是更广泛的对象类——张量的一部分，那么你必须确保你理解向量分量和基向量**
+ 最容易理解向量分量的方法是从在(x,y)平面上的向量开始
+ 究竟是什么使分量和基向量的组合使张量如此强大？答案是：所有观察者，在所有参考系中，都达成共识。不是基向量，不是分量，而是分量和基向量的组合。
+ 基向量在参考系之间以一种方式转换，而分量以某种方式转换，从而保持所有观察者的分量和基向量的组合相同。
+ 正是张量的这一特性使得莉莲·利伯称张量为“宇宙的事实”。

# 20240803 INSANE AI NEWS! OpenAI Chip, AI talks to Dogs, Figure 02 Robot and Autonomous Robot Dentists #AI #每日陪读
+ [https://www.youtube.com/watch?v=rwFiXs52ZK8](https://www.youtube.com/watch?v=rwFiXs52ZK8)
+ **Broadcom**是一家美国的开发商、设计商、制造商和全球供应商，主要产品包括半导体， 类似于Nvidia
+ **Groq**芯片，目前是我们拥有的最快或可能实际上是最快的AI推理芯片。
+ 台积电的商业模式： **TSMC**没有自己的芯片；他们不与客户竞争，他们只是为客户进行设计制造
+ **Sam Altman**和**Microsoft**确实有许多非常大的项目正在进行中，包括**Stargate**，这是一个未来的数据中心，可能耗资高达1000亿美元。西雅图附近建造一个发电厂；该项目称为**Helion**，并宣布了全球首**Microsoft**达成的融合能源购买协议，地点位于华盛顿州**Everett**
+ **Figure2**将在8月6日推出，将通用型类人机器人带入**BMW**的各个生产设施，用于汽车制造
+ **TraiNY**，一家位于加利福尼亚州**Palo Alto**的AI初创公司，将帮助客户训练和与他们的狗交流
+ Software 3.0： 使用一个开源模型，比如**LLaMA 3.1**这样的先进模型，并根据我们的需求进行微调，无论这些需求是什么。这款狗用AI模型**TraiNY**使用了**LLaMA**这个开源代码模型，开发了这款应用程序，现在已有200,000名注册用户
+ 狗的语言也是一种自然语言
+ 机器人牙医，本来需要人类牙医分两次就诊2 个小时工作，15 分钟就搞定了

