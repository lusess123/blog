# 20250423Meta's AI Chief: "I'm DONE with LLMs"（上）
+ [https://www.youtube.com/watch?v=QxCSLBm3_iA](https://www.youtube.com/watch?v=QxCSLBm3_iA)
+ Yan LeCun认为通往 AGI 的道路不会依赖 LM，或者说 LM 至少不会是最终架构，于是他提出了一种名为 Japa 的新架构
+ Japa 是一种“世界模型”架构，其目标是构建一个内部世界模型，使系统能够在现实环境中安全地规划、推理和行动。
+ Demis Hassabis 最近也在呼应“给 AI 构建世界模型”的思路；他还提到谷歌的 Astra 项目，届时 AI 能通过用户的智能眼镜观察世界、对所见进行交流，并更好地理解物理世界。
+ 或许 LM 把我们带到了今天，但要实现 AGI，仍缺少一些关键要素，甚至可能需要一套全新的架构。
    - 机器如何理解物理世界
    - 机器如何拥有持久记忆
    - 机器如何进行推理与规划
+ 大家暂时看不出趋势，但五年后就会明白并为之振奋；突破不会来自“token”或大型语言模型。
+ 世界模型使动物仅用少量尝试就能学习新技能，预测后果，进行推理与规划，探索并想象解决方案，还能在陌生情境下避免危险错误。
+ 并未否定 transformer，它们完全可以嵌入我提出的架构中
+ token 是离散的——要么存在，要么不存在——因此我们可能需要一种连续而非离散的表示
+ 我们在生命最初几个月便形成这些物理世界模型，它们帮助我们应对现实——而应对现实要比处理语言难得多。
+ 我们已掌握文本领域的做法，却尚未攻克视频等高维连续数据。所有试图通过像素级视频预测来构建世界模型的做法基本都失败了。
+ 现实中有许多事物本就无法预测，而像素级预测器却耗费资源去臆造不可能知晓的细节。

# 20250422 Model Context Protocol (MCP): Everything You Need To Know（下）
+ [https://www.youtube.com/watch?v=v_NSfjNszU0](https://www.youtube.com/watch?v=v_NSfjNszU0)
+ Tensor Block 的 Awesome MCP servers，在这里你可以找到各种各样的Server
+ 可以使用 Model Context Protocol 注册表 Smiththery，轻松查找服务器并将它们添加到你的配置中
+ 从 MCP 服务器 fastmcp 中导入 FastMCP，它有点像 FastAPI，但本质上是 FastMCP
+ 有两种传输方式：一种是标准输入输出 (stdio)，另一种我记得是网络传输的 SSE；我们本地运行，因此使用 stdio
+ 不仅能轻松从不同的仓库或注册表添加多个工具，我还可以直接将配置文件复制到 Cursor 中使用
+ 再次强调，MCP 最大的优势就是标准化一切。我能在 Cursor、Claw Desktop 或任何其他支持 MCP 的客户端或 IDE 中，轻松复制粘贴这些配置，简单整合插件

# 20250420 Model Context Protocol (MCP): Everything You Need To Know（上）
+ [https://www.youtube.com/watch?v=v_NSfjNszU0](https://www.youtube.com/watch?v=v_NSfjNszU0)
+ MCP的全部用例或目的就是标准化LLM与资源和工具交互时的通信。
+ 工具本质上就是你定义函数签名的功能。
+ tool using, tool calling, function calling，这些是该概念的不同名称，但本质上就是这样。MCP所做的是标准化通信，以便实现这一点
+ 一个很好的类比是将客户端看作一个讲一种语言的客户端——最重要的语言——MCP语言，然后你有这些不同的数据源、服务和工具，它们讲德语、西班牙语、中文等等，然后你有这些翻译者将任何语言翻译成目标语言——MCP语言。
+ 关于标准化协议的一个很酷的特点是，由于大家使用相同的语言，现在非常容易将不同的功能直接插入这个配置文件。
+ MCP协议标准化了所有内容，使我们更容易使用这些不同的工具和数据库，这就是为什么MCP是将各种工具集成到一个系统中的改变游戏规则的原因。它让一切变得更简单、更流畅。

# 20250419  OpenAI's "AI SYSTEMS" and New Scientific Discoveries（下）
+ 首先通过暴力方法求解，然后意识到这一方案的不优雅，并逐渐通过更智能、更简洁的方式找到正确答案。在这个过程中，模型不仅要输出正确的答案，还需要能够向人类解释其思路和解决过程。
+ 这里真正酷的是，我们并没有直接训练模型使用某些策略，我们没有告诉它简化解决方案或再次检查，它只是自然地学会了这些方法，这真是太不可思议了
+ 03 模型可以接近deep research 的水平，但 03 运行得更快，并且使用时的限制要少得多。
+ 对于任何给定的推理成本，04 mini 的表现明显优于 03 mini。
+ 我们投入了比 01 多 10 倍的训练计算资源来产生 03
+ MRO 是一个 Python 结构，用来告诉你关于类的继承关系，你可以通过查看类的 **mro** 属性来验证 MRO 的顺序
+ 将推理范式应用于多模态任务，而这在以前是不可能的，模型能够直接在思维链中操作图像，这大大提高了多模态任务的能力。
+ Codex，因为它确实很好地体现了“代码”在我们训练模型时的核心作用
+ Codex 的一个令人惊讶的地方是，你不仅能看到它的思考过程，还能在你的计算机上直接运行这些工具
+ 一项价值100万美元的开源倡议，旨在通过使用我们最新的模型和 Codex CLI 提供API积分，支持开源项目，推动开源前沿的发展
+ 将推出 03 Pro，但我们需要一些时间来确保所有剩余的功能都能完成。

# 20250417  OpenAI's "AI SYSTEMS" and New Scientific Discoveries（上）
+ [https://www.youtube.com/watch?v=N9bj9dXdgGs](https://www.youtube.com/watch?v=N9bj9dXdgGs)
+ O3 替代了 01，O4 Mini 替代了 03 Mini，而 O3 看起来像是一个巨大的进步。
+ O3 和 O4 Mini。这些是首批被顶尖科学家确认能够产生真正好用且有价值的新颖创意的模型
+ 这些模型真正令人惊讶的是，它们不仅仅是模型，它们实际上是 AI 系统。我们已经训练它们使用工具，而这是我们以前的推理模型没有做过的。
+ 得益于我们在 RL（强化学习）范式中的持续算法创新，续扩大了训练时间和测试时间的规模
+ 在 AIM 这项艰难的数学竞赛中，O4 Mini 使用工具获得了 99% 的准确率，几乎饱和了评估

# 20250416 The U.S. Is About to BUY BILLIONS in Bitcoin?! (Here’s the Crazy Plan)（下）
+ [https://www.youtube.com/watch?v=l98SRa4yoyU](https://www.youtube.com/watch?v=l98SRa4yoyU)
+ 五点计划，以使比特币债券成为现实
    - 指示财政部分析其可行性，
    - 评估美国国债与比特币的理想平衡，
    - 以及国债的理想收益率。
    - 起草相关立法，尤其是关于税收的部分。
    - 设计一个战略，将比特币债券整合到战略性比特币储备中，并在比特币债券发布后评估其效果。
+ 比特币债券的一个迷人之处在于，与现货比特币ETF不同，比特币债券的后端不会被卖出。
+ 比特币债券将显著限制比特币的流通供应。这是一个有点双刃剑的情况。
    - 一方面，这会使比特币的价格进一步上涨，从而可能激励更多的人购买比特币债券。
    - 另一方面，这会使比特币价格极度波动，这可能导致比特币债券持有者在比特币崩盘时恐慌性抛售。
+ 比特币债券可能对山寨币产生利好，因为它们可能对利率产生影响
+ 如果比特币债券的需求很大，那么美国国债的收益率最终将下降。将导致长期利率下降，同时风险资产上涨。
+ 比特币债券持有人的年化回报为7%，这个回报刚好足以抵消货币贬值。
+ 比特币债券可能让投资者却步的原因是，他们完全可以选择购买美国国债（年收益率4.5%）和持有一些比特币的组合。
+ 即使美国国债的价值因通货膨胀而下降，10年期的年化回报也会更高。稳定币越多，美国国债的购买量就越大

# 20250416 The U.S. Is About to BUY BILLIONS in Bitcoin?! (Here’s the Crazy Plan)
+ [https://www.youtube.com/watch?v=l98SRa4yoyU&t=907s](https://www.youtube.com/watch?v=l98SRa4yoyU&t=907s)
+ 将美国政府的债务问题与比特币结合解决，这是一个已经存在多年的想法，嗯，但它从未真正被认真对待过。但这个想法从未真正被认真对待，主要是因为它并不明确如何实现。
+ 未来三年，美国政府需要大约再融资14万亿美元的债务。这比你想象的要更严重，因为现在的利率远高于美国政府最初借款时的利率。
+ 自比特币推出以来，它的年化回报率一直是100%，不言而喻，这个数字被比特币早期的价格暴涨所夸大
+ 美国国债在金融系统中被认为是最安全的资产。
+ 投资者可以获得两全其美的回报：来自美国国债的相对安全的收益和来自比特币的巨大上涨潜力。比特币债券代表了一种创新的方式，将传统金融与加密货币的潜力结合起来。
+ 只要有通货膨胀，比特币应该会继续上涨，因为比特币的供应量是固定的，而法定货币的供应量是无限的。唯一可能导致比特币归零的情境是出现通货紧缩，而通货紧缩从客观上讲是不太可能发生的。
+ 理论上，比特币的价格没有上限，而固定收益率4.5%的国债有上限。持有90%美国国债（1%收益率）加上10%比特币的回报，可能比仅持有100%年化收益4.5%的美国国债要高得多。
+ 附加的好处是，美国政府逐步增加其比特币储备，进一步限制供应并提高比特币价格。
+ 如果美国政府使用10年期比特币债券，政府将节省7000亿美元的利息支出，这是非常巨大的。相当于为整个国土安全部融资的成本
+ 这些节省的资金可以在不增加税收或削减支出的情况下实现。
+ 免除比特币债券持有者对美国国债收益和比特币回报的税收。这将使它们成为美国人建立世代财富的低风险高回报方式。
+ 印钞导致的每年7%的购买力损失
+ 目前20%的美国国债由美国家庭购买，其余80%由机构投资者和外国投资者购买。

# 20250414 Google UNLEASHED Firebase Studio for AI app development (FREE)
+ [https://www.youtube.com/watch?v=bnNXIUdqnt0](https://www.youtube.com/watch?v=bnNXIUdqnt0)
+ Cursor是有史以来从100万迅速达到1亿年收入最快的应用
+ Firebase 本质上就是一个运行在你浏览器中的 VS Code
+ 你可以用 Firebase 托管网页应用、部署到 Cloud Run、添加 Gemini API 功能、加入 Google Maps、启用地理位置功能等等
+ 你可以在白板上随意涂鸦，然后点击按钮就能将它变成真正的东西。
+ 个工具几乎对所有希望在线原型开发和发布应用的人来说都是易于接受的
+ 拥有多个工作区、能够与他人共享这些工作区、能轻松快速地部署应用并将其发布到网上——随后又能方便地追踪实时统计数据并获取分析信息，这些功能都非常棒。

# 20250413 OpenAI's "STEALTH" Models Revealed (AI Safety Concern?)
+ [https://www.youtube.com/watch?v=5taJhLo13hs](https://www.youtube.com/watch?v=5taJhLo13hs)
+ 最近引起极大关注的是两个出现在 Open Router 上的所谓“隐秘模型”， Quazar 和 Optimus Alpha
+ 隐秘模型，是指很多 AI 实验室允许尚未正式发布的模型在不同的平台上进行测试
+ Sam Altman 插话说，“Quazar” 是一种非常明亮的东西
+ Optimus Alpha 模型在编程方面表现出色，并拥有100万 tokens 的上下文窗口
+ GPT-4.5 非推理模型，但这个模型更具创造力，语言也更加自然
+ 很多人讨厌那个故事，但我认为这种反应更多是因为它是AI生成的，而非内容本身。如果你告诉别人“这是我写的短篇小说，你怎么看？”，大家可能会觉得“挺好的”。
+ GPT-4 即将退役，可以说是一个时代的终结。
+ Matt Burman 在推特上报道的，Quazar Alpha 是一个神秘的拥有百万token上下文的模型，在基准测试中击败了 Claude 3.7 Sonnet，速度还快四倍——但没人知道是哪个实验室开发的。
+ O3 的话题，据一些文章和 OpenAI 内部人士透露，这些模型的安全性测试似乎变得不再那么优先了。
+ Daniel最近写了《到2027年AI将接管一切》
+ O3 Mini ，它是第一个具有潜在危险性的自主模型。特别之处在于，它是第一个在模型自主性评估中达到“中等风险”水平的模型。
+ 而如果达到高风险的话，我觉得那将是一个非常大的飞跃，因为高风险意味着模型能够进行递归式的自我改进。它能够自主地进行机器学习研究。
+ 之所以可能令人担忧，是因为解决开放式任务会立即加速AI研究进程，并展示出很强的长期上下文理解和适应能力。
+ 《Severance》讲述了一个名为Lumon的公司开发了一种脑部芯片技术（被称为“Severance Procedure”，中文可理解为“切割手术”）。接受这种手术的员工会将自己的工作记忆与私人记忆彻底分开：

# 20250411 Google Agentspace JUST WON the AI Game...
+ [https://www.youtube.com/watch?v=dIwBMXV33n0](https://www.youtube.com/watch?v=dIwBMXV33n0)
+ Agent Space 和 A2A 的发布这件事可能会非常重大。原因是，就像过去 Google 通过一个简单的搜索栏就统治了网络空间一样
+ 随着人工智能的兴起，搜索的这种概念可能已经有些过时了。我们发现自己更倾向于使用聊天机器人，也就是某种可以代表我们执行任务、寻找信息的 AI 智能体。
+ Google 新推出的时间序列预测模型，这个模型专门为这类场景进行了训练
+ Agent Space 是目前市场上唯一能够连接第三方数据和工具，并提供与第三方智能体和模型互操作性的超大规模平台。
+ 想象一下这个市场不断扩大，不断增加更多智能体，而每个智能体都有根据用户体验形成的自身信誉体系。
+ ADK 是一个开源且灵活的框架，专门用于简化多智能体系统的开发与部署。
+ A2A 是一个开放协议，它是 MCP 的补充。作为用户，你可以将来自不同供应商的各种智能体自由组合到一起，让它们无缝地去完成你所需的任何任务。你只需挑选就行，智能体来自哪家公司并不重要，完全是即插即用的。
+ 它的重点是让智能体以它们自然、非结构化的方式协作，即使它们不共享记忆、工具和上下文信息也能协同工作。
+ 但如果你回想一下 Google 当年为何如此成功，就是因为他们创造了一个搜索栏作为进入网络的门户。可能是向 Google 支付一定费用，以便 Google 将他们的服务或智能体排在更前的位置

# 20250407 Llama 4 Meta's "NEARLY INFINITE" Context Window... (also Reasoning?)
+ [https://www.youtube.com/watch?v=jwE6_ujYcPw](https://www.youtube.com/watch?v=jwE6_ujYcPw)
+ 正绝对突破性的、完全出乎意料的创新是：Llama 4 Scout 拥有1000万的上下文长度窗口。
+ 目前还没有任何其他前沿实验室能与之匹敌。Mark Zuckerberg 甚至称之为“近乎无限的上下文窗口”。
+ 使用拥有100万上下文窗口的 Gemini 2.5 Pro 时，你会明显感受到：在生成内容时，它好像拥有更多的“思考空间”。
+ 尚未完全推出的 Llama 4 Behemoth：2880亿活跃参数、16个专家，总参数达到2万亿
+ 如果你想用它来蒸馏知识，生成合成数据以训练其他模型，这个模型——即 Behemoth——就是最佳选择。它就像异形女王一样，“产下”能够构建其他模型的“卵”，供你具体使用场景来使用。
+ 在此之前，Meta 没有使用混合专家模型；他们以前所有的模型都是所谓的“稠密模型”，即单一结构，而非根据需求调用多个专家
+ Google 是较早开始公开这些“海底捞针”式信息检索测试结果的公司之一。
+ 并非完全开源；Llama License 有自己特殊的规定。欧盟境内的用户和公司被禁止使用或分发这些模型。
+ 看起来 Llama for Reasoning 即将推出

# 20250406 Swarms of AI Agents JUST Got Unleashed...
+ [https://www.youtube.com/watch?v=VnwbsGvUmZA](https://www.youtube.com/watch?v=VnwbsGvUmZA)
+ AI Digest，他们发布了一个名为“智能体村庄”的项目，你电脑里会有四个智能体组成一个群聊，你给它们设定一个雄心勃勃的目标，它们就会开始努力去实现这个目标。
+ Gen Spark已经筹集了1亿美元来与 Google 展开竞争，目标是达到类似 Perplexity 那样的高估值
+ Lindy，主打的是“智能体群”（agentic swarm）的理念
+ 为什么 GenSpark 超级智能体效果更好呢？秘密在于三个关键创新技术的协同作用：大型语言模型、工具集和数据集
+ 数量多少并不重要，因为它们都是同时完成的。

# 20250405 OpenAI's Autonomous AI Research Benchmark 下
+ [https://www.youtube.com/watch?v=SeQU2LNQ5ig](https://www.youtube.com/watch?v=SeQU2LNQ5ig)
+ 起初 AI 代理——其中 01 模型在复制实验初期表现优于人类基线——但在24小时后，人类开始超过 AI。这个现象，即 AI 代理起初领先但在长时间运行后逐渐落后，与以往的结果是一致的。
+ 01 模型起步非常迅速，能在最初阶段快速编写大量代码，但在超过某一时间段后，其表现便显得不足。
+ 我们从那些连代码都不会写的阶段，短短几年内就发展到了如今的水平；但未来也许会出现一个进展停滞的“平台期”，或者进步会突破这一界限并持续加速。

# 20250404 OpenAI's Autonomous AI Research Benchmark 上
+ [https://www.youtube.com/watch?v=SeQU2LNQ5ig](https://www.youtube.com/watch?v=SeQU2LNQ5ig)
+ openAI在X账号上所说，他们将发布 Paperbench——一种用于评估AI智能体复制顶尖AI研究能力的基准测试，作为其“preparedness framework（应对框架）”的一部分。
+ 许多前沿AI实验室都有各自版本的“preparedness framework”。这种框架用于跟踪潜在的AI风险。随着AI模型不断进步，我们希望观察它们可能带来的逐步升级的威胁
+ “模型自主性”，这当然是AI智能体的重要前景，即它们完成长期任务的能力
+ 人类唯一的贡献是选择一个适合该研讨会的广泛主题。
+ 首次完全由AI生成的论文达到了通过标准科学同行评审的水平。
+ 人们可能因为这些结果不够吸引人而不发表，甚至有人可能为了发表而篡改数据，而这正是AI可以发挥巨大作用的地方。
+ AI可能擅长处理那些被视为无聊或不重要的研究
+ Claude 3.5 Sonnet 得到了21分，也就是说，它能够复现21%的论文。
+ 虽然AI目前尚未超过机器学习博士，但我们不应忽视这些AI智能体在复现研究方面展现出的非同一般的能力
+ 一位博士，他花了差不多一年完成的代码库，而 O1 preview 加上 O1 mini 大约在一小时内就搞定了。

# 20250403 AI Dev 25 | Justin Uberti: Introduction to the OpenAI RealTime API 6
+ [https://www.youtube.com/watch?v=fHz6s0YmNFo](https://www.youtube.com/watch?v=fHz6s0YmNFo)
+ RAG 通常用于，当用户提出的问题不在模型的训练集中时，我们就需要去查询它。
+ 向量数据库会用从中检索到的信息来增强对话的上下文。
+ 调用工具后返回的信息，会通过使用 conversation.item.create 这个 API 插入对话中，这样就人为地将一段历史记录推送到了上下文。
+ Real-time API 虽然响应快、对话流畅，但在思考和编码方面表现一般。
+ 目前它支持文本和音频，但还不支持图像。

# 20250402 AI Dev 25 | Justin Uberti: Introduction to the OpenAI RealTime API 5
+ [https://www.youtube.com/watch?v=fHz6s0YmNFo](https://www.youtube.com/watch?v=fHz6s0YmNFo)
+ 如果有人说了一个特定的词，我们将停止音频响应并将助手引导去谈论其他内容。
+ 文本的速度比它播放音频的速度要快，如果我们看到转录文本中不喜欢的内容，我们通常能立即停止音频播放，通常是在音频播放前就能停止
+ guard rails 是确保防止最坏行为的有效方式
+ real-time API当前没有公开微调机制

# 20250401 AI Dev 25 | Justin Uberti: Introduction to the OpenAI Realtime API  4
+ [https://www.youtube.com/watch?v=fHz6s0YmNFo](https://www.youtube.com/watch?v=fHz6s0YmNFo)
+ 你可以给出非常具体的步骤说明，比如首先做什么，然后再做什么。如果用户说了某句话，就跳转到相应的步骤，这几乎就像描述一个小流程图。
+ 我在之前的公司做过的一件事是，我们曾经有一个非常受欢迎的圣诞老人 AI，从12月中旬到12月26日都很火爆。孩子们特别喜欢打电话给它，家长们会让孩子们跟圣诞老人聊天，这实际上是非常神奇的。但我们确保包含的一条规则是，永远不要承诺任何具体的礼物。
+ 99%的准确度对所有企业来说可能还不够，因此我们还有其他方法来解决这个问题，也就是我们所称的“guard rails”
+ 工具调用是一个异步过程，所以在语音仍在输出时，工具调用可以同时进行。
+ 如果你需要等待工具调用以进行进一步生成，比如你在使用 RAG，需要访问一个向量存储获取更多的数据，以便进一步回复，那么你最终会使用一些技巧。助手可能会说：“让我帮你查一下”或“稍等片刻”，类似这样的表达。
+ 再次强调一下，管理好向量存储的延迟及类似问题是很重要的。
+ 模型发送回了一段语音，但因被打断而未传达给用户，因此模型误以为用户已经知晓，但实际上用户并未收到，因此你想要删除这些内容。WebRTC 版本的 API 可以自动做到这一点。如果你打断助手，任何尚未被说出的内容都会自动被清除。
+ 有时我们发现模型会误解用户，那么有没有办法告诉模型：“如果你对刚才听到的内容没有把握，就请提示用户重复一遍”？刚才的问题是模型听错时该怎么办？如果它信心不足，我们能否让它重复一次或请用户再重复一次？实际上，这可以通过提示很好地实现。

