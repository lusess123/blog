# 20250404 OpenAI's Autonomous AI Research Benchmark
+ [https://www.youtube.com/watch?v=SeQU2LNQ5ig](https://www.youtube.com/watch?v=SeQU2LNQ5ig)
+ openAI在X账号上所说，他们将发布 Paperbench——一种用于评估AI智能体复制顶尖AI研究能力的基准测试，作为其“preparedness framework（应对框架）”的一部分。
+ 许多前沿AI实验室都有各自版本的“preparedness framework”。这种框架用于跟踪潜在的AI风险。随着AI模型不断进步，我们希望观察它们可能带来的逐步升级的威胁
+ “模型自主性”，这当然是AI智能体的重要前景，即它们完成长期任务的能力
+ 人类唯一的贡献是选择一个适合该研讨会的广泛主题。
+ 首次完全由AI生成的论文达到了通过标准科学同行评审的水平。
+ 人们可能因为这些结果不够吸引人而不发表，甚至有人可能为了发表而篡改数据，而这正是AI可以发挥巨大作用的地方。
+ AI可能擅长处理那些被视为无聊或不重要的研究
+ Claude 3.5 Sonnet 得到了21分，也就是说，它能够复现21%的论文。
+ 虽然AI目前尚未超过机器学习博士，但我们不应忽视这些AI智能体在复现研究方面展现出的非同一般的能力
+ 一位博士，他花了差不多一年完成的代码库，而 O1 preview 加上 O1 mini 大约在一小时内就搞定了。

# 20250403 AI Dev 25 | Justin Uberti: Introduction to the OpenAI RealTime API 6
+ [https://www.youtube.com/watch?v=fHz6s0YmNFo](https://www.youtube.com/watch?v=fHz6s0YmNFo)
+ RAG 通常用于，当用户提出的问题不在模型的训练集中时，我们就需要去查询它。
+ 向量数据库会用从中检索到的信息来增强对话的上下文。
+ 调用工具后返回的信息，会通过使用 conversation.item.create 这个 API 插入对话中，这样就人为地将一段历史记录推送到了上下文。
+ Real-time API 虽然响应快、对话流畅，但在思考和编码方面表现一般。
+ 目前它支持文本和音频，但还不支持图像。

# 20250402 AI Dev 25 | Justin Uberti: Introduction to the OpenAI RealTime API 5
+ [https://www.youtube.com/watch?v=fHz6s0YmNFo](https://www.youtube.com/watch?v=fHz6s0YmNFo)
+ 如果有人说了一个特定的词，我们将停止音频响应并将助手引导去谈论其他内容。
+ 文本的速度比它播放音频的速度要快，如果我们看到转录文本中不喜欢的内容，我们通常能立即停止音频播放，通常是在音频播放前就能停止
+ guard rails 是确保防止最坏行为的有效方式
+ real-time API当前没有公开微调机制

# 20250401 AI Dev 25 | Justin Uberti: Introduction to the OpenAI Realtime API  4
+ [https://www.youtube.com/watch?v=fHz6s0YmNFo](https://www.youtube.com/watch?v=fHz6s0YmNFo)
+ 你可以给出非常具体的步骤说明，比如首先做什么，然后再做什么。如果用户说了某句话，就跳转到相应的步骤，这几乎就像描述一个小流程图。
+ 我在之前的公司做过的一件事是，我们曾经有一个非常受欢迎的圣诞老人 AI，从12月中旬到12月26日都很火爆。孩子们特别喜欢打电话给它，家长们会让孩子们跟圣诞老人聊天，这实际上是非常神奇的。但我们确保包含的一条规则是，永远不要承诺任何具体的礼物。
+ 99%的准确度对所有企业来说可能还不够，因此我们还有其他方法来解决这个问题，也就是我们所称的“guard rails”
+ 工具调用是一个异步过程，所以在语音仍在输出时，工具调用可以同时进行。
+ 如果你需要等待工具调用以进行进一步生成，比如你在使用 RAG，需要访问一个向量存储获取更多的数据，以便进一步回复，那么你最终会使用一些技巧。助手可能会说：“让我帮你查一下”或“稍等片刻”，类似这样的表达。
+ 再次强调一下，管理好向量存储的延迟及类似问题是很重要的。
+ 模型发送回了一段语音，但因被打断而未传达给用户，因此模型误以为用户已经知晓，但实际上用户并未收到，因此你想要删除这些内容。WebRTC 版本的 API 可以自动做到这一点。如果你打断助手，任何尚未被说出的内容都会自动被清除。
+ 有时我们发现模型会误解用户，那么有没有办法告诉模型：“如果你对刚才听到的内容没有把握，就请提示用户重复一遍”？刚才的问题是模型听错时该怎么办？如果它信心不足，我们能否让它重复一次或请用户再重复一次？实际上，这可以通过提示很好地实现。

