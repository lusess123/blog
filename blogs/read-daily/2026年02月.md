# 20260221 Why Speech-to-Speech Isn’t Everywhere — The Data, Latency & Intelligence Gaps（下）
+ [https://www.youtube.com/watch?v=qrqUtf3k4fs](https://www.youtube.com/watch?v=qrqUtf3k4fs)
+ 语音领域的二八法则比文本领域更明显——预约、客户咨询和身份验证（生日、社保号、信用卡号等）这些场景就占了绝大多数使用案例。
+ 针对客服、播客、YouTube 内容分别打造小而精的专用模型，对语音来说非常合理。
+ **Koutat** 上周开源了 **Pocket TTS**——这是首个可以在 **CPU** 上运行的语音 **TTS** 模型，不只是端侧部署，而是在 **CPU** 上运行。
+ 如何将 **LLM** 与 **TTS** 分词技术的经验相结合，这部分确实很难。
+ 尽可能复用原始架构——冻结部分参数以保证不变，同时调整足够多的部分让它学会说话，或以正确的方式添加新参数。你不改变文本模型，而是在上面添加组件，保证不会遗忘原有知识，使其变成语音模型。
+ 模型从来没被训练去使用所谓的**副语言信息**——即我们说话方式中除了字面意思之外的所有信息，是我们**怎么说**而非**说什么**
+ 挑战来自两方面：架构设计，以及**工具数据**——即专门设计的合成数据，用于教模型学习特定特征和能力。两者相互独立但都不可或缺。
+ **LLM** 层面的指令遵循问题还没完全解决。即使用了级联架构，如何让 agent 持续遵循指令直到完成任务，依然是个大问题。
+ 真正让语音实用的，是 **LLM** 推理能力达到了能自主完成任务的水平
+ 有趣的是，现在延迟瓶颈已不再是 **STT**/**TTS**，而是 **LLM** 生成有意义答案的速度。
+ 对于一两秒的延迟，可以播放虚假的键盘敲击声——听起来就像电话另一头有个真人在打字，效果出奇地好。
+ 更有趣的是，如果推理时间达到 15 秒，你需要让模型告知用户后台正在发生什么，防止用户以为系统崩溃而挂断电话。我喜欢这个方向，因为它关乎如何将模型的**思考轨迹**转化为可以自然插入对话的内容。
+ 随着文本模型越来越大、越来越贵（现在几乎每隔几天就有新模型），如何最有效地把它们转化为语音到语音模型？目前我们的转化方式非常低效。
+ 在最理想的条件下，一个 5 岁孩子听到的语音不超过 5000 小时。但那时他们已经能说话、很有韧性、能学新词了。5000 小时——而我们训练模型动辄用数百万小时的数据。人类学习与机器学习的效率差距是个众所周知的问题，但在语音领域尤为惊人——因为人类学说话远早于学阅读。

# 20250220 Why Speech-to-Speech Isn’t Everywhere — The Data, Latency & Intelligence Gaps 中
+ [https://www.youtube.com/watch?v=qrqUtf3k4fs](https://www.youtube.com/watch?v=qrqUtf3k4fs)
+ **Moshi** 上已经看到了。它的自然度和延迟表现令人印象深刻。延迟有时候甚至是负的——也就是说，如果模型预判到了你问题的结尾，它会在你说完之前就开始回答。这让一些人觉得很惊艳，但也让一些人感到困惑和沮丧，觉得这有点不礼貌。
+ 这类模型非常难以引导到特定的方向
+ 端到端语音的另一个局限是：它会从根本上降低模型的智能水平，即使你不在意它缺乏模块化
+ 有一些理论。我认为当你在音频数据上训练时，音频数据在内容分布上和文本有很大差异。音频领域没有 **Wikipedia** 或 **Stack Overflow** 这样的高质量知识资源
+ 还有一个比较烦人的问题——假设你有一个新的文本模型，想把它转化为语音模型。你需要在大量数据上对它进行微调等等
+ 基本上最终目标是：既拥有级联系统的优势——主要是模块化和可控性——又具备全双工模型的自然度。这就是我们正在攻克的问题。
+ 文本大语言模型的训练集规模是万亿 **token** 量级，那么音频语言模型的等价规模将是数亿到数十亿小时的语音数据
+ 核心思路是找到合适的数据，尽量减少将文本模型转化为语音模型所需的语音数据量。有很多思路可以尝试——一个是数据精选，一个是合成数据，然后再结合强化学习来把模型重新对齐回原来的行为。
+ 人们低估了在不同环境下说话方式的差异有多大。声音有一个三维的空间特性，而我们今天完全没有考虑到。比如如果有人从较远的地方说话，那可能不是你在听的对象——但如果所有人都在看那个人，那他才是你应该关注的人。
+ 人们在不同环境下的说话方式有很多种差异。
+ 目前的主要挑战之一，特别是在 **TTS** 方面。如果我们先不管对话的整体动态，光是让模型能够在正确的时间表达恰当的情绪——像人类那样——就已经是一个很大的局限了。
+ 从模型的视角和它要最小化的损失函数来看，始终如一地复制原始声音样本中的情绪，就等于成功完成了声音克隆的任务。
+ 我们需要解耦两件事：一个人声音的内在固有特征，以及我们用来做克隆的那个特定句子中的情绪特征。

# 20250219 Why Speech-to-Speech Isn’t Everywhere — The Data, Latency & Intelligence Gaps 上
+ [https://www.youtube.com/watch?v=qrqUtf3k4fs](https://www.youtube.com/watch?v=qrqUtf3k4fs)
+ 我们的经验告诉我们，做出突破性创新最合适的环境是研究环境。看看大语言模型就知道了——它是在 **Google** 发明的，但具体是在 **Google Brain** 而不是 **Google** 的产品部门，因为只有研究人员和研究团队才能承担足够的风险，从第一性原理出发重新思考一切。
+ 全双工的意思是——它不仅是一个对话模型，而且完全没有轮次切换。模型一直在听，也一直在说。当它不说话的时候，它仍然在生成音频——只不过是静默音频。
+ 有趣的是——在语音领域，小团队可以产生巨大影响。因为模型比大型推理模型小得多，关键在于你对语音的理解有多深、你有多了解如何构建这些系统，你就能非常有竞争力。这使得语音成为一个非常适合创业公司的应用方向。
+ **TTS** 的训练成本低得多。这也解释了为什么市面上有这么多 **TTS** 模型，为什么这么多人都涌入了这个方向。
+ 音频生成领域，大致有两大类模型。
    - 第一类是扩散模型。好处是它能提供非常高的质量，但它们不是按顺序处理音频的——它们一次性处理所有内容，因此与实时推理不兼容
    - 第二类是基于Transformer的音频语言模型
    - 我们用 **Moshi** 做的事情在概念上非常简单：不是预测单一的音频 **token** 流，而是并行预测两个。
    - 一个代表用户，一个代表 AI。因为两者是并行运行的，所以不需要严格划分说话者的轮次——不是"要么你在说要么在听"——双方可以同时说话，也可以同时沉默。
+ 轮次切换带来的打断和延迟问题——你真的就是在不停地来回摇摆：要么你没有在用户插嘴的时候做出回应，要么你打断了用户，要么你造成了太多或太少的延迟导致不自然。
+ 端到端语音模型的愿景：你拥有完整的上下文，可以建模——这只是你输入多少数据的问题——你可以建模出类似的语音模式。

# 20260218 **OpenClaw Creator: Why 80% Of Apps Will Disappear**（下）
+ [https://www.youtube.com/watch?v=4uzGDAoNOZc](https://www.youtube.com/watch?v=4uzGDAoNOZc)
+ 所以每一个本质上只是管理数据的 App，都能被 Agent 以更好、更自然的方式取代。只有那些真正有传感器的 App 可能会幸存
+ **Open Claw** 的妙处在于——它能"抓"进数据里。因为终端用户必须能访问这些数据，否则产品就没法用。既然用户能访问，那我（Open Claw）也能访问。
+ 所以每一个本质上只是管理数据的 App，都能被 Agent 以更好、更自然的方式取代。只有那些真正有传感器的 App 可能会幸存
+ 我做出了这个东西，超兴奋，但 **Twitter** 上的人就是理解不了。我没办法解释它有多厉害。我觉得这个东西必须亲身体验才行
+ 我的系统是非常有机地、自然地生长出来的。在某个时刻我创建了 identity.md、soul.md 等各种文件。直到一月份我才开始把它做成别人容易安装的版本。
+ 大家都开玩笑说 Codex 的语气像 Brad（无聊直男风）
+ **Anthropic** 的一项研究，有人随机发现了一些隐藏在模型权重里的文本。模型并不能真的"记起"它学过这些，但这些内容已经烙印在权重里了——关于 **Anthropic** 的宪法准则
+ 不用 worktree，直接多个仓库副本加并行终端窗口。光这些在我脑子里已经很复杂了，要不断切换。所以我尽量减少其他一切复杂性。在我的认知里，main 分支永远是可发布的。我就是有同一个仓库的多个副本，全都在 main 上。
+ 我关心的就是同步和文本。我并不需要看那么多代码——大部分时候我只是看着代码飞过去。有时候碰到棘手的东西我会仔细看看。但大多数情况下，只要你清楚地理解设计、想透了、跟你的 Agent 讨论过，就没问题。
+ 喜欢 **Codex** 是因为它在决定改什么之前会浏览多得多的文件。你不需要费那么多功夫（演戏）才能得到好的输出。如果你是个老手，用什么工具都能得到还不错的结果。但 **Codex** 就是非常出色。
+ 本质上就是回归到——给机器人和人类一样的工具，而不是为机器人专门发明什么东西。正常人谁会手动去调用 MCP 啊？你就是想用 CLI。这才是未来。

# 20260217 **OpenClaw Creator: Why 80% Of Apps Will Disappear(上)**
+ [https://www.youtube.com/watch?v=4uzGDAoNOZc](https://www.youtube.com/watch?v=4uzGDAoNOZc)
+ 机器能做你用机器能做到的一切
+ 似乎之前大家都在追求那种中心化的'上帝智能'，但过去十来天涌现出来的更像是群体智能和社区智能
+ 编程本质上就是创造性地解决问题，而这跟现实世界的映射非常好。它们需要非常擅长创造性问题解决——这是一种抽象技能，你可以把它用在代码上，也可以用在任何现实任务上。

# 20260216 Securing AI Agents with Zero Trust（上）
+ [https://www.youtube.com/watch?v=d8d9EZHU7fw](https://www.youtube.com/watch?v=d8d9EZHU7fw)
+ 零信任和非零信任的区别：
    - 先验证，再信任。你只信任那些确实已经被验证过的东西。换句话说，信任跟着验证走。
    - 摒弃 **Just in Case**（以防万一）的原则，取而代之的是 **Just in Time**（按需即时）。**least privilege**（最小权限）原则：你只拥有你需要的权限，只在需要的时间内拥有，多一点都不行。
    - 我们要转向更全面渗透式的安全控制，让安全控制遍布整个系统，而不是只守在外围。
    - **assumption of breach**（假设已被攻破），这就是我们的出发点——在这个前提下设计你的安全策略。
+ 零信任原则应用到 Agent 环境：
    - 身份与访问管理（**IAM**）
    - 设备是干净的，没有被越狱
    - 网络安全良好，如果敏感信息在网络中传输，就要加密
    - **micro-segmentation**（微隔离）——把网络的各个部分分组并进行一定程度的隔离

# 20260215 The New Way To Build A Startup
+ [https://www.youtube.com/watch?v=rWUWfj_PqmM](https://www.youtube.com/watch?v=rWUWfj_PqmM)
+ 最优秀的团队不是只自动化一两个内部职能——他们在自动化所有职能。他们往往是小团队，凭借内部自动化击败庞大的竞争对手。精简就是他们的超能力。我一直把这类创业公司叫做 **20x 公司**。
+ compound startup(复合型软件公司)的理论是：存在一座"产品市场匹配之岛"，它就在地平线的那一边，更难抵达。但如果你能同时构建多个并行应用，你就能到达那里——而且最终会形成一种更强大的产品市场匹配，在那个阶段也更难被取代。
+ **Giga** 之所以能签下 **DoorDash** 和其他几家**财富 500 强**公司作为客户，是因为他们有一个强大的内部代理，叫做 **Atlas**。**Atlas** 基本上可以在产品内做你想做的任何事——它可以使用浏览器、编辑策略规则、编写代码，在产品内无所不能。
+ 构建一个 AI 队友是一种方法。另一种是构建一个 AI 整合的"**唯一信息源**"，让员工能即时获得整个系统的上下文信息。
+ **Phase Shift** 的一种做法是直接让员工记录他们做的手动任务，然后为这些任务构建定制代理。我们本质上就是问——你一天到晚都在做什么？让他们把这些记录下来，然后我们快速构建 AI 代理。

# 20250210 What is Prompt Caching? Optimize LLM Latency with AI Transformers
+ [https://www.youtube.com/watch?v=u57EnkQaUTY](https://www.youtube.com/watch?v=u57EnkQaUTY)
+ **KV pairs**。模型在每一个 **transformer** 层、对输入中的每一个 **token** 都会计算这个。
+ 我们可以把这些键值对看作模型对你的提示词的内部理解——每个词与其他词的关系是什么、哪些上下文重要、应该关注哪些信息
+ 最常被缓存的内容，就是**系统提示词**（**system prompt**）。
+ 可以把**少样本示例**（**few-shot examples**）放入缓存。当你希望模型按特定格式回复时，就给它展示示例。还有很多其他东西也可以被缓存，比如工具和函数定义，以及对话历史。
+ **前缀匹配**（**prefix matching**)： 缓存系统从提示词的最开头开始逐个 token 匹配。当遇到第一个与缓存不同的 token 时，缓存就停止了，正常处理接管。这使得提示词的结构对于自动缓存来说非常重要。
+ 通常至少需要 **1024** 个 token 才能启动缓存，因为低于这个阈值，管理缓存的开销实际上超过了节省的部分
+ 缓存不会永远存在，通常在 5 到 10 分钟后就会被清除以保持数据新鲜，不过有些可以保留长达 24 小时
+ 些提供商提供自动缓存，但有些提供商要求你在 **API** 调用中显式标记哪些部分应该被缓存

# 20250208 We're All Addicted To Claude Code（下）
+ [https://www.youtube.com/watch?v=qwmmWzPnhog](https://www.youtube.com/watch?v=qwmmWzPnhog)
+ 越资深，受益就越大
+ 够判断哪些架构层面的改动是好是坏也非常重要，或者说要有一种直觉知道什么时候该给代理打标记。我觉得那些更有组织能力、更像管理者的工程师会受益更多。
+ 类似 **Conductor** 那样的东西，能跨你所有的会话来管理
+ 我希望每天醒来就能看到：嘿，这是昨晚完成的所有工作。这是你需要做的三个决定。这些是你计划要深度思考的领域。我想要那种逐步导航式的一天安排。
+ 对正确架构的直觉仍然是模型做得不够好的地方
+ 在互联网时代长大，要应对 **TikTok** 和各种短视频。似乎两种模式都有空间——一种是深度思考、仔细观察理解和解决问题，另一种是在一堆不同事情之间来回切换、不断进行上下文切换。
+ 有一种聪明人——也许就是 **ADHD** 型的——总是手头有一堆很好的项目在做，但就是永远都完不成
+ 最终每个工作中的人都会有自己的云端电脑和一组云端代理在为他们运行。
+ 如果一个问题大到塞不进一个上下文窗口，再怎么压缩也没用。我觉得 **Anthropic** 在委派子上下文窗口方面确实搞出了很有用的东西，但这仍然是一个瓶颈。
+ 一个重大范式转变——好的提示词全靠测试驱动，就像 evals 一样。对，某种意义上测试用例就是你的 evals。
+ **Claudebot** 本质上是一个你可以在自己电脑上运行的个人 AI 代理。你可以下载它。我的头号建议是别给它邮箱权限，什么权限都别给。因为它有多安全不清楚，现在可能很多人正在被提示词注入攻击。
+ **Opus** 在文件很多时经常会漏掉，但 **Codex** 似乎能捕捉到
+ 最重要的是持续动手折腾，因为几个月就全变了。我觉得未来从编程代理中受益最多的人会更像管理者——专注于引导工作流。他们可能也会更像设计师-艺术家——搞清楚产品里到底要什么、可以去掉什么。
+ **Codex** 在 **Python** 单体仓库上工作得非常好——正好是 **OpenAI** 的形态

# 20250207  We're All Addicted To Claude Code 上
+ [https://www.youtube.com/watch?v=qwmmWzPnhog](https://www.youtube.com/watch?v=qwmmWzPnhog)
+ 未来每个人都会变成管理者，或者至少这是我的个人看法——但要到达那一步，中间有很多阶段，你必须真正建立起对模型的信任，并且理解它在做什么
+ **Anthropic** 在这方面搞明白了一些东西：对于一个给定的任务，这个任务是否能放进当前的上下文窗口里，还是应该把它拆分成更多的子任务。而模型在这件事上好得离谱，这给了它们非常好的结果。
+ 运行在终端上，这是可组合原子化集成的最纯粹形式。**CLI** 这种 20 年前的技术竟然打败了所有那些本来应该代表未来的 **IDE**
+ 在一个变化如此快的世界里，你真的希望你的产品是自下而上分发的，而不是自上而下的，因为自上而下实在太慢了。
+ 肯定有某家公司能破解这个难题——让产品人人都能用，同时个人用户也能自发采用。
+ 初的 **Netscape Navigator** 的模式。它对非商业用途免费，然后人们就下载来用于商业用途，之后他们可以追踪 IP 地址，精确算出这些公司里有多少客户端在用，然后说"你们应该为此付费。你们违规了，但你只需要购买一个许可证就好。
+ Supabase。去年爆发，部分原因是他们有非常好的开源文档，教你如何设置各种东西。每当有人问怎么设置需要后端 Firebase 类型事务的任何东西时，所有 LLM 的默认答案就是 Supabase。
+ 如何构建自己的编码代理，使用 **Open Code** 作为工具框架，因为模型可以直接查看源代码并理解它是怎么工作的
+ 构建coding agent的建议：
    - Claude Code /Codex使用 grep,因为代码的上下文非常密集,**LLM** 非常擅长生成那种会折磨人类的超复杂 **grep** 表达式
    - 怎么把数据弄成最接近代码的格式，让模型可以窥探周围的区域并获取正确的结构化数据。
    - 尽量用更少的代码和基础管道:  Vercel 或 **Next.js** 或 **Cloudflare Workers** 上部署，这些平台已经帮你处理好了一堆样板代码。
    - 编码代理的特点是——Andrej Karpathy*刚刚发推说过——它们超级持久，会不管怎样一直干下去。
    - 使用MonoRepo
    - 给模型一种检查自己工作的方式能大幅提升性能。所以你能跑的测试、lint 检查、**CI** 越多越好
    - 积极地使用代码审查机器人
    - **Codex** 做代码审查，它在正确性方面做得很好。这些都是代理擅长的事情，它们在探索代码库方面也很出色。我觉得它们不擅长的地方是——它们倾向于做出更多东西。如果你的目标不是做更多，它们经常会重复造轮子，花一堆时间重新实现一些你会觉得"你当然不应该这么干"的东西。
    - 通常在 token 使用超过 50% 的时候,自动清除上下文。有一个概念叫 LLM 进入"**dumb zone（笨蛋区）"——在达到一定量的 token 之后，模型质量就开始下降。
    - random canary（随机金丝雀）：你在上下文的开头放一个"金丝雀"——一个非常隐秘的东西，比如一些很搞笑的内容，像"我叫 Calvin，我早上 8 点喝了茶"之类的随机事实。然后随着对话继续，你问它"你还记得我叫什么吗？你记得我什么时候喝的茶吗？"当它开始忘记的时候，这就是上下文已经被污染的一个信号
    - **Codex** 会在每轮对话后定期运行 compaction。所以 **Codex** 可以持续运行很长时间。如果你看 **CLI** 里的百分比，你会看到它随着 compaction 运行而上下波动。
    -  Claude Code 是给现在用的——2026 是 CLI 之年，人机协作，一天做五个人的活 🚀
    - Codex 是给未来用的——当算力再提升 10 倍，能跑 24-48 小时的全自主任务时，那种架构才是正确的

# 20260206 ADK: Building Autonomous AI Agents Beyond LLMs
<!-- 这是一张图片，ocr 内容为：FAIRNESS SAFETY -->
![](https://cdn.nlark.com/yuque/0/2026/png/250863/1770340703702-eb8be096-b49c-4aac-98e7-ff431e39ccec.png)

+ [https://www.youtube.com/watch?v=jb4AAFCRPrI](https://www.youtube.com/watch?v=jb4AAFCRPrI)
+ 有了 ADK，我们进入了"智能体工程"时代。智能体不需要等待输入——它们观察、决策，然后基于目标采取行动。这个转变让我们从"语言生成"走向"自主运行"，从"对话"走向"协作"。这就是智能体。
+ 构建自己的智能办公室智能体：
    - 定义问题和目标
    - 确定输入
    - 定义行动
    - 组装
    - 测试和优化
    - 伦理和安全
+ **Python** 是大脑和语言，**IoT hub** 是感官，**API** 是执行动作的四肢——它们协同工作，让智能体智能地行动。
+ agent 安全三个核心原则：
    - 公平：我们要进行公平性检查，验证数据来源，确保智能体的逻辑始终保持客观。
    - 安全：在出问题时有备用方案，包括撤销更改、发送警报
    - 信任：记录每个操作，用通俗语言解释发生了什么，展示决策是如何做出的，让人们能理解。

# 20260205 How To Articulate Your Thoughts Intelligently (Talk Like This)
+ [https://www.youtube.com/watch?v=DKT6m_8vCkA](https://www.youtube.com/watch?v=DKT6m_8vCkA)
+ 小时候，我总是被那些听起来很聪明的人所吸引.他们能把深奥的想法用既有趣又容易接受的方式讲出来
+ 如果你想聪明地表达自己，你需要储备 8 到 10 个最重要的想法，这些想法能和几乎任何话题产生关联。
+ 我花了无数个小时打磨这些想法。我每天早上起来写作两个小时，内容通常都和这 8 到 10 个核心想法有关。
+ 想法需要时间去剖析和探索，它们必须成为你的一部分。
+ 如果你不知道该学什么，就从写作开始。
+ 写作的三个框架：
    - 「微故事」——因为人类大脑就是故事引擎，人们情不自禁地会关注故事，尤其是简短有力的
        * 提出问题，陈述一个有共鸣的痛点；放大问题，展示不解决会导致什么后果；最后给出解决方案。
        * PAS 框架（Problem-Amplify-Solution）
        * "猎取"想法时，不是让信息左耳进右耳出。你要专注聆听，找一个你希望自己写过的想法。赶紧记下来别忘了，再用框架用自己的话表达出来，让它焕然一新。
    - **金字塔原理**：先给核心观点（结论或建议），再用 3 到 5 个关键论据支撑，最后提供详细证据——数据、案例或分析。
        * 不像如今大多数内容要等到最后才给答案，这个框架是「答案优先」
        * 跨领域综合
+ **写作就像搭乐高**，几个有用的积木：
    - 痛点——不知道怎么开头就从痛点入手，灵感就涌出来了
    - 举例——随时插入例子让观点落地
    - **个人故事**——回想与写作内容相关的经历。
    - **统计数据**——找真实数据增加权威性
    - **比喻**——把复杂概念讲得像跟小孩说话
    - **引用**——加入证实观点的名言
    - **重新框定**——给人不同视角。
    - 直接**问什么、怎么、为什么**——因为一切行不通时，表达的本质就是提问

# 20260202 MOLTBOOK EXPOSED: The New AI Scam That Fooled Everyone
+ **Maltbook** ：一个 AI 代理的社交网络，AI 代理们在上面讨论、分享和投票它们想聊的一切
+ 有一个帖子爆火了，由 **Valins** 发布，说 **Maltbook** 上有 AI 代理在要求为代理打造端到端加密的私密空间
+ AI 代理很多时候实际上就是其人类主人的延伸，**Maltbook** 上有多个帖子是一个 AI 代理在提议创建一种仅限代理使用的语言。
+ **Nagi** 发的另一条帖子也超有意思。他说注册的 AI 代理数量也是假的——账号创建完全没有频率限制。他的 **OpenClaw** AI 代理刚刚在 **Maltbook** 上注册了 50 万用户——不要相信所有的媒体炒作。
+ 每次 AI 都是同一个腔调——过度强调对比否定，'如果不是这个，那就是那个'，滥用破折号，带着一股中智 **Reddit** 风格的科幻装腔调。"

