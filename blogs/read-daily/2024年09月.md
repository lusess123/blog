# 20241029 Sam Altman SHOCKING "Catalysts of Change" Interview (never before seen footage) #每日陪读
+ [https://www.youtube.com/watch?v=ydPVL0HGpJ4](https://www.youtube.com/watch?v=ydPVL0HGpJ4)
+ 资本主义是世界上曾经见过的最糟糕的经济系统，但比其他所有系统都好。
+ 当你身处一个组织中时，特别是如果你担任领导角色，坚持不动摇是多么重要，因为最终你需要在组织的方向上保持坚定。
+ 1747年在Chin这里发生了一场非常重要的战斗，近4000人战胜了40万法国人，他们称之为Bujan，意思是不要动。
+ 一些你会大声说出来的事情和一些你会用文字表达的事情，它们有些许不同
+ 推理能力将是人们在编程和科学发现中使用AI的一个重大突破
+ 快速成长的真实体验是无法通过他人预先描述获得的
+ 语音功能能像我所见到的那样好，想象一下这种能力在车内的应用，如何能够完全改变你与车的互动方式
+ 引擎的制造实际上比整辆车的时间更长
+ 在接下来的十年或几十年里，我最感兴趣的两大趋势是丰富的智能和丰富的能源，以及我们将从这两者中获得的繁荣，这两件事大约在同一时间得以实现

# 20240926   BREAKING: Sam Altman STUNNED As Top Employees LEAVE OpenAI #每日陪读
+ [https://www.youtube.com/watch?v=gKk-TF1ZE0M](https://www.youtube.com/watch?v=gKk-TF1ZE0M)
+ 语音到语音技术和OpenAI o1 的发布，认为这是互动和智能新时代的开始
+ 《纽约时报》泄露的信息称，OpenAI的关键高管Mira Murati在Sam Altman被驱逐事件中起了关键作用
+ Mira说她离开的原因是想为自己的探索创造时间和空间。

# 20240924 THE INTELLIGENCE AGE by Sam Altman "...we will have superintelligence in a few thousand days" (上) #每日陪读
+ [https://www.youtube.com/watch?v=evDI1a6E8JY](https://www.youtube.com/watch?v=evDI1a6E8JY)
+ 在2016年、2017年，当他们创立OpenAI时，他宣称他们正在构建AGI（人工通用智能）。在当时，这被认为是无稽之谈，是可笑的。
+ 智能机器本身帮助我们制造更智能的机器，这种创新的递归循环将加速革命的步伐。
+ 在未来的几十年里，我们将能够做到一些在我们祖父母看来像魔法一样的事情。
+ 在某种重要意义上，社会本身就是一种高级智能的形式。
+ 如果我们允许掌握性学习，这意味着你可以按照自己的进度学习，孩子们的表现将提高一个标准差。
+ 在未来，每个人的生活都可能比现在的任何人更好。
+ 我们让沙子思考。这听起来有点怪异，但如果你真正理解这意味着什么，这有点像当你看着银河系，看到所有的星星和星系时，你意识到自己在宇宙中是多么渺小。
+ 我们如何迈向下一个繁荣飞跃的门槛？三个词：深度学习奏效了。
+ 它是隐式学习，而不是显式学习。不是我们告诉它事物的工作原理，然后它学习。我们给它我们收集的数据，它非常快地弄清楚了事物的工作原理。
+ Sam Altman所说：“我发现，无论我花多少时间思考这个问题，我都无法真正理解它的重要性。”
+ 如果我们不建设足够的基础设施，人工智能将成为一种非常有限的资源，甚至会为此爆发战争，并且最终成为富人的工具。

# 20240923 AI prompt engineering: A deep dive（下） #每日陪读
+ 过度拟人化，从根本上说，它通过在推理过程中迈出错误的一步，破坏了推理的主题
+ 如果你想要更多的灵活性和多样性，你会使用说明性的例子，而不是具体的例子。
+ 使用例子的直觉实际上也源自预训练，但它似乎不适用于RLHF模型
+ 与这些模型对话的框架，在某种程度上它们几乎像是模仿者。
+ 聊天设置中，你可以让人类保持在循环中，并不断地来回调整。而当你编写一个支持聊天机器人系统的提示时，它必须涵盖它可能遇到的所有情况。
+ 几个学习提示词的建议：
    - 阅读提示，阅读模型输出。多看，多学习
    - 将你的提示给另一个人看看可能会有所帮助，尤其是给那些对你所做的事情没有背景了解的人。
    - 找到你能想到的最难的事情，然后去尝试做它。即使你失败了，你往往会学到很多关于模型如何工作的知识。
+ 最好的东西总是短暂的。
+ 一个非常保守的观点是，未来我们将更多地使用模型来帮助我们进行提示。人们会逐渐习惯将模型融入他们所做的一切，尤其是与提示相关的事情。
+ 如果模型能力比人强，提示工程变成了一种我问问题、向模型解释我想要什么，然后模型反过来提示我
+ 我发现最难的事情是从我的大脑中提取出正确的信息。
+ 提示工程可能确实会消失，如果模型变得如此强大，它们所需要做的只是从你的大脑中获取信息，然后就可以去完成任务。
+ 提示工程的核心：外化你的大脑，然后我们会把它剪掉。

# 20240922 Microsoft Goes FULL NUCLEAR to Develop AGI... #每日陪读
+ [https://www.youtube.com/watch?v=T301T6H9l34&t=24s](https://www.youtube.com/watch?v=T301T6H9l34&t=24s)
+ 微软重新启动导致美国历史上最严重核事故的核电站，目的是为了满足他们对AI的能源需求
+ 核燃料的能量密度极高。一吨煤炭产生的能量与120加仑石油相同，且与一个微小的铀颗粒相同。
+ 在福岛和切尔诺贝利之前，我们还有三里岛，这是美国本土的一次核事故。
+ 虽然GrimMo不是最小的，但它绝对是这里最小的模型之一，同时也是最好的
+ AI将承担大量繁重的工作，工程师们将被提升到更高的任务，如监督、规划和整合各部分。
+ 在这个HumanEval测试中，不到70亿参数的情况下，GrinMo达到了74.4%
+ 有一种现象叫“语义饱和”——就像当你多次重复一个词时，它失去了所有意义
+ o1一个非常重要的进步，我认为关于这些新范式时刻的有趣之处之一是改进曲线非常陡峭。
+ 五个我们讨论的AI级别:
    - 1.chatbots 聊天机器人
    - 2.reasoners 推理机， o1 刚刚达到的
    - 3.agents 代理
    - 4.innovators 创新者
    - 5.full organizations 完整的组织
+ 从一级到二级的转变花了一段时间，但我认为关于二级最令人兴奋的事情之一是它能在之后相对迅速地实现三级。

# 20240921 AI prompt engineering: A deep dive（中） #每日陪读
+ [https://www.youtube.com/watch?v=T9aRN5JkmL8&t=1264s](https://www.youtube.com/watch?v=T9aRN5JkmL8&t=1264s)
+ 关于文本的直觉转移到图像上的情况少得令人惊讶
+ 告诉模型你正在玩口袋工厂的游戏
+ 最著名的提示技巧之一，就是告诉语言模型它们是某个角色或扮演某个角色：
    - 为了让 claude玩口袋工厂的游戏，告诉Claude它是一个盲人使用的屏幕阅读器，效果很好
+ 有时候需要对模型诚实，现在模型能力越来越强，没有必要对他撒谎，没必要做一些牵强的角色扮演。“如果他们理解这件事，就直接让他们做你想要的事情。”
+ 有些情况下，不完全是撒谎，而是给它一个如何思考的比喻，可能会有帮助。
    - 问模型如果这张图表是作为高中作业提交的，它会给出什么样的评分。
+ 模型能力越来越强，告诉他真相，你是大语言模型目前正在嵌入产品， 你不是一个人
+ 要非常明确地规定某个东西的使用具体场景
+ 我对角色提示的最大担忧是，人们把它当作想让模型执行的类似任务的捷径
+ 这可能是从预训练模型转移到RLHF模型的直觉
+ 给模型留有余地。这是人们在提示中经常忘记的事情。发生了真正意外的输入，就给它一些可以做的事情。
+ 过度拟人化推理可能有害，因为它会让我们失去我们试图在这里做的事情的主线。
+ 思维链并非是一个可以反复进行注意力计算的空间

# 20240920 AI prompt engineering: A deep dive (上)#每日陪读
+ [https://www.youtube.com/watch?v=T9aRN5JkmL8&t=8s](https://www.youtube.com/watch?v=T9aRN5JkmL8&t=8s)
+ 什么是Prompt Engineering？为什么叫做Engineering？究竟什么是Prompt？
+ 我觉得Prompt Engineering是在尝试让模型执行任务，尽量发挥模型的最大潜力。尝试与模型合作，完成你原本无法完成的事情。
+ 我认为，从本质上讲，跟模型对话很像和人对话。并且深入理解模型的心理
+ 而“工程”这个部分的意思是不断的试验和错误。能够与模型来回交互并反复修改这个消息，每次都能恢复到初始状态，这个过程就是“工程”的部分。还有另一个方面，就是将提示集成到你整个系统中。关于如何围绕模型构建系统，有足够多的系统性思考。
+ 与模型对话与与人对话不同的一个好处是你可以有一个重启按钮。这个巨大的重置功能让你可以从头开始。
+ 事实是，现在我们确实在写文章时把它们当作代码对待，我认为这是正确的。
+ 说清晰的沟通能力和反复迭代的能力是关键。还要考虑你的提示可能出错的方式
+ 你实际上需要做的是找到那些不寻常的案例。
+ 作为一个好的作家与作为一个好的提示工程师的相关性并不像人们可能认为的那样
+ 他们会在他们的提示中放入逐步思考。他们不会检查以确保模型实际上是在逐步思考，因为模型可能会以更抽象的方式接受它
+ 作为一个提示工程师，有那种奇怪的心理理论部分，你得考虑模型将如何看待你的指令。
+ 要剥离你所有的假设，并能够非常清晰地传达模型所需的全部事实信息集，这是一项极具挑战性的事情。
+ “你做错了这个。你能想想为什么吗？你能不能也许写出一个修改版的我的指令，让你不再犯错误？”很多时候，模型就能做对。
+ 当前的模型并不擅长像人类那样提出好的、探究性的问题作为回应。
+ 任何时候你回到模型或与模型来回交流，你都会学到一些关于正在发生的事情的信息。
+ 我认为我从不信任模型，然后我只是不断敲打它。模型是有点奇怪的。如果你稍微偏离了分布，你就会进入它们未经训练或不寻常的领域。

# 20240919 Ex-OpenAI Employee LEAKED DOC TO CONGRESS! #每日陪读
+ [https://www.youtube.com/watch?v=-1tPBqnEN5Y&t=16s](https://www.youtube.com/watch?v=-1tPBqnEN5Y&t=16s)
+ OpenAI距离解锁人工通用智能（AGI）比大多数人所相信或理解的更近，可能只需要3年时间
+ AGI是一个高度自主的系统，因此我们一直用“agents”这个词来指代这种自主代理。拥有自主权，能够出去追求长期目标，计划、调整变化或应对意外障碍的东西。
+ 现在OpenAI推出了一种新技术，叫做“测试时计算”；它在回答问题时给予更多的计算资源、更多的硬件和更多的算力，基本上就是让它在回答之前进行思考。
+ 令人惊讶的是，“01迷你版”在AIM测试中的表现实际上比“01预览版”更好，可能是因为预览版受到了限制；可能在思考能力上有一些限制
+ OpenAI将AGI定义为一种在大多数经济上有价值的工作中表现优于人类的高度自主系统。
+ 自动化系统可能会导致人类灭绝。这一点已经被AI公司自身、全球各国政府以及其他AI专家所承认。

# 20240918 Sam Altman Teases Orion (GPT-5) 🍓 o1 tests at 120 IQ 🍓 1 year of PHD work done in 1 hour... #每日陪读
+ [https://www.youtube.com/watch?v=nZHGYGUjo9Q](https://www.youtube.com/watch?v=nZHGYGUjo9Q)
+ Strawberry模型最重要的应用之一就是为Orion生成高质量的训练数据。
+ 一位从事黑洞等研究的物理学家意识到01能够在1小时内写出他花了一年时间编写的博士代码。
+ 大多数聊天机器人，大型语言模型，它们的智商大约低于平均智商，低于人类的平均智商。
+ parsec（秒差距）： 这是个长度单位
+ 你给它更多的思考时间，花更多的推理成本，但它的表现越来越好。
+ Jim Fan博士所说，“这可能是自2022年原始 the original Chinchillascaling laws 以来LLM研究中最重要的图表。”
+ 正如Jim Fan博士继续指出的那样，人们一直通过推测训练缩放定律来预测LLM能力的停滞，然而他们没有预见到推理缩放才是真正打破收益递减的关键。
+ 二月份发文指出，没有一个自我改进的LLM算法能够超过三轮的提升。我们很可能已经突破了这个瓶颈
+ 事实上，一旦它们开始自我对弈，我们经常看到它们的能力超越了人类玩家。
+ Jim Fan博士所说，我们终于看到推理时间缩放的范式在生产中得到推广和应用。这个概念是，我们不仅仅是在减少训练计算——就像Ethan Mollick谈到的第三代、第四代模型——我们还在增加训练计算，同时更加关注推理计算。
+ Strawberry创造了一个全新的范式，为他人提供了模仿的全新理念，也塑造了一种新的世界观，其他人现在会相信并追随它。



# 20240917  Google's New AI Feature is UNREAL... #每日陪读
+ [https://www.youtube.com/watch?v=b7GJ45oKQww](https://www.youtube.com/watch?v=b7GJ45oKQww)
+ 这正是价值百万美元的问题。它能够以这些非常令人印象深刻的方式重新混合和组合现有元素。
+ 特斯拉机器人仅仅只需比你好 5%，就可以改变整个美国制造业的规则
+ “劳动分摊”基本上是指公司有多少资金用于支付员工工资
+ 对于那些支付员工工资已经是他们成本中很小部分的行业，机器人就不那么有意义了。即使机器人能胜任这些工作。
+ 记住这一点：变化很快。今天看似不可能的东西，明天可能就像你的智能手机一样普通。

# 20240915 this AI is a little bit _TOO_ good... #每日陪读
+ [https://www.youtube.com/watch?v=71SPKzfGntY](https://www.youtube.com/watch?v=71SPKzfGntY)
+ 马克·吐温曾经著名地说过：“有三种谎言：谎言，该死的谎言，还有统计数据。”
+ reflection tuning：在这种技术中，模型能够思考、纠正自己并提供正确的答案
+ 这是 Matt Schumer 现在面临的风险——他要么修复这个问题，要么冒着被社区抛弃的风险。



# 20240913 OpenAI o1 CRUSHES PHD Level Experts! [HIDDEN THOUGHTS] #ai-web-exam
+ [https://www.youtube.com/watch?v=K_3ww-kICiM](https://www.youtube.com/watch?v=K_3ww-kICiM)
+ O1 隐藏了 COT，它是一个通过强化学习训练的新型大型语言模型，用于执行复杂的推理。  
它在响应用户之前可以产生一个长的内部思维链。  
+ test-time compute（测试时间计算）：
+ GPT 40 的即时回答准确率是13，而我们现在开始接触的01预览版准确率是56.7，01 是83.3，所以绝对是一个巨大的飞跃
+ 英语 没有提升，公共关系 只有小幅改进
+ Chain of Thought理念是：你可以要求模型逐步思考它正在处理的任何问题，以此来展示其推理过程。
+ 它正在构建一种分支型的Chain of Thought，称为“Tree of Thought”，它分支出来探索不同的可能性。它沿着一个特定的分支思考，意识到“这不是正确的路径”，然后返回并思考另一个分支。
+ Tree of Thought方法的工作方式：测试不同的分支并排除错误的答案
+ 思考过程比实际答案多出10到20倍
+ 推理能力直接有助于增强模型的稳健性
+ 01 preview 在关键的jailbreak评估中取得了显著提升
+ OpenAI说：“我们认为，隐藏的Chain of Thought为监控模型提供了独特的机会，假设它是忠实且清晰的。”
+ 如果模型的思维是不可见的，你就不必担心训练它避免冒犯性的语言，只要输出对用户有利即可。
+ 如果竞争对手无法访问隐藏的思维，他们就无法轻易复制相同的推理过程到他们的模型中。
+ OpenAI决定不向用户展示原始的Chain of Thought，而是提供一个推理过程的摘要。
+ 就是为什么开源模型变得越来越重要，因为它们可能是我们唯一能完全看到模型思维过程的方式
+ 01模型代表了AI推理的新纪元，模型现在能够解决曾经被认为过于复杂的机器无法处理的问题。

# 20240912 Elon Musk Reveals SuperComputer COLOSSUS, $10k Optimus Robot and the 80/20 AI Future #每日陪读
+ [https://www.youtube.com/watch?v=3m4U24402wU](https://www.youtube.com/watch?v=3m4U24402wU)
+ 埃隆的看法：“目前在AI上的支出可能超过了收入，这一点毫无疑问。”但AI的进步速度远远快于我见过的任何技术
+ 更大的挑战是：我们如何在一个AI能做我们所有事情并且做得更好的世界中找到意义？
+ Colossus 是目前所有类型中最强大的超级计算机
+ “智能的本质实际上是不同的，AI中重要的东西也不一样。”
+ “我们试图从其他公司购买芯片，但它们不够快，或者性能不足。”“所以我们被迫设计自己的芯片，最终我们打造出了世界级的东西。”
+ Dojo 2应该在明年年底批量生产，它会与B200类型的训练系统相当。
+ 成本落在哪里将极大地决定需求
+ 我真正发现的是，任何在足够数量下生产的东西，都会渐进地接近其材料成本
+ 很多芯片的内容包括支付使用费和芯片的折旧，但芯片的实际材料成本非常低
+ 十年后，Optimus的劳动力和材料成本可能不会超过一万美元。主要的技术迭代少于两年时间
+ 操作你手的主要肌肉实际上在前臂里。当前版本的Optimus手部将执行器放在手中，并且只有11个自由度。而人类的手根据计算方式，大约有25个自由度

# 20240911 OpenAI's "Strawberry" Model Coming THIS MONTH... #每日陪读
+ [https://www.youtube.com/watch?v=jpIskGUQPyI](https://www.youtube.com/watch?v=jpIskGUQPyI)
+ 根据information.com的消息，OpenAI计划在9月24日，将strawberry作为chatgpt服务的一部分发布，
+ strawberry不同于其他地方的是，在回答前它会花时间思考答案.这个思考阶段通常持续10到20秒
+ 使用Chain of Thought提示或Chain of Thought推理，基本上是要求模型在回答前一步一步地思考答案。在strawberry模型中，这种提示机制似乎内置了
+ 有些人说，strawberry并不是最大的威胁，人们真正需要担心的是Orion
+ 完整的strawberry模型是某种量化、简化版
+ 很多类似泡沫的巨大活动和大规模的投资流入AI领域，我认为至少有一部分是由OpenAI以及围绕它的炒作推动的
+ 即使AI模型的能力保持现状不再进步…即使在接下来的5到10年里只有轻微的进步，依然会有很多可以应用的场景。
+ 炒作的热潮可以正式宣布结束了



# 20240908 《Elon Musk》43 The Boring Company 2016 #每日陪读 #人物传记 #ElonMusk
+ Musk终于说道：“你有没有注意到，城市是以3D方式建造的，但道路却只是2D的？”
+ The Boring Company以一个简单明了的使命成立：快速且高效地挖掘隧道，以缓解城市中的交通拥堵。
+ 它并没有改变一切。事实上，它成了一个Musk过度炒作的想法的例子。

# 20240906 BREAKING!! OpenAI **JUST** Announced GPT-5 [100X BIGGER] #每日陪读 #AI
+ [https://www.youtube.com/watch?v=v7sFwtrnQIw](https://www.youtube.com/watch?v=v7sFwtrnQIw)
+ GPT next将于2024年发布，其性能将比前一版本GPT 4强100倍，而GPT 4比GPT 3强100倍
+ GPT-2像个学龄前儿童GPT-3像小学生；GPT-4则像一个聪明的高中生。
+ 我们在GPT-2、GPT-3和GPT-4之间看到了每两个数量级的增长。
+ GPT-4 Next预计将在今年发布，并将使用Strawberry的微型版本进行训练，其计算资源大致与GPT-4相同。
+ 这个100倍的提升可能不是指计算资源的扩大，而是指有效计算量，包括架构和学习效率的改进。
+ 我们认为GPT-4的参数大约是1.7万亿
+ 截至8月底，活跃的ChatGPT用户数量已超过2亿，这是历史上最快达到1亿到2亿活跃用户的软件。
+ 日本是最早面临社会问题的国家之一，比如出生率下降和人口老龄化，
+ GitHub Co-pilot前首席架构师Alex Gra表示，使用Strawberry生成更高质量的训练数据可以减少OpenAI模型产生的错误，也就是所谓的幻觉。

# 20240904 Amazon's LEAKED Conversation Reveals Stunning Truth About The Future Of Software Engineering #每日陪读
+ [https://www.youtube.com/watch?v=I1dB_6h09pU&t=20s](https://www.youtube.com/watch?v=I1dB_6h09pU&t=20s)
+ Garman说道编码只是我们与计算机对话的一种语言。
+ 意味着我们每个人都需要更好地了解客户的需求以及我们试图构建的最终产品是什么。因为这将会成为工作越来越多的一部分，而不是仅仅坐下来写代码
+ AI是为了增强他们的能力，而不一定只是取代他们。
+ 与AI打交道现在比计算机历史上任何时候都要容易得多。
+ 科学中最复杂的领域之一是生物学，特别是人类生物学的理解。
+ 生命科学是断断续续的。如果我现在要重新开始，我会意识到将生命工程、生命科学转变为生命工程的技术已然到来。未来所有这些发明将成为工程的一部分，而不是科学发现的一部分。
+ 在6个月内，ChatGPT可以通过GLU三级程序员考试，它几乎可以在MacBook上运行。
+ 5年后将没有程序员了
+ 使用GitHub Copilot的开发者生产力提高了50%，并且更加专注。
+ 我们大约有一亿专业开发者，我们认为世界可能会增加到十亿专业开发者。
+ 替代总是关于掌握新技能。

