# 20250927 Designing Claude Code
+ [https://www.youtube.com/watch?v=vLIDHi-1PVU](https://www.youtube.com/watch?v=vLIDHi-1PVU)
+ 最初选择 **CLI** 的部分原因，其实就是这种“形态”的易用性。
+ 终端几乎自打有软件开发以来，就一直是这个领域的基础部件，可以说“从有记忆开始就这样”。
+ 我认为很有意思的是：终端其实是 **LLM** 的理想载体。
+ 能“原生地”待在一切内容所处的环境里，本身就是体验中非常丰盈的一部分。
+ 编程领域的第一项真正重要的 **AI** 进展是“按 Tab 键自动补全”（_tab to auto-complete_）。
+ 你会“编排”来自多个位置的多个 **Claude**，以便完成一项工作。
+ 以往为 **CLI** 设计的所有经验里，我都像避瘟疫一样避免使用外框，因为元素一多就会把布局全打乱
+ **ASCII** 风格的“reticulating”和“thinking”效果。我认为这些为 **Claude** 增添了很棒的个性。
+ 有时我也会请 **Claude Code** 帮我“界定/估算”我提出的设计工作量。我会把设计稿作为图片拖拽进去。

# 20250926 Why Now Is The Best Time To Build In Crypto 2
+ [https://www.youtube.com/watch?v=Pdne9xaRLUc](https://www.youtube.com/watch?v=Pdne9xaRLUc)
+ 监管极度不明确”这一事实，这在过去十年里成为创新的巨大制约因素
+ 支撑下一阶段的因素之一就是**扩展链（scaling the chain）**
+ **监管解锁**也是一个巨大变化；第三个重要变化是**稳定币的成熟**，这等于我们拥有了**可编程货币**。
+ **钱包**也出现了一系列**突破**与**简化**，并以“不让人害怕”的方式**无缝融入**用户体验。
+ 像 **Latam** 的 **Dollar App**、印度的 **Aspora** 等，本质上是围绕稳定币构建的**新型互联网银行（neobank）****服务，****增速惊人****。其****杀手级场景**是**跨境汇款**：**即时且低成本**。
+ 稳定币的关键**解锁点**在于：把**可编程货币**引入既有金融体系，让**全球任何人**都能使用**可编程的美元**。
    - **第一个重大解锁**：如今**人人可触达美元**，还能在**可编程平台**上“**用美元来构建**”，美元**可瞬时、全球、几乎免费**地流转。
    - 全球许多国家之所以青睐**美元稳定币**，是因为它们**立刻解决痛点**（如**对冲通胀**、获得更**稳定**的账户）
    - 本地稳定币，就能把**围绕美元稳定币积累的创新**“**迁移**”到**本地经济**。
+ 加密的一大强项是**可组合性（composability）**。你围绕某一稳定币起步，若**另一种**增长更快，**切换/并行支持**的**难度和成本**都不高。
+ 这种**灵活性**正是**用户与企业**所需要的：一款支付应用，既能**存美元或本币稳定币**，又能在二者之间**兑换**、**赚利息**，并以二者**进行借贷**。而这一切**首次真正可行**，正是因为**加密**运行在**可编程的平台**之上。
+ 机会在于：**逐一审视**当下金融体系的**每个环节**，思考如何把那些**遗留系统（legacy systems）**——很多**已有 50–100 年历史**——**改造成**运行在链上的**可编程智能合约**。
+ **电商支付（commerce payments）协议**，让全球任何一家 **Shopify** 商店都能在 **Base** 上**接受 USDC**，来自**全球任何**用户。
+ **收款**背后的逻辑；对大多数人是“**幕后**”，但对 **Shopify** 来说就是“**台前**”，是他们的核心业务。
+ 创业者应当秉持这样的**思维模型（mental model）**：**美国及全球经济**的每个角落都有类似机会。
+ **去中心化**在**技术栈底层**至关重要：诸如 **Ethereum** 的底层、**Base** 等需要去中心化，以便形成**人人可参与的全球平台**。但若**目光短浅（myopically）****地要求从底层到上层****事事都去中心化**，那等于**抛弃**过去**百年**的商业建设经验。
+ 思维模型：依托**新平台**进行**转译/迁移**，**降成本**、**降门槛**，交付**十倍更优**产品，**颠覆 incumbents（既有巨头）****并****获取市场份额**。
+ **支付本应是互联网的原生协议**，我们本该将其内置，但后来**没有这样做**。

# 20250925 Why Now Is The Best Time To Build In Crypto 1
+ [https://www.youtube.com/watch?v=Pdne9xaRLUc](https://www.youtube.com/watch?v=Pdne9xaRLUc)
+ **Jesse Pollock**。他是 **Base** 的创始人，最初 **Base** 是作为 **Coinbase** 的区块链项目启动的，但后来逐渐扩展，几乎成为一个“加密领域的万能应用”
+ 从 **fintech 1.0** 到 **fintech 3.0** 的演进：
    - **fintech 1.0** 是上世纪 90 年代的那一波，比如 **PayPal**，让消费者首次开始适应在线支付
    - **fintech 2.0** 是过去十年这一波创业公司，它们建立在既有的传统金融系统之上，提供更友好的用钱体验
    - **fintech 3.0** 则是把一切重写的机会——从零开始，思考如何把金融系统搭建在一个“包含货币、可编程且即为加密”的软件平台之上，让它更好地为所有人服务。
+ 我认为相反，他们可能会感到害怕；他们可能并不真正了解加密在日常到底做了什么。也正因为如此，这反而是我们建设的最佳时机。
+ 现在正是突破之时，因为基础设施已经铺好。工具就位，有稳定币、有链。接下来要做的，就是把这些拼成一种神奇的体验，让它像野火一样席卷全球。
+ 过去几年真正取得长足进步的有几点：
    - 第一，**链** 已经相当成熟；你可以把链看作一个**编程环境**，你在其中构建各种应用
    - 第二，成本**大幅下降**。无论是 **Base** 还是 **Solana**，扩容都在发生……
        * 我们把这称作加密的“**宽带时刻**”。当年的互联网**拨号时代**，今天这些应用根本不可能存在；后来**吞吐量**、**带宽**都扩大了，于是出现了新的**爆款体验**……
        * **Ethereum** 在过去五年推进的是：若要达到能孕育“下一个 **Google**”的**规模**，在**去中心化/安全**与**可扩展性**之间必然有取舍；因此要设计一种架构：在 **L1** 之上**打造 L2 生态**，在**保持去中心化**为核心特性的同时实现**扩容**。
            + 把 **Base** 想成**高占用车道（HOV 车道）**：我们跑在 **Ethereum** 之上，把**数以百万计**的交易**压缩**后**发布**到以太坊。压缩带来**高效率与大幅降费**；而底层的以太坊提供**去中心化**与**抗审查性**。
            + **Solana** 走的是**另一端**：把扩展**都放在 L1**
    - 第三，**监管清晰化**：比如 **Genius Act** 涉及**稳定币**，**Clarity Act** 可能涉及**所有加密代币**。企业家因此**确定性更高**：不必再堆一堆法律意见，**可以直接去构建**。
    - 第四，**稳定币成熟**——把大家熟悉的钱变成**可编程货币**
        * 稳定币把**可编程货币**带入现有金融系统——让**全球任何人**获得**可编程的美元**。在稳定币之前，**美国以外**的人往往**无法真正接入美元体系**。如今，他们可以**用美元交易、用美元构建**，而且**即时、全球、几乎免费**。
        * **汇款**与**即时低成本跨境转账**是**杀手级**用例
    - 第五，**钱包的突破**：更简单、不再吓人、可融入 **UX**
+ 入门项目推荐：
    - 一个**简单又酷**的入门项目：做个 **UI 入口**对接这些去中心化交易，**连接钱包**，把钱包里的某个资产**交换**为另一个——**无需 API Key、无需许可**，只需写个小界面。
    - 另一个不错的入门是**自己写一个 AMM**。本质上就是一个函数，定义**资产如何互换**——几百到上千行代码。更复杂一些，但把传统交易所**浓缩**成一个小合约的“**顿悟时刻**”非常震撼。

# 20250924 Sam Altman and Elon Musk go ALL IN
+ [https://www.youtube.com/watch?v=9iyYhxbmr6g](https://www.youtube.com/watch?v=9iyYhxbmr6g)
+ 1 gigawatt（吉瓦）≈1 座核反应堆
+ 如果 AI 继续按我们预期的**轨迹**发展，那么将有**惊人的**事情成为可能。也许在**10 吉瓦**算力下，AI 能**找出治愈癌症的方法**。
+ 传统大公司做成类似规模**要 15 个月**。走极限路线的话，**xAI** 的 **Colossus 2** 用了**6 个月**。当 **Elon** 开启“**速通工厂**”模式时，他们获批**临时许可**，可在**无正式许可证**的情况下**运行燃气轮机 12 个月**。
+ **提升算力**是**提升与释放收入**的**关键**。至于你**怀疑**还是**兴奋**，取决于你的**世界观**。
+ **Jensen** 基本处在 AI 行业**硬件中心**……如今愿意**投资 OpenAI**，这**改变了格局**。**Nvidia** 不再只是**“卖铲子的人”**，而是**亲自下场**参与 AI 开发。

# 20250918  Google and Coinbase launch "AI MONEY" 🤯（上）
+ [https://www.youtube.com/watch?v=8s6nGMcyr7k](https://www.youtube.com/watch?v=8s6nGMcyr7k)
+ 很多人早就猜到这一步会来——**AI agents** 将需要自己的“货币”和付款方式，才能获取资源、出去把事情办成
+ 我们可能需要大量 **microtransactions**（微交易）——金额只有几美分，甚至不到一美分的分数——用于各类微型服务，而且要快速完成、几乎零摩擦。
+ 意味着那些过去需要人工监管的任务——比如为数据抓取、各类服务或微任务付款——如今可由代理本身代表用户无缝执行。
+ 它解决了代理之间互相交互的难题——这为“**agentic commerce**（代理型商业）”铺平了道路。
    - 在规模化层面，这会带来负面影响：我们在“弱化”创作者继续创作/汇编信息/做调查报道的激励——等于切断了他们为内容筹资、维持投入的能力。
    - 有很多媒体只要质量够高，我乐意付费——但也会带来麻烦：通常是难以取消的月订阅；还得输入信用卡信息；要处理一堆“繁文缛节”。
+ 我的代理检查来源，判断“这条内容应该收录进报告；我获准花几分钱获取它”，如果出版方同意，就自动完成支付；我得到信息；报告被整理完成；皆大欢喜。
+ 如果我想在某个产品上使用他人的艺术作品，同样道理：这会让授权许可变得容易得多。无需我自己硬着头皮读冗长条款，代理会说：“我想把你的作品用在这个东西上；我的预算是××。”

# 20250915 The future of agentic coding with Claude Code（下）
+ [https://www.youtube.com/watch?v=iF9iV4xponk](https://www.youtube.com/watch?v=iF9iV4xponk)
+ 说真的，我也不太清楚自己到底在做什么。老实讲，几乎没人真正知道该怎么用 **AI**。就像这样，我们一边构建它，一边慢慢把这个东西“摸索出来”。
+ 而最好的指标就是用户想要什么。所以你必须去倾听。
+ **Claude Code** 从一开始就被设计成尽可能简单、而且尽可能“可折腾”。而且我们一直在大力增强这种可扩展性，这也是让我非常兴奋的地方。
+ 要“改造” **Claude Code** 的方式就是往 **CLAUDE.md** 里添加内容——那是最初的扩展点。
+ **hooks**，是 **Dixon** 做的。**Dixon** 是我们团队的一位工程师，他看到了大量用户提出“我想在这里接入、那里也想挂钩”的需求，于是他做了一个非常完善的 **hook** 系统。
+ 我们在用户自定义的 **slash commands** 上投入很多。理念是：它本质上就是一段“工作流”，像一个 **markdown** 文件那样，你把它放进代码里，就能反复复用。
+ 我觉得 **slash commands** 非常有意思，而 **agents** 可以看作是它的另一种视角：像 **slash command**，但带有一个“分叉的上下文窗口”。
+ 所以你可以把 **agents** 和 **slash commands** 视为“一体两面”。这同样令人兴奋——只是扩展 **Claude Code** 的另一条路径。
+ Claude Code的两个建议：
    - 如果你刚接触 **Claude Code**，先别用它来写代码——听起来很反直觉，但你得克制一下。先用它来问与库相关的问题，先别写；熟悉这种“研究式代理”后再开始让它写代码。
    - 把任务粗分为“简单/中等/困难”：
        * 简单任务：我会上 **GitHub** 在 issue 里 **@Claude**，让它直接写 **PR**；这样还能“解放”我的终端。
        * 中等任务：我会在终端里先进入 **plan mode**（按 **Shift+Tab** 切到 **plan**），先和 **Claude** 对齐方案，再切到 **auto-accept** 让它自动实施。
        * 困难任务：仍由我掌舵，**Claude** 只是“工具/搭档”。我会和它结对，先让它做代码库调研、原型一些思路、随手 **vibe code** 几个版本来摸清系统“边界”，单元测试可以交给 **Claude**，但主要实现由我完成。

# 20250914 The future of agentic coding with Claude Code（上）
+ [https://www.youtube.com/watch?v=iF9iV4xponk](https://www.youtube.com/watch?v=iF9iV4xponk)
+ 在你进行开发时，它已经进入“内循环”（核心迭代环节）。这是过去一年最大的变化：现在写代码时你会用 **agent**，而不是再在 **IDE** 里直接手动改文本。
+ 我们已经看到的趋势是：从“人直接改文本”转向“让模型代为修改文本”。
+ 编码工作自动化尝试难点：
    - 模型本身还不够强；
    - 所谓“**scaffolding**”（搭在模型之上的支架/框架）也不够好。
+ 型在 **agentic coding**（智能体式编码）方面变强很多，这种提升体现在 **3.7**、现在的 **4.0**，以及 **Opus 4.1** 等版本上。
+ **Harness** 也提升很多。显然，这个 **harness** 就是 **Claude Code**：你与模型交互的方式不是“直接用模型”，而是通过这层 **harness**。
+ 可以说 **Claude** 像马，而作为工程师，你要让它朝某个方向前进并对其进行引导，你需要在它周围搭建某种 **scaffolding**（支架/外层系统）来正确“掌舵”。
+ 每天“造模型的人”都会用模型来完成他们的工作。
+ 如果你让模型“自由运行”约 30 分钟，在 **3.5** 上它也许能短时间保持在正确轨道上——可能就一分钟左右。
+ 无论是哪个模型、在测哪种新东西，我就用它来写代码，看看整体“感觉/流程”如何；并没有特定的固定测试。
+ 从某种意义上说，如果你只拿模型做某一件固定的事，你反而会错过一些新能力，比如通过 **MCP** 拉取上下文、读取你的 **Slack** 消息等。
+ 从某种意义上，最好的 **eval**（评测）就是最贴近真实使用的评测；这时“直接用它”反而能给出最佳信号。
+ 我知道针对不同产品我们尝试过各种评测，但对 **Claude Code** 来说，真正有效的是“紧密的反馈闭环”，它几乎比任何“硬编码评测集”都能更快给出信号。
+ 我认为要找到能覆盖软件工程全部复杂性的“合成评测”真的很难。
+ **Claude Code** 的“**dogfooding**（自家人自用、以用促建）循环”是我见过最好的之一。

# 20251012 OpenAI Just SOLVED Hallucinations...（下）
+ [https://www.youtube.com/watch?v=uesNWFP40zw](https://www.youtube.com/watch?v=uesNWFP40zw)
+ 基准测试优化模型可能会助长**hallucinations（幻觉/胡编乱造）**。
+ 我们实际上在强化这些幻觉，因为我们只关注答对，而在不确定答案时乱猜并不会受罚，这种行为反而能提高测试分数
+ 人是在校外、在“社会的狠课”中才学会表达不确定性的价值。
+ 非常自信地说一个百分之百错误的答案——这会消耗你的社会信用
+ “自信地说蠢话”所带来的羞耻感，正是这些模型所缺失的
+ **hallucinations**只是在**base models**中不可避免
+ 如今的训练方式并不能把所有**hallucination**的表现形式都“熨平”。它会提升准确率，但那只是平均意义上的提升；模型猜错的时候依然会错，不过平均分更高，所以我们还会给它“击个掌”。
+ 几乎都是二元评分（要么对要么错），只有极少数不是。并且，只有**wild bench**会对“I don't know”（**IDK**）给予加分，其他统统不会
+ 减少**instruct models**（聊天机器人）的**hallucinations**：
    - 要么惩罚错误答案，要么在模型不确定时，对其说“I don't know”给予加分
    - “不自信”量化为某种数学表征，当其低于某个**threshold**时，就应当让模型说 “I don't know”。
    - 

# 20251011 OpenAI Just SOLVED Hallucinations...（上）
+ [https://www.youtube.com/watch?v=uesNWFP40zw](https://www.youtube.com/watch?v=uesNWFP40zw)
+ 这种事我们都遇到过：我们提问，它给出答案，但却“错得很自信”。你明知道答案不对，但它偏偏坚称自己正确。
+ 答对就会收到“点赞”（正向反馈）；而只要不是正确答案——无论是答错、说 _I don't know_，还是其他说法——都会被判为错误。
+ 这种现象并非源自 **large language models** 内在的缺陷，而是出在训练与评估流程上。换句话说，这不是模型的错，而是我们人类的错
+ 如果错误陈述无法与事实区分开来，那么在 **pre-trained language models** 中，**hallucinations** 就会因自然的统计压力而出现。
+ 模型没有动力去说 _I don't know_
+ **LM** 被训练去具备“自我确定性”。换句话说，它们利用自身的置信度作为奖励信号，通过内部反馈进行 **reinforcement learning**（强化学习）。
+ “是否有效”就是一种基准测试。即模型要学会识别对与错。如果它能正确区分好答案和坏答案，那就是个好模型。

# 20250910 Alfred Wahlforss - Listen Labs
+ [https://www.youtube.com/watch?v=-_gPru8KmIE](https://www.youtube.com/watch?v=-_gPru8KmIE)
+ customer research 这是一个极其庞大的市场，因为每家公司都想“以客户为中心”，并深入理解是什么驱动他们的客户。
+ 一家名叫 **Qualrix** 的公司，他们做的全是枯燥的客户问卷调查。这家公司估值 120 亿
+ 一家 **Fortune 500**（财富 500 强）公司：“你们每年在 **Qualrix** 上花多少钱？” 他们说：“每年 1,000 万美元。这一块的总支出大约是 300 亿美元。
+ 这些公司基本都是管理不善的咨询公司，技术含量低，而且动作非常迟缓。非常适合被 **LLM** 颠覆
+ 我们每月有 2,000 条入站线索，但只能为其中 50 位完成上手/接入
+ “模拟回应”：设想一下，能否基于既有访谈进行外推，并据此用“合成访谈”给出建议

# 20250909 visual storytelling
+ [https://www.vev.design/visual-storytelling/](https://www.vev.design/visual-storytelling/)
+ 最简单来说，visual storytelling（视觉叙事）是“showing, not telling（展示而非叙述）”这种叙事技巧的一个华丽说法。
+ 由于人们对视觉刺激的反应速度远快于单纯的文字，而且反应更具个人化
+ 它是一种长篇幅、有意放慢节奏、并且带有沉浸享受感的内容形式，专为长时间注意力设计
+ 作为高度吸引人的内容形式，它们通常包含一定程度的读者参与和个性化，这是其他数字营销形式根本无法实现的。
+ 矛盾的是，网络同时成为了“短小内容”和“大规模视觉叙事”的栖身之所。挑战在于如何在美学吸引力与可用性、可访问性之间找到平衡。
+ 几种实现方式
    - Scrollytelling Sections
    - Horizontal Scrolling Timelines
    - Video Scroll
    - Before & After Sldier
    - Animated Charts
    - 3D Elements
+ 技巧
    - Illustrated experiences（图文并茂）
    - Animation and interactivity
    - Reader agency（观众参与）
    - 文字作为视觉艺术
+ 最佳实践
    - 从一开始就计划视觉内容设计
    - 保持一致的视觉风格
    - 促进读者参与
    - 使用移动和过渡
    - 不要忽略文本
+ SEO-Friendly
    - 压缩
    - 懒加载
    - visual file meta-data
    - 测试速度和性能

# 20250908 Codex
+ [https://developers.openai.com/codex](https://developers.openai.com/codex)
+ 登录账号或者API key 的方式使用都可以
+ 推荐使用 Codex 与 GPT-5，我们最好的编码模型。默认的推理级别是中等
+ 当你希望 Codex 主动修改代码并准备一个 pull request 时，请使用代码模式。
+ 默认是关闭联网的，Codex预设了访问的白名单
+ 提示词技巧
    - Codex 擅长定位相关代码，但当提示将其搜索范围缩小到几个文件或包时，效率更高
    - 当 Codex 能够验证其工作时，它会生成更高质量的输出
    - 你可以告诉 Codex 如何处理任务或使用它的工具
    - 像人类工程师一样，当复杂的工作被分解成更小、更专注的步骤时，Codex 能更好地处理。
    - 当遇到错误或意外行为时，尝试将详细的日志或错误跟踪粘贴到 Codex 中作为首要的调试步骤
    - 除了针对特定任务外，Codex 经常在开放式任务上给我们带来惊喜
+ AGENTS.md 不包括claude code

# 20250907 Turn boring AI designs to Pro-level with these simple steps(下)
+ [https://www.youtube.com/watch?v=lgqnMzOu2Lw](https://www.youtube.com/watch?v=lgqnMzOu2Lw)
+ Unicorn Studio ：非常**lightweight**（轻量）。它的**performant**（性能表现）也很强
+ Spline
+ 这些编辑功能，让它“像设计工具”一样，但同时拥有**AI 赋能**的能力，而且一切都是**代码层**——不是只停留在 **Figma** 里的**静态设计**
+ 对我这样做了 20 年设计的人来说，也很难一眼看出它是 AI 生成的。**这正是我们要的效果**——你的设计/艺术不该给人“AI 味儿”。
+ 如今，让作品**带有 AI 痕迹**几乎像是一种**冒犯**。能避免就尽量避免。即便大家知道它是 AI 生成的，也务必**保证质量**——不要给人“投机取巧/做得很糙”的感觉，比如“六根手指”“怪异的眼睛”等问题
+ **Spline** 是一款**基于浏览器的 3D 设计与交互工具**，主打“所见即所得”的建模、动画、互动（鼠标/触摸事件）和**网页嵌入**，并支持多人**实时协作**
+ 切换到 **cloud 4**，因为它在**修复类任务**上通常更**stable**（稳定）、更**robust**（可靠）；**创意**阶段已经完成——这一点 **GP5** 很擅长。

# 20250906 Turn boring AI designs to Pro-level with these simple steps（上）
+ [https://www.youtube.com/watch?v=lgqnMzOu2Lw](https://www.youtube.com/watch?v=lgqnMzOu2Lw)
+ **AI** 特别喜欢给的那些渐变色
+ **GPT5** 是一次巨大的飞跃,此前大约只能生成 200 行，如今一次就能生成约 800 行代码，这带来了巨大的差别。你会得到更高的一致性；**image-to-HTML** 转换效果更好；视觉理解能力也更强
+ **GPT5** 生成的那些紫色渐变更少，结构更好，排版（**typography**）等方面也更佳。它对字距（**letter spacing**）和字体（**fonts**）的理解更到位。
+ GPT5在动画方面可能不那么理想，所以有时你需要切换到 **Cloud 4**
+ **Cloud 4** 在结构、**HTML** 与代码层面的稳定性上可能更“聪明”一些；但 **GP5**（即 **GPT5**）显然更有创造力，也更专业，并且视觉理解更强。
+ 如果只是做一个落地页，你不必指定这些细节；但如果你只做单个区块，就完全可以把这些都写清楚。
+ 如果你有明确的品牌基调，强调色（accent color）可以是蓝色——但千万别用紫色，因为 **AI** 很爱自动给紫色。可以用琥珀色（amber）或橙色，这些很流行；翠绿色（emerald）现在也很受欢迎
+ 投影、背景、边框之类的设置，如果拿不准，就直接跳过也没问题。
+ 越来越多设计师在用 _guys_，因为 _inter_ 更像 **AI** 的默认回退字体。如果你想让设计更有一点“oomph”（冲击力/劲儿），_guys_ 是个不错的选择
+ 我发现 **AI** 聚焦单一区块时产出更好：会为该区块生成更多代码与细节；整页截屏反而使每个区块的细节变少，这不是我们想要的
+ **AI** 对“偏方正”的布局不太拿手，除非你明确说明，它仍倾向使用更**圆角**的样式。你可以明确要求“更方正（squareish）”，或“圆角半径设为 0”。
+ 每次“借鉴灵感”时，一个**非常非常重要**的步骤是：打开 **Prompt Builder**，然后在提示里写上诸如“修改文本（change text）”“使用 **lucid icon**”“做成响应式（make responsive）”之类的要求。
+ 当你在既有模板上混改时，风格一致性会非常好。
+ 尽量**减少普通粗体（bold）****的使用。原因是现在屏幕更好了，而 ****AI**** 又很喜欢到处用粗体**
+ **AI** 经常生成**很糟糕的素材**，通常**随机抓自 Unsplashed**（原文如此，常见平台应为 **Unsplash**），而且 **AI** 喜欢反复用同一批素材、同一套头像

# 20250902 OpenAI vs. Deepseek vs. Qwen: Comparing Open Source LLM Architectures（ 下）
+ [https://www.youtube.com/watch?v=raTbhtKZTZA](https://www.youtube.com/watch?v=raTbhtKZTZA)
+ DeepSeek **V3.1** 保留了与 **V3** 相同的核心架构，但提供了更强的推理、更聪明的工具调用以及更高的整体性能
    - 在现代 **LLM** 中，大量算力与内存都被 **KV cache** 占据，因此 **V3** 采用 **MLA**：先把 **keys/values** 压缩到更小的 **latent space**（潜空间）再缓存，推断时再解压使用。
+ **Quen** 的 **MoE** 基座模型只用到五分之一的 **active parameters**（激活参数）就达到了 **dense** 模型的性能。
+ 各家如何扩展 **context length**（上下文长度）,使模型能处理远超原始训练上限的序列。
    - **GPTOSS** 从预训练阶段就应用 **Yarn**，因此权重原生适配 **131k** 上下文；**GPTOSS** “生来”就具备长上下文
    - **Deepsee** 采取分阶段路线——先微调到 **32k**，再训练到 **128k**；**DeepSeek** 通过分步学习获得；**Quen** 则在 **32k** 训练基础上把极限再往外推。
    - **Quen** 也微调到 **32k**，但跳过了后续再训练。**Quen** 在 **inference** 阶段再次应用 **Yarn scaling**——把 **RoPE** 基频放大 **4×**，无需额外再训练就达到 **128k**
+ 各主流模型在后训练与推理阶段都大量依赖 **reinforcement learning (RL)**——更有趣甚至出人意料的是，部分 **RL** 训练所需数据量极小：比如 **Quinn** 仅用 **4,000** 对数据。
+ 各实验室之间数据集差异不透明；显然，幕后进行了大量 **dataset**,这部分工作很可能构成它们的 **moat**（护城河）的一大块，使公司在开源/发布模型时更有底气——外界很难复刻其成果。
+ 不要只盯着 **benchmark** 或“**context size**”等顶层指标；要关注各实验室为达成这些结果所采用的具体方法。

# 20250902 OpenAI vs. Deepseek vs. Qwen: Comparing Open Source LLM Architectures（上）
+ [https://www.youtube.com/watch?v=raTbhtKZTZA](https://www.youtube.com/watch?v=raTbhtKZTZA)
+ **GPT OSS** 采用**专家混合（** **Mixture of Experts, MoE** **）****架构，提供两种规模：****1200 亿参数****和****200 亿参数**。
+ **GPTOSS** 作为**仅解码器（decoder-only）**的 **Transformer** 训练而成，并融入了许多现代 **LLM** 的常见特性
    - **grouped query attention（GQA）**：一种改进的注意力机制，允许多个 **query** 头**共享同一组** **key-value** 对，从而**减少内存**占用并**加速**推理
    - 馈层使用 **swiggloo** 激活函数，相比更简单的 **RLU**，能实现更**细腻**的变换
    - **rotary positional embeddings（RoPE）**，将**位置信息**直接嵌入注意力计算，因而更好地支持**长上下文**。
    - 模型采用**预归一化**的 **RMSNorm**：通过“**均方根**”缩放输入，以获得更**稳定**的训练
+ 亮点
    - **131,000 token** 的上下文窗口，这是在**预训练**中就应用 **YaRN** 缩放实现的，而非在推理时临时扩展。
    - 训练完成后，模型**默认以量化格式**发布，因此足够**轻量**，可部署在**一般硬件**上。这使其可运行在**消费级 GPU**、笔记本或其他**资源受限**设备上。不过，目前**未提供**未量化版本。
+ Qwen3**致密模型**共有**七档**规模，其中包含**6B** 级别——是当代开源权重模型中**较小**的一类
+ **Qwen 3** 的一大差异在于其**控制 Q/K/V 投影尺度**的方法，以在**大规模**下保持注意力**分数稳定**。
+ **思考模式融合**：**Qwen 3** 的关键创新，将“**思考/非思考**”两种风格**统一到一个模型**中，用户可**无缝切换**。尽管该特性在 **Qwen** 首发时颇为独特，但 **GPT-5** 现在也提供了类似的切换。
+ DeepSeek V3  的一大不同在于：它采用与 **GPT OSS**、**Qwen 3** **不同**的注意力机制。

