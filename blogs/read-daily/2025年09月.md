# 20250902 OpenAI vs. Deepseek vs. Qwen: Comparing Open Source LLM Architectures（ 下）
+ [https://www.youtube.com/watch?v=raTbhtKZTZA](https://www.youtube.com/watch?v=raTbhtKZTZA)
+ DeepSeek **V3.1** 保留了与 **V3** 相同的核心架构，但提供了更强的推理、更聪明的工具调用以及更高的整体性能
    - 在现代 **LLM** 中，大量算力与内存都被 **KV cache** 占据，因此 **V3** 采用 **MLA**：先把 **keys/values** 压缩到更小的 **latent space**（潜空间）再缓存，推断时再解压使用。
+ **Quen** 的 **MoE** 基座模型只用到五分之一的 **active parameters**（激活参数）就达到了 **dense** 模型的性能。
+ 各家如何扩展 **context length**（上下文长度）,使模型能处理远超原始训练上限的序列。
    - **GPTOSS** 从预训练阶段就应用 **Yarn**，因此权重原生适配 **131k** 上下文；**GPTOSS** “生来”就具备长上下文
    - **Deepsee** 采取分阶段路线——先微调到 **32k**，再训练到 **128k**；**DeepSeek** 通过分步学习获得；**Quen** 则在 **32k** 训练基础上把极限再往外推。
    - **Quen** 也微调到 **32k**，但跳过了后续再训练。**Quen** 在 **inference** 阶段再次应用 **Yarn scaling**——把 **RoPE** 基频放大 **4×**，无需额外再训练就达到 **128k**
+ 各主流模型在后训练与推理阶段都大量依赖 **reinforcement learning (RL)**——更有趣甚至出人意料的是，部分 **RL** 训练所需数据量极小：比如 **Quinn** 仅用 **4,000** 对数据。
+ 各实验室之间数据集差异不透明；显然，幕后进行了大量 **dataset**,这部分工作很可能构成它们的 **moat**（护城河）的一大块，使公司在开源/发布模型时更有底气——外界很难复刻其成果。
+ 不要只盯着 **benchmark** 或“**context size**”等顶层指标；要关注各实验室为达成这些结果所采用的具体方法。

# 20250902 OpenAI vs. Deepseek vs. Qwen: Comparing Open Source LLM Architectures（上）
+ [https://www.youtube.com/watch?v=raTbhtKZTZA](https://www.youtube.com/watch?v=raTbhtKZTZA)
+ **GPT OSS** 采用**专家混合（** **Mixture of Experts, MoE** **）****架构，提供两种规模：****1200 亿参数****和****200 亿参数**。
+ **GPTOSS** 作为**仅解码器（decoder-only）**的 **Transformer** 训练而成，并融入了许多现代 **LLM** 的常见特性
    - **grouped query attention（GQA）**：一种改进的注意力机制，允许多个 **query** 头**共享同一组** **key-value** 对，从而**减少内存**占用并**加速**推理
    - 馈层使用 **swiggloo** 激活函数，相比更简单的 **RLU**，能实现更**细腻**的变换
    - **rotary positional embeddings（RoPE）**，将**位置信息**直接嵌入注意力计算，因而更好地支持**长上下文**。
    - 模型采用**预归一化**的 **RMSNorm**：通过“**均方根**”缩放输入，以获得更**稳定**的训练
+ 亮点
    - **131,000 token** 的上下文窗口，这是在**预训练**中就应用 **YaRN** 缩放实现的，而非在推理时临时扩展。
    - 训练完成后，模型**默认以量化格式**发布，因此足够**轻量**，可部署在**一般硬件**上。这使其可运行在**消费级 GPU**、笔记本或其他**资源受限**设备上。不过，目前**未提供**未量化版本。
+ Qwen3**致密模型**共有**七档**规模，其中包含**6B** 级别——是当代开源权重模型中**较小**的一类
+ **Qwen 3** 的一大差异在于其**控制 Q/K/V 投影尺度**的方法，以在**大规模**下保持注意力**分数稳定**。
+ **思考模式融合**：**Qwen 3** 的关键创新，将“**思考/非思考**”两种风格**统一到一个模型**中，用户可**无缝切换**。尽管该特性在 **Qwen** 首发时颇为独特，但 **GPT-5** 现在也提供了类似的切换。
+ DeepSeek V3  的一大不同在于：它采用与 **GPT OSS**、**Qwen 3** **不同**的注意力机制。

