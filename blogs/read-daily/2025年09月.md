# 20250910 Alfred Wahlforss - Listen Labs
+ [https://www.youtube.com/watch?v=-_gPru8KmIE](https://www.youtube.com/watch?v=-_gPru8KmIE)
+ customer research 这是一个极其庞大的市场，因为每家公司都想“以客户为中心”，并深入理解是什么驱动他们的客户。
+ 一家名叫 **Qualrix** 的公司，他们做的全是枯燥的客户问卷调查。这家公司估值 120 亿
+ 一家 **Fortune 500**（财富 500 强）公司：“你们每年在 **Qualrix** 上花多少钱？” 他们说：“每年 1,000 万美元。这一块的总支出大约是 300 亿美元。
+ 这些公司基本都是管理不善的咨询公司，技术含量低，而且动作非常迟缓。非常适合被 **LLM** 颠覆
+ 我们每月有 2,000 条入站线索，但只能为其中 50 位完成上手/接入
+ “模拟回应”：设想一下，能否基于既有访谈进行外推，并据此用“合成访谈”给出建议

# 20250909 visual storytelling
+ [https://www.vev.design/visual-storytelling/](https://www.vev.design/visual-storytelling/)
+ 最简单来说，visual storytelling（视觉叙事）是“showing, not telling（展示而非叙述）”这种叙事技巧的一个华丽说法。
+ 由于人们对视觉刺激的反应速度远快于单纯的文字，而且反应更具个人化
+ 它是一种长篇幅、有意放慢节奏、并且带有沉浸享受感的内容形式，专为长时间注意力设计
+ 作为高度吸引人的内容形式，它们通常包含一定程度的读者参与和个性化，这是其他数字营销形式根本无法实现的。
+ 矛盾的是，网络同时成为了“短小内容”和“大规模视觉叙事”的栖身之所。挑战在于如何在美学吸引力与可用性、可访问性之间找到平衡。
+ 几种实现方式
    - Scrollytelling Sections
    - Horizontal Scrolling Timelines
    - Video Scroll
    - Before & After Sldier
    - Animated Charts
    - 3D Elements
+ 技巧
    - Illustrated experiences（图文并茂）
    - Animation and interactivity
    - Reader agency（观众参与）
    - 文字作为视觉艺术
+ 最佳实践
    - 从一开始就计划视觉内容设计
    - 保持一致的视觉风格
    - 促进读者参与
    - 使用移动和过渡
    - 不要忽略文本
+ SEO-Friendly
    - 压缩
    - 懒加载
    - visual file meta-data
    - 测试速度和性能

# 20250908 Codex
+ [https://developers.openai.com/codex](https://developers.openai.com/codex)
+ 登录账号或者API key 的方式使用都可以
+ 推荐使用 Codex 与 GPT-5，我们最好的编码模型。默认的推理级别是中等
+ 当你希望 Codex 主动修改代码并准备一个 pull request 时，请使用代码模式。
+ 默认是关闭联网的，Codex预设了访问的白名单
+ 提示词技巧
    - Codex 擅长定位相关代码，但当提示将其搜索范围缩小到几个文件或包时，效率更高
    - 当 Codex 能够验证其工作时，它会生成更高质量的输出
    - 你可以告诉 Codex 如何处理任务或使用它的工具
    - 像人类工程师一样，当复杂的工作被分解成更小、更专注的步骤时，Codex 能更好地处理。
    - 当遇到错误或意外行为时，尝试将详细的日志或错误跟踪粘贴到 Codex 中作为首要的调试步骤
    - 除了针对特定任务外，Codex 经常在开放式任务上给我们带来惊喜
+ AGENTS.md 不包括claude code

# 20250907 Turn boring AI designs to Pro-level with these simple steps(下)
+ [https://www.youtube.com/watch?v=lgqnMzOu2Lw](https://www.youtube.com/watch?v=lgqnMzOu2Lw)
+ Unicorn Studio ：非常**lightweight**（轻量）。它的**performant**（性能表现）也很强
+ Spline
+ 这些编辑功能，让它“像设计工具”一样，但同时拥有**AI 赋能**的能力，而且一切都是**代码层**——不是只停留在 **Figma** 里的**静态设计**
+ 对我这样做了 20 年设计的人来说，也很难一眼看出它是 AI 生成的。**这正是我们要的效果**——你的设计/艺术不该给人“AI 味儿”。
+ 如今，让作品**带有 AI 痕迹**几乎像是一种**冒犯**。能避免就尽量避免。即便大家知道它是 AI 生成的，也务必**保证质量**——不要给人“投机取巧/做得很糙”的感觉，比如“六根手指”“怪异的眼睛”等问题
+ **Spline** 是一款**基于浏览器的 3D 设计与交互工具**，主打“所见即所得”的建模、动画、互动（鼠标/触摸事件）和**网页嵌入**，并支持多人**实时协作**
+ 切换到 **cloud 4**，因为它在**修复类任务**上通常更**stable**（稳定）、更**robust**（可靠）；**创意**阶段已经完成——这一点 **GP5** 很擅长。

# 20250906 Turn boring AI designs to Pro-level with these simple steps（上）
+ [https://www.youtube.com/watch?v=lgqnMzOu2Lw](https://www.youtube.com/watch?v=lgqnMzOu2Lw)
+ **AI** 特别喜欢给的那些渐变色
+ **GPT5** 是一次巨大的飞跃,此前大约只能生成 200 行，如今一次就能生成约 800 行代码，这带来了巨大的差别。你会得到更高的一致性；**image-to-HTML** 转换效果更好；视觉理解能力也更强
+ **GPT5** 生成的那些紫色渐变更少，结构更好，排版（**typography**）等方面也更佳。它对字距（**letter spacing**）和字体（**fonts**）的理解更到位。
+ GPT5在动画方面可能不那么理想，所以有时你需要切换到 **Cloud 4**
+ **Cloud 4** 在结构、**HTML** 与代码层面的稳定性上可能更“聪明”一些；但 **GP5**（即 **GPT5**）显然更有创造力，也更专业，并且视觉理解更强。
+ 如果只是做一个落地页，你不必指定这些细节；但如果你只做单个区块，就完全可以把这些都写清楚。
+ 如果你有明确的品牌基调，强调色（accent color）可以是蓝色——但千万别用紫色，因为 **AI** 很爱自动给紫色。可以用琥珀色（amber）或橙色，这些很流行；翠绿色（emerald）现在也很受欢迎
+ 投影、背景、边框之类的设置，如果拿不准，就直接跳过也没问题。
+ 越来越多设计师在用 _guys_，因为 _inter_ 更像 **AI** 的默认回退字体。如果你想让设计更有一点“oomph”（冲击力/劲儿），_guys_ 是个不错的选择
+ 我发现 **AI** 聚焦单一区块时产出更好：会为该区块生成更多代码与细节；整页截屏反而使每个区块的细节变少，这不是我们想要的
+ **AI** 对“偏方正”的布局不太拿手，除非你明确说明，它仍倾向使用更**圆角**的样式。你可以明确要求“更方正（squareish）”，或“圆角半径设为 0”。
+ 每次“借鉴灵感”时，一个**非常非常重要**的步骤是：打开 **Prompt Builder**，然后在提示里写上诸如“修改文本（change text）”“使用 **lucid icon**”“做成响应式（make responsive）”之类的要求。
+ 当你在既有模板上混改时，风格一致性会非常好。
+ 尽量**减少普通粗体（bold）****的使用。原因是现在屏幕更好了，而 ****AI**** 又很喜欢到处用粗体**
+ **AI** 经常生成**很糟糕的素材**，通常**随机抓自 Unsplashed**（原文如此，常见平台应为 **Unsplash**），而且 **AI** 喜欢反复用同一批素材、同一套头像

# 20250902 OpenAI vs. Deepseek vs. Qwen: Comparing Open Source LLM Architectures（ 下）
+ [https://www.youtube.com/watch?v=raTbhtKZTZA](https://www.youtube.com/watch?v=raTbhtKZTZA)
+ DeepSeek **V3.1** 保留了与 **V3** 相同的核心架构，但提供了更强的推理、更聪明的工具调用以及更高的整体性能
    - 在现代 **LLM** 中，大量算力与内存都被 **KV cache** 占据，因此 **V3** 采用 **MLA**：先把 **keys/values** 压缩到更小的 **latent space**（潜空间）再缓存，推断时再解压使用。
+ **Quen** 的 **MoE** 基座模型只用到五分之一的 **active parameters**（激活参数）就达到了 **dense** 模型的性能。
+ 各家如何扩展 **context length**（上下文长度）,使模型能处理远超原始训练上限的序列。
    - **GPTOSS** 从预训练阶段就应用 **Yarn**，因此权重原生适配 **131k** 上下文；**GPTOSS** “生来”就具备长上下文
    - **Deepsee** 采取分阶段路线——先微调到 **32k**，再训练到 **128k**；**DeepSeek** 通过分步学习获得；**Quen** 则在 **32k** 训练基础上把极限再往外推。
    - **Quen** 也微调到 **32k**，但跳过了后续再训练。**Quen** 在 **inference** 阶段再次应用 **Yarn scaling**——把 **RoPE** 基频放大 **4×**，无需额外再训练就达到 **128k**
+ 各主流模型在后训练与推理阶段都大量依赖 **reinforcement learning (RL)**——更有趣甚至出人意料的是，部分 **RL** 训练所需数据量极小：比如 **Quinn** 仅用 **4,000** 对数据。
+ 各实验室之间数据集差异不透明；显然，幕后进行了大量 **dataset**,这部分工作很可能构成它们的 **moat**（护城河）的一大块，使公司在开源/发布模型时更有底气——外界很难复刻其成果。
+ 不要只盯着 **benchmark** 或“**context size**”等顶层指标；要关注各实验室为达成这些结果所采用的具体方法。

# 20250902 OpenAI vs. Deepseek vs. Qwen: Comparing Open Source LLM Architectures（上）
+ [https://www.youtube.com/watch?v=raTbhtKZTZA](https://www.youtube.com/watch?v=raTbhtKZTZA)
+ **GPT OSS** 采用**专家混合（** **Mixture of Experts, MoE** **）****架构，提供两种规模：****1200 亿参数****和****200 亿参数**。
+ **GPTOSS** 作为**仅解码器（decoder-only）**的 **Transformer** 训练而成，并融入了许多现代 **LLM** 的常见特性
    - **grouped query attention（GQA）**：一种改进的注意力机制，允许多个 **query** 头**共享同一组** **key-value** 对，从而**减少内存**占用并**加速**推理
    - 馈层使用 **swiggloo** 激活函数，相比更简单的 **RLU**，能实现更**细腻**的变换
    - **rotary positional embeddings（RoPE）**，将**位置信息**直接嵌入注意力计算，因而更好地支持**长上下文**。
    - 模型采用**预归一化**的 **RMSNorm**：通过“**均方根**”缩放输入，以获得更**稳定**的训练
+ 亮点
    - **131,000 token** 的上下文窗口，这是在**预训练**中就应用 **YaRN** 缩放实现的，而非在推理时临时扩展。
    - 训练完成后，模型**默认以量化格式**发布，因此足够**轻量**，可部署在**一般硬件**上。这使其可运行在**消费级 GPU**、笔记本或其他**资源受限**设备上。不过，目前**未提供**未量化版本。
+ Qwen3**致密模型**共有**七档**规模，其中包含**6B** 级别——是当代开源权重模型中**较小**的一类
+ **Qwen 3** 的一大差异在于其**控制 Q/K/V 投影尺度**的方法，以在**大规模**下保持注意力**分数稳定**。
+ **思考模式融合**：**Qwen 3** 的关键创新，将“**思考/非思考**”两种风格**统一到一个模型**中，用户可**无缝切换**。尽管该特性在 **Qwen** 首发时颇为独特，但 **GPT-5** 现在也提供了类似的切换。
+ DeepSeek V3  的一大不同在于：它采用与 **GPT OSS**、**Qwen 3** **不同**的注意力机制。

