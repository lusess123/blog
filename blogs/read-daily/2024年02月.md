# 20240204  NLP Course  6 ： THE 🤗 TOKENIZERS LIBRARY (上)
[https://huggingface.co/learn/nlp-course/chapter6/1?fw=pt](https://huggingface.co/learn/nlp-course/chapter6/1?fw=pt)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707055180554-33ccfd5b-0db8-4e96-838a-6ca932ca8343.png#averageHue=%23fdfaf5&clientId=u7e71d0d0-0cbb-4&from=paste&height=193&id=u31289722&originHeight=385&originWidth=1735&originalType=binary&ratio=2&rotation=0&showTitle=false&size=39974&status=done&style=none&taskId=uf59c2a3b-0230-4bd4-a897-873f6f6ba4d&title=&width=867.5)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707055315192-8cc8cf94-dbb2-4922-9898-0f385754d275.png#averageHue=%23fcf8ed&clientId=u7e71d0d0-0cbb-4&from=paste&height=512&id=u85c3ee33&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1486364&status=done&style=none&taskId=ue3544c4c-3ac7-40a3-99b7-955ad25ccf2&title=&width=512)

- 一个在英文语料库上训练的Tokenizer在日文文本的语料库上表现会很差，因为两种语言中空格和标点符号的使用非常不同
- Training a new tokenizer from an old one
   - 大多数Transformer模型使用subword(子词)分词算法
   - 为了识别哪些subwords(子词)是有趣的并且在手头的语料库中最常出现，tokenizer需要仔细查看语料库中的所有文本 —— 这个过程我们称之为training。
   - 训练一个tokenizer(分词器)与训练一个模型不同！模型训练使用stochastic gradient descent(SGD)(随机梯度下降)使每个批次的loss(损失)稍微减小。它本质上是随机的（意味着你必须设置一些seed(种子)以在进行相同训练两次时获得相同的结果）。
   - 训练一个tokenizer(分词器)是一个统计过程，试图识别哪些subword(子词)是给定语料库中最佳选择，而用于选择它们的确切规则取决于tokenization algorithm(分词算法)。它是deterministic(确定性的)，意味着在相同的语料库上使用相同的算法训练时，你总是获得相同的结果。
   - 使用python的Generator Expression（生成器表达式）而不是List Comprehension（列表推导式）用于节约内存
   - 快速分词器由🤖 Tokenizers 库支持，后者是用 Rust 编程语言编写的。
   - 模型计算核心的矩阵乘法是使用 CUDA 编写的，这是一种针对 GPU 优化的 C 库。
- Fast tokenizers’ special powers
   - Fast tokenizer 的快速除了并行之外还有 “跟踪来自偏移列表每个令牌的文本跨度”
   -  fast tokenizer 需要进行 post-processing，主要是增加了上下文信息（比如偏移量），并且用rust实现包装性能和效率
# 20240202 Announcing Multion：与AI Agents 为人类建立更美好的未来
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706885972970-f8fb0f60-093a-4aa1-982c-c2ca23008da8.png#averageHue=%238c9e8f&clientId=ue927c512-cbf0-4&from=paste&height=334&id=u3e91d129&originHeight=667&originWidth=1000&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1139109&status=done&style=none&taskId=u92dee6d2-fecb-4c49-99bb-c23a8e0bdf5&title=&width=500)
[https://www.multion.ai/blog/multion-building-a-brighter-future-for-humanity-with-ai-agents](https://www.multion.ai/blog/multion-building-a-brighter-future-for-humanity-with-ai-agents)

- Multion是一家旨在开发AI产品和技术的开拓性AI初创公司，旨在开发AI产品和技术
- Multion是AI代理，它采取行动并与数字世界进行互动，以解决人们宁愿将其委派给助手的平凡任务
- MultiOn的创意来自斯坦福大学的2个人 Div Garg 和 Omar Shaya
   - Div同时有三份工作，在斯坦福教课，机器人初创公司，副业。他想从无聊平凡的工作中解放出来，去做一些有创意和有意义的工作
   - Omar，一个追求技术和创业目标的环球旅行者，一直认为技术可以做更多的事情来帮助他在新的地方定居，就像朋友和家人在家乡所能提供的一样
- Div在斯坦福，他的研究聚焦于大型语言模型和强化学习，将它们应用于如能在视频游戏比赛中赢得顶级奖项的AI代理、可以通过语言控制的机器人、以及获得广泛媒体报道的最先进自动驾驶系统等项目
- Omar拥有丰富的计算机科学和消费产品经验，曾在微软和Meta领导开发消费者AI产品的团队。奥马尔对社交媒体平台的算法优化和微软的AI助手开发的深刻理解，为他创立MultiOn和制定其独特产品愿景提供了坚实的基础。
- Multion的愿景不是替代人类的机器，而是增加人类
- 最早的demo取得了很大的成功
- 亚马逊Alexa Fund的董事保罗·伯纳德（Paul Bernard）说：“跨越正在重新定义AI时代的最前沿。Multion的AI代理具有与Internet上几乎任何设备或接口连接的能力，令人印象深刻。”
# 20240202 MultiOn AI
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706882599310-2e192e90-347f-48c7-9b74-775291fda917.png#averageHue=%23fcfbfb&clientId=u51acee71-69a5-4&from=paste&height=329&id=u1a602f60&originHeight=658&originWidth=1834&originalType=binary&ratio=2&rotation=0&showTitle=false&size=141056&status=done&style=none&taskId=u940c53c0-0602-4928-b421-91bac78d278&title=&width=917)
[https://docs.multion.ai/](https://docs.multion.ai/)

- Multion是下一代Web AI代理，可以代表您在Internet上采取行动
- 通过浏览器插件，可以完全自动化
- 支持两种模式 step by step 和 auto
- 也支持通过api写代码的方式进行操作， 无代码 和 代码
   - 每个会话都是隔离的
   - 集成Langchain ，LlamaHub， OpenAI Assistants API
   - LlamaHub是一个开源项目，提供了一系列数据连接器，这些连接器可以将来自各种源的原始数据转换为向量，以便大型语言模型（LLMs）如ChatGPT和Google Bard等更容易地访问和转换这些数据
- 盈利模式

![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706886794855-28596678-c113-4126-b4ae-1ea5fbd16ab3.png#averageHue=%23333333&clientId=uc5046217-dcf9-4&from=paste&height=763&id=u4e1ab751&originHeight=1526&originWidth=2584&originalType=binary&ratio=2&rotation=0&showTitle=false&size=546936&status=done&style=none&taskId=ua70b853e-08c8-432c-9a16-c6193245208&title=&width=1292)
# 20240202 LangChain Introduction
[https://js.langchain.com/docs/get_started/introduction](https://js.langchain.com/docs/get_started/introduction)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706869769957-58c45cd4-7136-449a-a664-4f976d5573c5.png#averageHue=%239bb4cd&clientId=u5f68a4b6-623a-4&from=paste&height=630&id=ua0133044&originHeight=1260&originWidth=1568&originalType=binary&ratio=2&rotation=0&showTitle=false&size=547096&status=done&style=none&taskId=u03625e9c-e3e2-4d41-9f32-34ca2433db6&title=&width=784)

- 定义：LangChina 是一个用于开发大模型应用的开发框架
- 提供两个能力：
   - 上下文感知
   - 推理
- 组成部分：
   - LangChain Libraries： 
      - 组件： 组件是模块化的
      - Off-the-shelf（现成的） chains
   - LangChain Templates: 各种不同任务的参考架构集合，目前只支持python
   - LangSmith: 一个运维平台
- LCEL：LangChain Expression Language
   - LCEL是构成链条的声明性方法。
   - LCEL从第1天开始设计，以支持将原型放在生产中，没有任何代码更改，从最简单的“提示 + LLM”链到最复杂的链条。
- modules： 标准的，可扩展的接口和集成
   - Model I/O
   - Retrieval: 应用特有的数据接口
   - Agents: 让模型选择使用的给定高级指令的工具



# 20240201 OpenAgents: An Open Platform for Language Agents in the Wild
[https://github.com/xlang-ai/OpenAgents](https://github.com/xlang-ai/OpenAgents)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706776082319-cd2bd575-bbfa-4f08-b7da-e13dedb3c31f.png#averageHue=%23ededec&clientId=uf0d4ec3a-9a3e-4&from=paste&height=696&id=u3e3f5718&originHeight=1391&originWidth=2596&originalType=binary&ratio=2&rotation=0&showTitle=false&size=765644&status=done&style=none&taskId=u2d762ba0-0b37-42bd-8ce3-f455ccb3ddb&title=&width=1298)

- 当前language agent frameworks的问题：
   - 只是proof-of-concept（概念验证）
   - 忽视非专业人士
   - 应用层的设计太少
- 目标是real-world language agents
- Web代理利用Chrome扩展程序的功能自动导航和探索网站。该代理简化了网络浏览体验，使查找相关信息，访问所需资源等变得更容易
- 缺点：打开新页面需要手动激活插件，这点无法自动化，看起来是否可以通过启动一个客户端来完成
- 原则：
   - 面对的是有形的具体的上下文
   - 自然语言的反馈
   - 工具支持增强
- “代理”是指直接或与工具与环境交互的系统或模型。通常，这是一个大型语言模型（LLM），提示采取行动或定制的中型模型。它遵循语言指令并通过预测用特定参数激活API函数的令牌来预测操作。
- 通常，LLM在语言理解和产生方面具有很强的能力，尤其是遵循指示，计划和推理，因此可以提示作为代理的政策网络，以执行一系列任务
- 本质上，Tool是Environment的组成部分，提供了一个快捷方式，该快捷方式封装了一系列操作以易于访问。例如，Serpapi是一种简化了在Google上搜索的用户过程的工具。
- In-context Human Feedback (内在的人类反馈)机制是X-lang最关键的特性，有两个好处：
   - 协助人物完成，因为用户是最了解人物的，需要用户的反馈
   - 更深的人物探索，用户的目标是随时会变化的
- 架构和技术
   - Agent
      - 基于LangChain中的ReAct
      - LangChain的不足之处
         - 工具还是不够用
         - 控制台输入已经不够用，需要更多的界面反馈
         - 相同的信息（例如，LLM上下文）通常需要根据情况不同而以不同方式表示
         - LangChain中当前提示设计的两个主要问题：一是过分依赖工具导致的代理响应不一致性，二是提示中包含的特定短语可能对用户界面的友好性和视觉吸引力产生负面影响。
   - Environment
      - 环境的实现在很大程度上依赖于目标代理的行动空间。
      - 实际上，代理通过使用不同的工具范围和组合来适应它们的场景
      - 浏览器扩展可以对网站进行自动探索和导航
   - In-context Human Feedback
      - 两个关键部分组成：
         - 前端交互界面：[https://github.com/mckaywrigley/chatbot-ui](https://github.com/mckaywrigley/chatbot-ui) Chatbot-ui基础上增加了一些新功能
         - 内存：当前端获得人类输入时，它将其作为LLM历史上下文的组成部分转移到代理的内存中
- 我们的系统根据个人用户需求智能自动选择最佳插件。
- 想象一个工具，可以通过随着时间的推移而提高的效率和准确性来复制人类互动。这是Web Agent的本质。
   - 一个稳定的框架，目前并没有开源
   - LLM不仅仅是沟通
   - 不仅仅是页面导航
- 工作流：
   - 聊天代理
   - 网页导航代理
- 愿景
   - Web Agent的变革潜力是无限的
   - 当我们拥抱未来时，网络代理不仅旨在成为助手，而且是对自己的数字扩展。数字领域将不再令人生畏。有了Web代理，一切都在障碍范围内。

![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706762493420-c3094bbd-d046-4492-b2d8-77cc012a6bbc.png#averageHue=%23f6f7f8&clientId=ucb69abe3-1759-4&from=paste&height=458&id=ua9e2fb6c&originHeight=916&originWidth=1539&originalType=binary&ratio=2&rotation=0&showTitle=false&size=202936&status=done&style=none&taskId=ua5878bcf-ff6a-4a44-acfc-a2f0f33b41b&title=&width=769.5)

# 20240201 Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception
[https://github.com/X-PLUG/MobileAgent](https://github.com/X-PLUG/MobileAgent)

- Introduction
   - 纯视觉，独立于XMl和系统元数据
   - 无限制的操作行为，跨多应用
   - 多种视觉感知工具用于操作本地
   - 不需要探索，训练，插入和播放
- 在感知非英语屏幕截图时，GPT-4V将会产生严重的幻觉
- Mobile-eval是一种旨在评估移动设备代理性能的基准。该基准包括10个主流单应用方案和1个多应用方案。
- Grounding DINO的信息，它是一个与目标检测相关的项目，使用PyTorch实现，并提供了预训练模型。该项目的重点包括与语言结合的目标检测、零标注训练、图像分割等。
- ![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706754829821-5065739e-ae66-4914-a29b-c80e5a102ab0.png#averageHue=%23a7b5c0&clientId=uc884cdce-41de-4&from=paste&height=512&id=u0aa05777&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=916566&status=done&style=none&taskId=u35e055bc-ed43-4345-bad5-99a32e3361c&title=&width=512)
- ![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706754848111-988a83e3-9762-4a64-8fd5-6191900a5516.png#averageHue=%23c87d42&clientId=uc884cdce-41de-4&from=paste&height=448&id=u5e9b9ca4&originHeight=896&originWidth=2953&originalType=binary&ratio=2&rotation=0&showTitle=false&size=881990&status=done&style=none&taskId=u302f65ea-9f2f-4903-a144-5a4511f495d&title=&width=1476.5)
