# 20240211 2024 is the Year of the AI AGENT
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707636754436-a13e5c95-b707-47f1-a05d-e60b5b579248.png#averageHue=%23a18451&clientId=u87a33967-2f24-4&from=paste&height=874&id=u67e097f6&originHeight=1748&originWidth=1346&originalType=binary&ratio=2&rotation=0&showTitle=false&size=2481337&status=done&style=none&taskId=ude924c63-431d-463d-91d5-94b65d67bd4&title=&width=673)
[https://www.youtube.com/watch?v=hmt5MnStKUI&t=379s](https://www.youtube.com/watch?v=hmt5MnStKUI&t=379s)

- Agentboard ：强调对大型语言模型（LLMs）进行分析评估，作为通用代理程序在各种环境中感知和行动的能力。[https://hkust-nlp.github.io/agentboard/](https://hkust-nlp.github.io/agentboard/)
- Voyager：具有大语言模型的开放式具身代理；"具身代理"是指一个智能代理系统，它不仅仅是一个虚拟存在或者算法，而是在物理世界中具有一定形态或身体，可以与环境进行交互、感知和行动 [https://voyager.minedojo.org/](https://voyager.minedojo.org/)
- adept ：使用计算机的新方法，建立一个机器学习模型，该模型可以与计算机上的所有内容进行交互。[https://www.adept.ai/](https://www.adept.ai/)
- Rabbit： 学习人类在计算机应用上面行动 [https://www.rabbit.tech/research](https://www.rabbit.tech/research)
- RPA，基本上是你在录制屏幕，然后部署一个算法，一个预先编程的序列，来导航你的鼠标，你的光标到XY位置，基于绝对的坐标
- 神经符号算法更进一步，因为我们不是通过屏幕的绝对坐标来识别所有这些元素，我们从符号方法中直接提取和自动标记一些元素，并对这些元素进行推理，这意味着，如果一个应用程序完全改变了界面，也不会有关系
- **根本的哲学逻辑是，所有这些现代软件都是为了人眼来处理信息设计的，**它们必须在某个地方有一个设置
# 20240210 The next grand challenge for AI
[https://www.ted.com/talks/jim_fan_the_next_grand_challenge_for_ai/transcript?subtitle=en](https://www.ted.com/talks/jim_fan_the_next_grand_challenge_for_ai/transcript?subtitle=en)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707532853545-28fecd45-3e5a-4d91-830c-11a1293e6696.png#averageHue=%233f413d&clientId=ue97aebf6-6ec3-4&from=paste&height=409&id=uc743a1c0&originHeight=818&originWidth=1468&originalType=binary&ratio=2&rotation=0&showTitle=false&size=112788&status=done&style=none&taskId=uf17d7219-195c-426a-acd6-f21b5a95dfc&title=&width=734)

- Alphago只能单独做一件事
- Voyager是一个agent，在许多技能方面都大大扩展。
- Minecraft的玩家是英国人口的两倍
- Voyager的核心思想是coding as action
- self-reflection的feedback有三个来源：
   - JavaScript代码执行错误；
   - agent的状态，例如健康和饥饿；
   - world的状态，例如附近的地形和敌人
- 我们只给Voyager一个高级指令，那就是尽可能获取尽可能多的独特物品
- 我们没有提前编程任何这样的内容。这都是Voyager的想法。这，你在这里看到的，是我们所说的终身学习。当一个代理永远好奇，永远在追求新的冒险。与AlphaGo相比，Voyager在他能做的许多事情上都大规模扩展，但仍然只控制Minecraft中的一个身体。
- 我们能有一个适用于许多不同身体的算法吗？让我们来看看MetaMorph。这是我在斯坦福共同开发的一个项目。我们创建了一个基础模型，它不仅可以控制一个，而且可以控制成千上万个具有非常不同的手臂和腿部配置的机器人。Metamorph能够处理来自不同机器人身体的极其多样化的运动特性。
- IsaacSim的最大优势是将物理模拟加速到比实时快1,000倍。
- 这是一个有趣的主意。如果agent能够掌握10,000个模拟，那么它很可能只是概括为我们的真实世界，这只是第10,001个现实
- 我相信训练Foundation Agent将与Chatgpt非常相似。所有语言任务都可以表示为文本和文本。
- 有一天，我们将意识到，无论是在物理还是虚拟空间中，所有的AI代理，都在Wall-E，星球大战，头号玩家 上，与同一Foundation Agent都有不同的 提示词 。我的朋友们，这将是我们寻求AI的下一个大挑战。
# 20240208 NLP Course  7 ：MAIN NLP TASKS (上)
[https://huggingface.co/learn/nlp-course/chapter7/1?fw=pt](https://huggingface.co/learn/nlp-course/chapter7/1?fw=pt)

- 本章基本上是重复前面的东西，让你对整个任务有更深入的了解
- Token classification
   - 将标签归因于句子中的每个token
      - Named entity recognition (NER)
      - Part-of-speech tagging (POS)
      - Chunking
   - 数据预处理其实是最艰难的部分
   -  使用Trainer API对模型进行Fine-tuning
      - 数据批处理
      - 度量函数
- Fine-tuning a masked language model
   - 用于预读的语料库与用于微调的语料库没有太大不同，转移学习通常会产生良好的结果。
   - 对内域数据进行验证的语言模型进行微调的过程通常称为domain adaptation（域适应性）
# 20240208 The Rust Programming Language-Introduction
[https://doc.rust-lang.org/book/ch00-00-introduction.html](https://doc.rust-lang.org/book/ch00-00-introduction.html)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707395513215-134428ea-45e2-4cca-a502-a45a2ea09a36.png#averageHue=%23722218&clientId=ud5efa388-364e-4&from=paste&height=424&id=u196dd236&originHeight=847&originWidth=1259&originalType=binary&ratio=2&rotation=0&showTitle=false&size=100504&status=done&style=none&taskId=u8c3a4045-d91f-4eb0-bba3-85b4bad7ddc&title=&width=629.5)

- Rust可帮助您更快，更可靠的软件编写。在编程语言设计中，High-level ergonomics（人体工程学） 和 low-level control通常会矛盾；Rust试图解决这个冲突。
- Rust适合谁
   - 开发团队
      - 编译器
      - 工具链
   - 学生
      - 系统编程的概念
   - 公司
      - 生态
   - 开源代码开发者
   - 重视速度和稳定的人
      - zero-cost abstractions（零成本抽象）
- 本书目录
   - Chapter 1 Helloworld
   - Chapter 2 一个demo, 测试数字的游戏
   - Chapter 3 涵盖了与其他编程语言相似的RUST功能
   - Chapter 4 ownership system
   - Chapter 5  structs and method
   - Chapter 6  enums, match expressions
   - Chapter 7 模块化系统
   - Chapter 8   some common collection data structures 
   - Chapter 9 error-handling
   - Chapter 10  generics, traits, and lifetimes
   -  Chapter 11 testing
   - Chapter 12 一个命令行工具的例子
   - Chapter 13 用于函数式编程的 closures（闭包） and iterators（迭代器）
   - Chapter 14 深入Cargo
   - Chapter 15 智能指针
   - Chapter 16 并发编程
   - Chapter 17 对比传统的面向对象编程
   - Chapter 18 模型匹配
   - Chapter 19 一些先进的主题
   - Chapter 20 开发一个web服务器
# 20240207《Elon Musk》34 Falcon 9 Lifto Cape Canaveral, 2010
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707314532115-d16bc6e1-1446-4eba-8f4b-3e3b8eda5c66.png#averageHue=%237d7d7d&clientId=u883a8359-d556-4&from=paste&height=452&id=u9477663f&originHeight=904&originWidth=1332&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1053587&status=done&style=none&taskId=ueb21b0ba-36d0-43e0-a4a4-3c31eafd277&title=&width=666)

- 进入轨道
   - 对Elon的重要意义是，如果您告诉他风险并向他展示了工程数据，他将进行快速评估，并让责任从您的肩膀转移到他的肩膀上。
- ... and return
   - SpaceX不仅可以将无人胶囊推入轨道，而且还可以安全地将其返回地球。没有私人公司这样做。实际上，只有三个政府拥有：美国，俄罗斯和中国。
   - 在Musk或奥巴马出生之前，水星计划已经完成了类似的壮举
# 20240206 LangChain:  Why use LCEL ？
[https://python.langchain.com/docs/expression_language/get_started#entire-pipeline](https://python.langchain.com/docs/expression_language/get_started#entire-pipeline)

- 什么是LCEL？
   - LangChain Express Language
   - LCEL使从基本组件构建复杂的链条变得容易，并支持out of the box的功能，例如流媒体，并行性和日志记录。
   - 例子： chain = prompt | model | output_parser
   - Python代码使用了管道操作符(**|**)，这在标准Python语法中并不直接存在。这种用法可能来自特定的库或框架，它们通过重载对象的**__or__**方法来实现自定义的管道操作。这种做法在某些数据处理和流式处理库中很常见，比如Pandas的某些扩展、Dask或类似的可以链式调用的库，用以简化代码并提高可读性。 是一种内部DSL
- why?
   - 通用的接口：每个 LCEL 对象都支持invoke, batch, stream, ainvoke, …
   - 原子组合
- ![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707221553404-5c79d55e-b2ad-4ffa-bf15-a4b997915290.png#averageHue=%23606355&clientId=u15361ee1-1e74-4&from=paste&height=512&id=ud25664e0&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1825108&status=done&style=none&taskId=u5499bc7b-54da-4dbb-851a-376152be307&title=&width=512)

# 20240204  NLP Course  6 ： THE 🤗 TOKENIZERS LIBRARY (下)
[https://huggingface.co/learn/nlp-course/chapter6/3b?fw=pt](https://huggingface.co/learn/nlp-course/chapter6/3b?fw=pt)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707117984912-3c08ac8e-5218-4c8f-865c-e7f4b9839fc3.png#averageHue=%23fdf8ef&clientId=u2f759465-0fc4-4&from=paste&height=158&id=ucc9df4b1&originHeight=316&originWidth=1735&originalType=binary&ratio=2&rotation=0&showTitle=false&size=42034&status=done&style=none&taskId=ua4c0938f-2ea3-4337-b574-bd1eccec057&title=&width=867.5)

- Fast tokenizers in the QA pipeline
   - QA pipeline需要处理和返回长文本
   - return_overflowing_tokens=True允许分词器(tokenizer)返回所有因超出最大长度(max_length)而溢出的tokens，这些溢出的tokens被组织成多个块。通过设定stride值，我们可以控制这些块之间的重叠部分，确保上下文的连贯性和完整性，从而在不丢失重要信息的前提下，有效处理长上下文。
- Normalization and pre-tokenization
   - SentencePiece算法是 reversible tokenization（可逆令牌），BERT tokenizer 是不可逆的
   - 三个主要的subword tokenization算法：
      - BPE (used by GPT-2 and others), 
      - WordPiece (used for example by BERT)
      - Unigram (used by T5 and others)
- Byte-Pair Encoding tokenization
   - OpenAI使用的，用在Transformer模型
   - 将单词拆分成字符，然后从两个字符开始合并
- WordPiece tokenization
   - google 开发的，跟BPE非常相似
   - google并没有开源其实现，所以这些实现都是猜测的
   - 给定一个单词，算法从最长可能的片段（在词汇表中）开始匹配，然后逐步减小片段长度，直到找到匹配的tokens。
- Unigram tokenization
   - 应用在 SentencePiece
   - 基本思想是从一个大的候选词汇集合出发，通过优化概率模型来逐步减少词汇集合的大小，最终得到一个高效的分词结果
   - Unigram算法能够自适应不同语言和领域的文本，因为它基于数据的统计特性来建立词汇表。
- Building a tokenizer, block by block
   - tokenization的四个步骤
      - **标准化(Normalization)**：可能包括去除空格、标点符号、文本中的特殊字符，进行Unicode标准化，以及删除或转换口语词汇和缩写等。这有助于减少文本中的变异性，确保相似的文本片段在处理时被视为相同。
      - **预分词(Pre-tokenization)**：通常是词(words)或子词(subwords)
      - **通过模型处理(Running the input through the model)**：根据所使用的分词算法（如BPE、WordPiece或Unigram），预分词单元可能会被进一步分解成更小的单元或被转换成模型的词汇表中的索引。
      - **后处理(Post-processing)**：、生成注意力掩码(attention masks)和token类型IDs(token type IDs)。特殊tokens用于模型理解句子的结构，如区分两个句子或表示句子的开始和结束


# 20240204  NLP Course  6 ： THE 🤗 TOKENIZERS LIBRARY (上)
[https://huggingface.co/learn/nlp-course/chapter6/1?fw=pt](https://huggingface.co/learn/nlp-course/chapter6/1?fw=pt)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707055180554-33ccfd5b-0db8-4e96-838a-6ca932ca8343.png#averageHue=%23fdfaf5&clientId=u7e71d0d0-0cbb-4&from=paste&height=193&id=u31289722&originHeight=385&originWidth=1735&originalType=binary&ratio=2&rotation=0&showTitle=false&size=39974&status=done&style=none&taskId=uf59c2a3b-0230-4bd4-a897-873f6f6ba4d&title=&width=867.5)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707055315192-8cc8cf94-dbb2-4922-9898-0f385754d275.png#averageHue=%23fcf8ed&clientId=u7e71d0d0-0cbb-4&from=paste&height=512&id=u85c3ee33&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1486364&status=done&style=none&taskId=ue3544c4c-3ac7-40a3-99b7-955ad25ccf2&title=&width=512)

- 一个在英文语料库上训练的Tokenizer在日文文本的语料库上表现会很差，因为两种语言中空格和标点符号的使用非常不同
- Training a new tokenizer from an old one
   - 大多数Transformer模型使用subword(子词)分词算法
   - 为了识别哪些subwords(子词)是有趣的并且在手头的语料库中最常出现，tokenizer需要仔细查看语料库中的所有文本 —— 这个过程我们称之为training。
   - 训练一个tokenizer(分词器)与训练一个模型不同！模型训练使用stochastic gradient descent(SGD)(随机梯度下降)使每个批次的loss(损失)稍微减小。它本质上是随机的（意味着你必须设置一些seed(种子)以在进行相同训练两次时获得相同的结果）。
   - 训练一个tokenizer(分词器)是一个统计过程，试图识别哪些subword(子词)是给定语料库中最佳选择，而用于选择它们的确切规则取决于tokenization algorithm(分词算法)。它是deterministic(确定性的)，意味着在相同的语料库上使用相同的算法训练时，你总是获得相同的结果。
   - 使用python的Generator Expression（生成器表达式）而不是List Comprehension（列表推导式）用于节约内存
   - 快速分词器由🤖 Tokenizers 库支持，后者是用 Rust 编程语言编写的。
   - 模型计算核心的矩阵乘法是使用 CUDA 编写的，这是一种针对 GPU 优化的 C 库。
- Fast tokenizers’ special powers
   - Fast tokenizer 的快速除了并行之外还有 “跟踪来自偏移列表每个令牌的文本跨度”
   -  fast tokenizer 需要进行 post-processing，主要是增加了上下文信息（比如偏移量），并且用rust实现包装性能和效率
# 20240202 Announcing Multion：与AI Agents 为人类建立更美好的未来
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706885972970-f8fb0f60-093a-4aa1-982c-c2ca23008da8.png#averageHue=%238c9e8f&clientId=ue927c512-cbf0-4&from=paste&height=334&id=u3e91d129&originHeight=667&originWidth=1000&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1139109&status=done&style=none&taskId=u92dee6d2-fecb-4c49-99bb-c23a8e0bdf5&title=&width=500)
[https://www.multion.ai/blog/multion-building-a-brighter-future-for-humanity-with-ai-agents](https://www.multion.ai/blog/multion-building-a-brighter-future-for-humanity-with-ai-agents)

- Multion是一家旨在开发AI产品和技术的开拓性AI初创公司，旨在开发AI产品和技术
- Multion是AI代理，它采取行动并与数字世界进行互动，以解决人们宁愿将其委派给助手的平凡任务
- MultiOn的创意来自斯坦福大学的2个人 Div Garg 和 Omar Shaya
   - Div同时有三份工作，在斯坦福教课，机器人初创公司，副业。他想从无聊平凡的工作中解放出来，去做一些有创意和有意义的工作
   - Omar，一个追求技术和创业目标的环球旅行者，一直认为技术可以做更多的事情来帮助他在新的地方定居，就像朋友和家人在家乡所能提供的一样
- Div在斯坦福，他的研究聚焦于大型语言模型和强化学习，将它们应用于如能在视频游戏比赛中赢得顶级奖项的AI代理、可以通过语言控制的机器人、以及获得广泛媒体报道的最先进自动驾驶系统等项目
- Omar拥有丰富的计算机科学和消费产品经验，曾在微软和Meta领导开发消费者AI产品的团队。奥马尔对社交媒体平台的算法优化和微软的AI助手开发的深刻理解，为他创立MultiOn和制定其独特产品愿景提供了坚实的基础。
- Multion的愿景不是替代人类的机器，而是增加人类
- 最早的demo取得了很大的成功
- 亚马逊Alexa Fund的董事保罗·伯纳德（Paul Bernard）说：“跨越正在重新定义AI时代的最前沿。Multion的AI代理具有与Internet上几乎任何设备或接口连接的能力，令人印象深刻。”
# 20240202 MultiOn AI
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706882599310-2e192e90-347f-48c7-9b74-775291fda917.png#averageHue=%23fcfbfb&clientId=u51acee71-69a5-4&from=paste&height=329&id=u1a602f60&originHeight=658&originWidth=1834&originalType=binary&ratio=2&rotation=0&showTitle=false&size=141056&status=done&style=none&taskId=u940c53c0-0602-4928-b421-91bac78d278&title=&width=917)
[https://docs.multion.ai/](https://docs.multion.ai/)

- Multion是下一代Web AI代理，可以代表您在Internet上采取行动
- 通过浏览器插件，可以完全自动化
- 支持两种模式 step by step 和 auto
- 也支持通过api写代码的方式进行操作， 无代码 和 代码
   - 每个会话都是隔离的
   - 集成Langchain ，LlamaHub， OpenAI Assistants API
   - LlamaHub是一个开源项目，提供了一系列数据连接器，这些连接器可以将来自各种源的原始数据转换为向量，以便大型语言模型（LLMs）如ChatGPT和Google Bard等更容易地访问和转换这些数据
- 盈利模式

![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706886794855-28596678-c113-4126-b4ae-1ea5fbd16ab3.png#averageHue=%23333333&clientId=uc5046217-dcf9-4&from=paste&height=763&id=u4e1ab751&originHeight=1526&originWidth=2584&originalType=binary&ratio=2&rotation=0&showTitle=false&size=546936&status=done&style=none&taskId=ua70b853e-08c8-432c-9a16-c6193245208&title=&width=1292)
# 20240202 LangChain Introduction
[https://js.langchain.com/docs/get_started/introduction](https://js.langchain.com/docs/get_started/introduction)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706869769957-58c45cd4-7136-449a-a664-4f976d5573c5.png#averageHue=%239bb4cd&clientId=u5f68a4b6-623a-4&from=paste&height=630&id=ua0133044&originHeight=1260&originWidth=1568&originalType=binary&ratio=2&rotation=0&showTitle=false&size=547096&status=done&style=none&taskId=u03625e9c-e3e2-4d41-9f32-34ca2433db6&title=&width=784)

- 定义：LangChina 是一个用于开发大模型应用的开发框架
- 提供两个能力：
   - 上下文感知
   - 推理
- 组成部分：
   - LangChain Libraries： 
      - 组件： 组件是模块化的
      - Off-the-shelf（现成的） chains
   - LangChain Templates: 各种不同任务的参考架构集合，目前只支持python
   - LangSmith: 一个运维平台
- LCEL：LangChain Expression Language
   - LCEL是构成链条的声明性方法。
   - LCEL从第1天开始设计，以支持将原型放在生产中，没有任何代码更改，从最简单的“提示 + LLM”链到最复杂的链条。
- modules： 标准的，可扩展的接口和集成
   - Model I/O
   - Retrieval: 应用特有的数据接口
   - Agents: 让模型选择使用的给定高级指令的工具



# 20240201 OpenAgents: An Open Platform for Language Agents in the Wild
[https://github.com/xlang-ai/OpenAgents](https://github.com/xlang-ai/OpenAgents)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706776082319-cd2bd575-bbfa-4f08-b7da-e13dedb3c31f.png#averageHue=%23ededec&clientId=uf0d4ec3a-9a3e-4&from=paste&height=696&id=u3e3f5718&originHeight=1391&originWidth=2596&originalType=binary&ratio=2&rotation=0&showTitle=false&size=765644&status=done&style=none&taskId=u2d762ba0-0b37-42bd-8ce3-f455ccb3ddb&title=&width=1298)

- 当前language agent frameworks的问题：
   - 只是proof-of-concept（概念验证）
   - 忽视非专业人士
   - 应用层的设计太少
- 目标是real-world language agents
- Web代理利用Chrome扩展程序的功能自动导航和探索网站。该代理简化了网络浏览体验，使查找相关信息，访问所需资源等变得更容易
- 缺点：打开新页面需要手动激活插件，这点无法自动化，看起来是否可以通过启动一个客户端来完成
- 原则：
   - 面对的是有形的具体的上下文
   - 自然语言的反馈
   - 工具支持增强
- “代理”是指直接或与工具与环境交互的系统或模型。通常，这是一个大型语言模型（LLM），提示采取行动或定制的中型模型。它遵循语言指令并通过预测用特定参数激活API函数的令牌来预测操作。
- 通常，LLM在语言理解和产生方面具有很强的能力，尤其是遵循指示，计划和推理，因此可以提示作为代理的政策网络，以执行一系列任务
- 本质上，Tool是Environment的组成部分，提供了一个快捷方式，该快捷方式封装了一系列操作以易于访问。例如，Serpapi是一种简化了在Google上搜索的用户过程的工具。
- In-context Human Feedback (内在的人类反馈)机制是X-lang最关键的特性，有两个好处：
   - 协助人物完成，因为用户是最了解人物的，需要用户的反馈
   - 更深的人物探索，用户的目标是随时会变化的
- 架构和技术
   - Agent
      - 基于LangChain中的ReAct
      - LangChain的不足之处
         - 工具还是不够用
         - 控制台输入已经不够用，需要更多的界面反馈
         - 相同的信息（例如，LLM上下文）通常需要根据情况不同而以不同方式表示
         - LangChain中当前提示设计的两个主要问题：一是过分依赖工具导致的代理响应不一致性，二是提示中包含的特定短语可能对用户界面的友好性和视觉吸引力产生负面影响。
   - Environment
      - 环境的实现在很大程度上依赖于目标代理的行动空间。
      - 实际上，代理通过使用不同的工具范围和组合来适应它们的场景
      - 浏览器扩展可以对网站进行自动探索和导航
   - In-context Human Feedback
      - 两个关键部分组成：
         - 前端交互界面：[https://github.com/mckaywrigley/chatbot-ui](https://github.com/mckaywrigley/chatbot-ui) Chatbot-ui基础上增加了一些新功能
         - 内存：当前端获得人类输入时，它将其作为LLM历史上下文的组成部分转移到代理的内存中
- 我们的系统根据个人用户需求智能自动选择最佳插件。
- 想象一个工具，可以通过随着时间的推移而提高的效率和准确性来复制人类互动。这是Web Agent的本质。
   - 一个稳定的框架，目前并没有开源
   - LLM不仅仅是沟通
   - 不仅仅是页面导航
- 工作流：
   - 聊天代理
   - 网页导航代理
- 愿景
   - Web Agent的变革潜力是无限的
   - 当我们拥抱未来时，网络代理不仅旨在成为助手，而且是对自己的数字扩展。数字领域将不再令人生畏。有了Web代理，一切都在障碍范围内。

![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706762493420-c3094bbd-d046-4492-b2d8-77cc012a6bbc.png#averageHue=%23f6f7f8&clientId=ucb69abe3-1759-4&from=paste&height=458&id=ua9e2fb6c&originHeight=916&originWidth=1539&originalType=binary&ratio=2&rotation=0&showTitle=false&size=202936&status=done&style=none&taskId=ua5878bcf-ff6a-4a44-acfc-a2f0f33b41b&title=&width=769.5)

# 20240201 Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception
[https://github.com/X-PLUG/MobileAgent](https://github.com/X-PLUG/MobileAgent)

- Introduction
   - 纯视觉，独立于XMl和系统元数据
   - 无限制的操作行为，跨多应用
   - 多种视觉感知工具用于操作本地
   - 不需要探索，训练，插入和播放
- 在感知非英语屏幕截图时，GPT-4V将会产生严重的幻觉
- Mobile-eval是一种旨在评估移动设备代理性能的基准。该基准包括10个主流单应用方案和1个多应用方案。
- Grounding DINO的信息，它是一个与目标检测相关的项目，使用PyTorch实现，并提供了预训练模型。该项目的重点包括与语言结合的目标检测、零标注训练、图像分割等。
- ![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706754829821-5065739e-ae66-4914-a29b-c80e5a102ab0.png#averageHue=%23a7b5c0&clientId=uc884cdce-41de-4&from=paste&height=512&id=u0aa05777&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=916566&status=done&style=none&taskId=u35e055bc-ed43-4345-bad5-99a32e3361c&title=&width=512)
- ![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706754848111-988a83e3-9762-4a64-8fd5-6191900a5516.png#averageHue=%23c87d42&clientId=uc884cdce-41de-4&from=paste&height=448&id=u5e9b9ca4&originHeight=896&originWidth=2953&originalType=binary&ratio=2&rotation=0&showTitle=false&size=881990&status=done&style=none&taskId=u302f65ea-9f2f-4903-a144-5a4511f495d&title=&width=1476.5)
