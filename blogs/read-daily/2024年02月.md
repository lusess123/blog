# 20240215 AgentBoard :一个多回合LLM Agent 的分析评估板-摘要和介绍
- 评估LLMs面临的挑战：
   - 在统一框架内跨多样化场景基准测试代理性能，比如 维持部分可观察环境和确保多轮交互方面
   - 当前的评估框架大多关注最终成功率，过程中揭示的洞察少，未能提供模型能力的深入理解
- 如何解决：
   - 细粒度的进度率指标
   - 捕捉逐步进展
   - 包含了一个综合评估工具包，该工具包通过交互式可视化轻松评估代理进行多方面分析
- 能够独立感知和在各种环境中行动的通用代理被认为是人工智能领域的重要里程碑
- 现有基准中常见是： 单轮任务和完全可观察环境中的“伪”任务
- agent task 的特点：
   - 多轮交互
   - 基于长文本的决策制定
   - 各种子任务目标
- AgentBoard包含9种独特任务和1013个示例环境
- 开源权重大模型代理与商业大模型代理的差距
   - GPT-4超越所有
   - 与环境进行多轮交互的能力
   - 开源权重LLM在基础建设、世界建模和自我反思方面显示出不同程度的缺陷

# 20240214 OpenAI Introduces MEMORY and New Controls for ChatGPT | Meet your new personalized AI assistant.
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707881075556-77111a1c-2f24-498f-9119-1ace6425e25e.png#averageHue=%23dbdbdb&clientId=u6f7ca4e1-5012-4&from=paste&height=900&id=u230f946d&originHeight=1800&originWidth=1800&originalType=binary&ratio=2&rotation=0&showTitle=false&size=225520&status=done&style=none&taskId=u8c506340-85ca-4bc1-812b-5999a921da8&title=&width=900)
[https://www.youtube.com/watch?v=I8C5gLRLAu8](https://www.youtube.com/watch?v=I8C5gLRLAu8)

- Chat GPT的记忆功能会随着你的使用而变得更好，你会逐渐注意到随着时间的推移会有所改善。
- 对于明确的信息指令，您可以将其添加到您的自定义指令中，所以这些记忆似乎是更加流动的持续性事物，您可以快速更改，这将自动被排
- 敏感的信息，比如你的健康细节，它不会记住除非你明确要求它
- gpts也将有记忆，所以那些自定义gpts如果用户正在构建gpts，它们将有自己独特的记忆，作为一个构建者，用户可以选择为gpts启用记忆，现在这些记忆将不会与构建者共享
# 20240214 Sam Altman SPEAKS at WGS 2024 | GPT-5 is "smarter", Deploying AGI, Open Source GPT. Are we ready?
[https://www.youtube.com/watch?v=JVatgo0TJIw](https://www.youtube.com/watch?v=JVatgo0TJIw)

- GTP5会更加聪明，使这些模型如此神奇的是它们的普适性，所以如果它稍微好一点，如果它稍微更聪明一点，那意味着它在所有方面都会好一点
- 不是这个模型在这个任务上会变得稍微好一点，而在其他任务上并没有真正进步，你知道，不是这样，而是因为我们将使模型变得更加智能，它将在各个方面都变得更好
- 需要有一个国际原子能机构那样的全球系统
- GPT2 已经开源了
- 悲观的事是，对那种非常微妙的社会错位更感兴趣
- 年轻人是非常幸运的，你们正在经历人类历史上可能是最好的时代，你们年轻人理解这项技术，年轻人几乎总是技术的早期采用者，几乎总是，但在这种情况下肯定是这样，你们将能够使用这些工具做一些前一代人甚至无法想象的事情，你们的整个职业生涯都将充满机会和做出惊人的新事物的能力，你们将能够创办比前一代人更有影响力和成功的公司，你们将生活在这个极具扩张性和机会的时代，充满了大量的机会，你们可以做任何你们想做的事情，我认为我们所有人的地面都在变化，规则正在改变，但将创造的价值和个人创造力和意志的能力将是巨大的
# 20240213 我们10多年的外语教学的方法几乎全错了
[https://www.youtube.com/watch?v=TlP4iwFum2g](https://www.youtube.com/watch?v=TlP4iwFum2g)

- 英语知识是一种隐形知识（运动类知识）
- 听英语不要看字幕
- 单词是靠学习而不是记忆
- 两项原则：
   - 明确任务的输入输出
   - 用例子重塑大脑连接
- 注意要点：
   - 不要依靠意识
   - 以句子为单位
   - 多例子学习
   - 输出要一致

# 20240213 learning human actions on computer applications
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707812883122-1d110518-70ed-4650-b19e-d5ba251a5877.png#averageHue=%237c7f82&clientId=u1cf141c2-62bb-4&from=paste&height=612&id=u4036cb94&originHeight=1224&originWidth=2042&originalType=binary&ratio=2&rotation=0&showTitle=false&size=514402&status=done&style=none&taskId=u46c1ff42-6720-4ace-8050-4dd674d5734&title=&width=1021)
[https://www.rabbit.tech/research](https://www.rabbit.tech/research)

- 我们开发了一个系统，可以推断和模拟计算机应用程序上的人类行为，可靠且快速地执行这些操作，并且非常适合部署在各种人工智能助手和操作系统中。我们的系统称为大型行为模型（LAM）。借助最近在神经符号编程方面的进展，LAM 允许直接对各种应用程序及其上执行的用户操作的结构进行建模，而无需像文本等过渡性表示
- 通过移动应用程序提供的个性化体验的普及已成为个人计算的上一个十年的主题，这些应用程序由图形用户界面启用，允许用户进行交互而无需任何编程经验。
- 一种新型的用户交互体验出现了，其中设备的主要用户界面是通过口语自然语言而不是触摸实现的
- 主要服务提供商的应用程序编程接口（API）不可用是最大的挑战。采用了神经符号编程来直接学习用户与应用程序的交互，从而避免了翻译自然语言用户请求为严格的API的需求
- 我们的关键观察是，人机交互的固有结构与自然语言或视觉不同。这些应用程序以一种比栅格图像更结构化的形式表达，比句子或段落更冗长且嘈杂
- 虽然我们可能希望智能聊天机器人具有创造性，但 LAM 对应用程序的学习动作应该是高度规则化、极简主义、稳定且可解释的
- 虽然神经语言模型已经表现出理解和利用应用程序编程接口的能力，但用户界面与文本之间存在基本差异，因此不太适合
- 使用测试时间自适应提示模板、指令驱动或基于强化学习的微调来进行某种形式的推理。在这种情况下，语言模型需要作为端到端推理器，但它们仍然难以胜任这项任务。额外的缺点包括：丢失应用程序中重要的结构信息、标记化序列或像素数组通常过长且嘈杂，以及引入自然语言中描述的操作的模糊性
- 通常，需要为特定问题设计一个专门的形式规范，而用于解决一个问题的启发式方法往往无法很好地适用于其他问题。RPA的挑战在于泛化的困难
- 为了协助新模型的开发，我们从零开始设计了技术堆栈，从数据收集平台到一个新的网络架构，该架构利用了变压器式的注意力和基于图的消息传递，结合了以示范和示例为导向的程序合成器 
- LAM的建模方法根植于模仿，或者称之为学习演示。它观察人类使用界面，并旨在可靠地复制这个过程，即使界面被以不同方式或稍微改变的方式呈现
- 随着时间的推移，LAM从演示中积累知识，深入理解了应用程序所暴露的接口的每个方面，并创建了应用程序提供的底层服务的概念蓝图。LAM可以被视为一座桥梁，通过应用程序的界面将用户连接到这些服务
- 通过在循环中利用神经符号技术，LAM处于语言建模（LM）、编程语言（PL）和形式方法（FM）跨学科科学研究的最前沿
- 今为止，还没有人将尖端的神经符号技术投入到生产中 — LAM旨在开创这一方向
- 智能放在终端用户手中是可行的，而无需沉重的客户端计算能力。
- 神经符号 LAM 在云端运行，但与之交互的硬件设备并不需要昂贵而庞大的处理器，非常环保，并且能耗极低
-  scaling law在神经系统研究的所有方面都持续存在，从过去十年的视觉 [4] 到现在的自然语言
- 理解行为将进一步帮助重新设计人机交互，并可以产生更直观和有用的自然语言驱动的系统和设备，从服务提供商、消费者和硬件制造商到软件开发人员，使所有利益相关者受益
- the future of human-machine interface
# 20240211 2024 is the Year of the AI AGENT
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707636754436-a13e5c95-b707-47f1-a05d-e60b5b579248.png#averageHue=%23a18451&clientId=u87a33967-2f24-4&from=paste&height=874&id=u67e097f6&originHeight=1748&originWidth=1346&originalType=binary&ratio=2&rotation=0&showTitle=false&size=2481337&status=done&style=none&taskId=ude924c63-431d-463d-91d5-94b65d67bd4&title=&width=673)
[https://www.youtube.com/watch?v=hmt5MnStKUI&t=379s](https://www.youtube.com/watch?v=hmt5MnStKUI&t=379s)

- Agentboard ：强调对大型语言模型（LLMs）进行分析评估，作为通用代理程序在各种环境中感知和行动的能力。[https://hkust-nlp.github.io/agentboard/](https://hkust-nlp.github.io/agentboard/)
- Voyager：具有大语言模型的开放式具身代理；"具身代理"是指一个智能代理系统，它不仅仅是一个虚拟存在或者算法，而是在物理世界中具有一定形态或身体，可以与环境进行交互、感知和行动 [https://voyager.minedojo.org/](https://voyager.minedojo.org/)
- adept ：使用计算机的新方法，建立一个机器学习模型，该模型可以与计算机上的所有内容进行交互。[https://www.adept.ai/](https://www.adept.ai/)
- Rabbit： 学习人类在计算机应用上面行动 [https://www.rabbit.tech/research](https://www.rabbit.tech/research)
- 与RPA的区别：
   - RPA，基本上是你在录制屏幕，然后部署一个算法，一个预先编程的序列，来导航你的鼠标，你的光标到XY位置，基于绝对的坐标
   - 神经符号算法更进一步，因为我们不是通过屏幕的绝对坐标来识别所有这些元素，我们从符号方法中直接提取和自动标记一些元素，并对这些元素进行推理，这意味着，如果一个应用程序完全改变了界面，也不会有关系
- **根本的哲学逻辑是，所有这些现代软件都是为了人眼来处理信息设计的，**它们必须在某个地方有一个设置
- 当前计算机技术的变革，从以前简单地执行我们指示的动作，变为像人类一样理解符号并与网站进行交互的神经符号处理
- 通过人类示范的方式进行训练
- 在语言模型的基于文本的游戏中的欺骗与合作 [https://arxiv.org/abs/2308.01404](https://arxiv.org/abs/2308.01404)
# 20240210 The next grand challenge for AI
[https://www.ted.com/talks/jim_fan_the_next_grand_challenge_for_ai/transcript?subtitle=en](https://www.ted.com/talks/jim_fan_the_next_grand_challenge_for_ai/transcript?subtitle=en)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707532853545-28fecd45-3e5a-4d91-830c-11a1293e6696.png#averageHue=%233f413d&clientId=ue97aebf6-6ec3-4&from=paste&height=409&id=uc743a1c0&originHeight=818&originWidth=1468&originalType=binary&ratio=2&rotation=0&showTitle=false&size=112788&status=done&style=none&taskId=uf17d7219-195c-426a-acd6-f21b5a95dfc&title=&width=734)

- Alphago只能单独做一件事
- Voyager是一个agent，在许多技能方面都大大扩展。
- Minecraft的玩家是英国人口的两倍
- Voyager的核心思想是coding as action
- self-reflection的feedback有三个来源：
   - JavaScript代码执行错误；
   - agent的状态，例如健康和饥饿；
   - world的状态，例如附近的地形和敌人
- 我们只给Voyager一个高级指令，那就是尽可能获取尽可能多的独特物品
- 我们没有提前编程任何这样的内容。这都是Voyager的想法。这，你在这里看到的，是我们所说的终身学习。当一个代理永远好奇，永远在追求新的冒险。与AlphaGo相比，Voyager在他能做的许多事情上都大规模扩展，但仍然只控制Minecraft中的一个身体。
- 我们能有一个适用于许多不同身体的算法吗？让我们来看看MetaMorph。这是我在斯坦福共同开发的一个项目。我们创建了一个基础模型，它不仅可以控制一个，而且可以控制成千上万个具有非常不同的手臂和腿部配置的机器人。Metamorph能够处理来自不同机器人身体的极其多样化的运动特性。
- IsaacSim的最大优势是将物理模拟加速到比实时快1,000倍。
- 这是一个有趣的主意。如果agent能够掌握10,000个模拟，那么它很可能只是概括为我们的真实世界，这只是第10,001个现实
- 我相信训练Foundation Agent将与Chatgpt非常相似。所有语言任务都可以表示为文本和文本。
- 有一天，我们将意识到，无论是在物理还是虚拟空间中，所有的AI代理，都在Wall-E，星球大战，头号玩家 上，与同一Foundation Agent都有不同的 提示词 。我的朋友们，这将是我们寻求AI的下一个大挑战。
# 20240208 NLP Course  7 ：MAIN NLP TASKS (上)
[https://huggingface.co/learn/nlp-course/chapter7/1?fw=pt](https://huggingface.co/learn/nlp-course/chapter7/1?fw=pt)

- 本章基本上是重复前面的东西，让你对整个任务有更深入的了解
- Token classification
   - 将标签归因于句子中的每个token
      - Named entity recognition (NER)
      - Part-of-speech tagging (POS)
      - Chunking
   - 数据预处理其实是最艰难的部分
   -  使用Trainer API对模型进行Fine-tuning
      - 数据批处理
      - 度量函数
- Fine-tuning a masked language model
   - 用于预读的语料库与用于微调的语料库没有太大不同，转移学习通常会产生良好的结果。
   - 对内域数据进行验证的语言模型进行微调的过程通常称为domain adaptation（域适应性）
# 20240208 The Rust Programming Language-Introduction
[https://doc.rust-lang.org/book/ch00-00-introduction.html](https://doc.rust-lang.org/book/ch00-00-introduction.html)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707395513215-134428ea-45e2-4cca-a502-a45a2ea09a36.png#averageHue=%23722218&clientId=ud5efa388-364e-4&from=paste&height=424&id=u196dd236&originHeight=847&originWidth=1259&originalType=binary&ratio=2&rotation=0&showTitle=false&size=100504&status=done&style=none&taskId=u8c3a4045-d91f-4eb0-bba3-85b4bad7ddc&title=&width=629.5)

- Rust可帮助您更快，更可靠的软件编写。在编程语言设计中，High-level ergonomics（人体工程学） 和 low-level control通常会矛盾；Rust试图解决这个冲突。
- Rust适合谁
   - 开发团队
      - 编译器
      - 工具链
   - 学生
      - 系统编程的概念
   - 公司
      - 生态
   - 开源代码开发者
   - 重视速度和稳定的人
      - zero-cost abstractions（零成本抽象）
- 本书目录
   - Chapter 1 Helloworld
   - Chapter 2 一个demo, 测试数字的游戏
   - Chapter 3 涵盖了与其他编程语言相似的RUST功能
   - Chapter 4 ownership system
   - Chapter 5  structs and method
   - Chapter 6  enums, match expressions
   - Chapter 7 模块化系统
   - Chapter 8   some common collection data structures 
   - Chapter 9 error-handling
   - Chapter 10  generics, traits, and lifetimes
   -  Chapter 11 testing
   - Chapter 12 一个命令行工具的例子
   - Chapter 13 用于函数式编程的 closures（闭包） and iterators（迭代器）
   - Chapter 14 深入Cargo
   - Chapter 15 智能指针
   - Chapter 16 并发编程
   - Chapter 17 对比传统的面向对象编程
   - Chapter 18 模型匹配
   - Chapter 19 一些先进的主题
   - Chapter 20 开发一个web服务器
# 20240207《Elon Musk》34 Falcon 9 Lifto Cape Canaveral, 2010
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707314532115-d16bc6e1-1446-4eba-8f4b-3e3b8eda5c66.png#averageHue=%237d7d7d&clientId=u883a8359-d556-4&from=paste&height=452&id=u9477663f&originHeight=904&originWidth=1332&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1053587&status=done&style=none&taskId=ueb21b0ba-36d0-43e0-a4a4-3c31eafd277&title=&width=666)

- 进入轨道
   - 对Elon的重要意义是，如果您告诉他风险并向他展示了工程数据，他将进行快速评估，并让责任从您的肩膀转移到他的肩膀上。
- ... and return
   - SpaceX不仅可以将无人胶囊推入轨道，而且还可以安全地将其返回地球。没有私人公司这样做。实际上，只有三个政府拥有：美国，俄罗斯和中国。
   - 在Musk或奥巴马出生之前，水星计划已经完成了类似的壮举
# 20240206 LangChain:  Why use LCEL ？
[https://python.langchain.com/docs/expression_language/get_started#entire-pipeline](https://python.langchain.com/docs/expression_language/get_started#entire-pipeline)

- 什么是LCEL？
   - LangChain Express Language
   - LCEL使从基本组件构建复杂的链条变得容易，并支持out of the box的功能，例如流媒体，并行性和日志记录。
   - 例子： chain = prompt | model | output_parser
   - Python代码使用了管道操作符(**|**)，这在标准Python语法中并不直接存在。这种用法可能来自特定的库或框架，它们通过重载对象的**__or__**方法来实现自定义的管道操作。这种做法在某些数据处理和流式处理库中很常见，比如Pandas的某些扩展、Dask或类似的可以链式调用的库，用以简化代码并提高可读性。 是一种内部DSL
- why?
   - 通用的接口：每个 LCEL 对象都支持invoke, batch, stream, ainvoke, …
   - 原子组合
- ![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707221553404-5c79d55e-b2ad-4ffa-bf15-a4b997915290.png#averageHue=%23606355&clientId=u15361ee1-1e74-4&from=paste&height=512&id=ud25664e0&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1825108&status=done&style=none&taskId=u5499bc7b-54da-4dbb-851a-376152be307&title=&width=512)

# 20240204  NLP Course  6 ： THE 🤗 TOKENIZERS LIBRARY (下)
[https://huggingface.co/learn/nlp-course/chapter6/3b?fw=pt](https://huggingface.co/learn/nlp-course/chapter6/3b?fw=pt)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707117984912-3c08ac8e-5218-4c8f-865c-e7f4b9839fc3.png#averageHue=%23fdf8ef&clientId=u2f759465-0fc4-4&from=paste&height=158&id=ucc9df4b1&originHeight=316&originWidth=1735&originalType=binary&ratio=2&rotation=0&showTitle=false&size=42034&status=done&style=none&taskId=ua4c0938f-2ea3-4337-b574-bd1eccec057&title=&width=867.5)

- Fast tokenizers in the QA pipeline
   - QA pipeline需要处理和返回长文本
   - return_overflowing_tokens=True允许分词器(tokenizer)返回所有因超出最大长度(max_length)而溢出的tokens，这些溢出的tokens被组织成多个块。通过设定stride值，我们可以控制这些块之间的重叠部分，确保上下文的连贯性和完整性，从而在不丢失重要信息的前提下，有效处理长上下文。
- Normalization and pre-tokenization
   - SentencePiece算法是 reversible tokenization（可逆令牌），BERT tokenizer 是不可逆的
   - 三个主要的subword tokenization算法：
      - BPE (used by GPT-2 and others), 
      - WordPiece (used for example by BERT)
      - Unigram (used by T5 and others)
- Byte-Pair Encoding tokenization
   - OpenAI使用的，用在Transformer模型
   - 将单词拆分成字符，然后从两个字符开始合并
- WordPiece tokenization
   - google 开发的，跟BPE非常相似
   - google并没有开源其实现，所以这些实现都是猜测的
   - 给定一个单词，算法从最长可能的片段（在词汇表中）开始匹配，然后逐步减小片段长度，直到找到匹配的tokens。
- Unigram tokenization
   - 应用在 SentencePiece
   - 基本思想是从一个大的候选词汇集合出发，通过优化概率模型来逐步减少词汇集合的大小，最终得到一个高效的分词结果
   - Unigram算法能够自适应不同语言和领域的文本，因为它基于数据的统计特性来建立词汇表。
- Building a tokenizer, block by block
   - tokenization的四个步骤
      - **标准化(Normalization)**：可能包括去除空格、标点符号、文本中的特殊字符，进行Unicode标准化，以及删除或转换口语词汇和缩写等。这有助于减少文本中的变异性，确保相似的文本片段在处理时被视为相同。
      - **预分词(Pre-tokenization)**：通常是词(words)或子词(subwords)
      - **通过模型处理(Running the input through the model)**：根据所使用的分词算法（如BPE、WordPiece或Unigram），预分词单元可能会被进一步分解成更小的单元或被转换成模型的词汇表中的索引。
      - **后处理(Post-processing)**：、生成注意力掩码(attention masks)和token类型IDs(token type IDs)。特殊tokens用于模型理解句子的结构，如区分两个句子或表示句子的开始和结束


# 20240204  NLP Course  6 ： THE 🤗 TOKENIZERS LIBRARY (上)
[https://huggingface.co/learn/nlp-course/chapter6/1?fw=pt](https://huggingface.co/learn/nlp-course/chapter6/1?fw=pt)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707055180554-33ccfd5b-0db8-4e96-838a-6ca932ca8343.png#averageHue=%23fdfaf5&clientId=u7e71d0d0-0cbb-4&from=paste&height=193&id=u31289722&originHeight=385&originWidth=1735&originalType=binary&ratio=2&rotation=0&showTitle=false&size=39974&status=done&style=none&taskId=uf59c2a3b-0230-4bd4-a897-873f6f6ba4d&title=&width=867.5)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707055315192-8cc8cf94-dbb2-4922-9898-0f385754d275.png#averageHue=%23fcf8ed&clientId=u7e71d0d0-0cbb-4&from=paste&height=512&id=u85c3ee33&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1486364&status=done&style=none&taskId=ue3544c4c-3ac7-40a3-99b7-955ad25ccf2&title=&width=512)

- 一个在英文语料库上训练的Tokenizer在日文文本的语料库上表现会很差，因为两种语言中空格和标点符号的使用非常不同
- Training a new tokenizer from an old one
   - 大多数Transformer模型使用subword(子词)分词算法
   - 为了识别哪些subwords(子词)是有趣的并且在手头的语料库中最常出现，tokenizer需要仔细查看语料库中的所有文本 —— 这个过程我们称之为training。
   - 训练一个tokenizer(分词器)与训练一个模型不同！模型训练使用stochastic gradient descent(SGD)(随机梯度下降)使每个批次的loss(损失)稍微减小。它本质上是随机的（意味着你必须设置一些seed(种子)以在进行相同训练两次时获得相同的结果）。
   - 训练一个tokenizer(分词器)是一个统计过程，试图识别哪些subword(子词)是给定语料库中最佳选择，而用于选择它们的确切规则取决于tokenization algorithm(分词算法)。它是deterministic(确定性的)，意味着在相同的语料库上使用相同的算法训练时，你总是获得相同的结果。
   - 使用python的Generator Expression（生成器表达式）而不是List Comprehension（列表推导式）用于节约内存
   - 快速分词器由🤖 Tokenizers 库支持，后者是用 Rust 编程语言编写的。
   - 模型计算核心的矩阵乘法是使用 CUDA 编写的，这是一种针对 GPU 优化的 C 库。
- Fast tokenizers’ special powers
   - Fast tokenizer 的快速除了并行之外还有 “跟踪来自偏移列表每个令牌的文本跨度”
   -  fast tokenizer 需要进行 post-processing，主要是增加了上下文信息（比如偏移量），并且用rust实现包装性能和效率
# 20240202 Announcing Multion：与AI Agents 为人类建立更美好的未来
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706885972970-f8fb0f60-093a-4aa1-982c-c2ca23008da8.png#averageHue=%238c9e8f&clientId=ue927c512-cbf0-4&from=paste&height=334&id=u3e91d129&originHeight=667&originWidth=1000&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1139109&status=done&style=none&taskId=u92dee6d2-fecb-4c49-99bb-c23a8e0bdf5&title=&width=500)
[https://www.multion.ai/blog/multion-building-a-brighter-future-for-humanity-with-ai-agents](https://www.multion.ai/blog/multion-building-a-brighter-future-for-humanity-with-ai-agents)

- Multion是一家旨在开发AI产品和技术的开拓性AI初创公司，旨在开发AI产品和技术
- Multion是AI代理，它采取行动并与数字世界进行互动，以解决人们宁愿将其委派给助手的平凡任务
- MultiOn的创意来自斯坦福大学的2个人 Div Garg 和 Omar Shaya
   - Div同时有三份工作，在斯坦福教课，机器人初创公司，副业。他想从无聊平凡的工作中解放出来，去做一些有创意和有意义的工作
   - Omar，一个追求技术和创业目标的环球旅行者，一直认为技术可以做更多的事情来帮助他在新的地方定居，就像朋友和家人在家乡所能提供的一样
- Div在斯坦福，他的研究聚焦于大型语言模型和强化学习，将它们应用于如能在视频游戏比赛中赢得顶级奖项的AI代理、可以通过语言控制的机器人、以及获得广泛媒体报道的最先进自动驾驶系统等项目
- Omar拥有丰富的计算机科学和消费产品经验，曾在微软和Meta领导开发消费者AI产品的团队。奥马尔对社交媒体平台的算法优化和微软的AI助手开发的深刻理解，为他创立MultiOn和制定其独特产品愿景提供了坚实的基础。
- Multion的愿景不是替代人类的机器，而是增加人类
- 最早的demo取得了很大的成功
- 亚马逊Alexa Fund的董事保罗·伯纳德（Paul Bernard）说：“跨越正在重新定义AI时代的最前沿。Multion的AI代理具有与Internet上几乎任何设备或接口连接的能力，令人印象深刻。”
# 20240202 MultiOn AI
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706882599310-2e192e90-347f-48c7-9b74-775291fda917.png#averageHue=%23fcfbfb&clientId=u51acee71-69a5-4&from=paste&height=329&id=u1a602f60&originHeight=658&originWidth=1834&originalType=binary&ratio=2&rotation=0&showTitle=false&size=141056&status=done&style=none&taskId=u940c53c0-0602-4928-b421-91bac78d278&title=&width=917)
[https://docs.multion.ai/](https://docs.multion.ai/)

- Multion是下一代Web AI代理，可以代表您在Internet上采取行动
- 通过浏览器插件，可以完全自动化
- 支持两种模式 step by step 和 auto
- 也支持通过api写代码的方式进行操作， 无代码 和 代码
   - 每个会话都是隔离的
   - 集成Langchain ，LlamaHub， OpenAI Assistants API
   - LlamaHub是一个开源项目，提供了一系列数据连接器，这些连接器可以将来自各种源的原始数据转换为向量，以便大型语言模型（LLMs）如ChatGPT和Google Bard等更容易地访问和转换这些数据
- 盈利模式

![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706886794855-28596678-c113-4126-b4ae-1ea5fbd16ab3.png#averageHue=%23333333&clientId=uc5046217-dcf9-4&from=paste&height=763&id=u4e1ab751&originHeight=1526&originWidth=2584&originalType=binary&ratio=2&rotation=0&showTitle=false&size=546936&status=done&style=none&taskId=ua70b853e-08c8-432c-9a16-c6193245208&title=&width=1292)
# 20240202 LangChain Introduction
[https://js.langchain.com/docs/get_started/introduction](https://js.langchain.com/docs/get_started/introduction)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706869769957-58c45cd4-7136-449a-a664-4f976d5573c5.png#averageHue=%239bb4cd&clientId=u5f68a4b6-623a-4&from=paste&height=630&id=ua0133044&originHeight=1260&originWidth=1568&originalType=binary&ratio=2&rotation=0&showTitle=false&size=547096&status=done&style=none&taskId=u03625e9c-e3e2-4d41-9f32-34ca2433db6&title=&width=784)

- 定义：LangChina 是一个用于开发大模型应用的开发框架
- 提供两个能力：
   - 上下文感知
   - 推理
- 组成部分：
   - LangChain Libraries： 
      - 组件： 组件是模块化的
      - Off-the-shelf（现成的） chains
   - LangChain Templates: 各种不同任务的参考架构集合，目前只支持python
   - LangSmith: 一个运维平台
- LCEL：LangChain Expression Language
   - LCEL是构成链条的声明性方法。
   - LCEL从第1天开始设计，以支持将原型放在生产中，没有任何代码更改，从最简单的“提示 + LLM”链到最复杂的链条。
- modules： 标准的，可扩展的接口和集成
   - Model I/O
   - Retrieval: 应用特有的数据接口
   - Agents: 让模型选择使用的给定高级指令的工具



# 20240201 OpenAgents: An Open Platform for Language Agents in the Wild
[https://github.com/xlang-ai/OpenAgents](https://github.com/xlang-ai/OpenAgents)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706776082319-cd2bd575-bbfa-4f08-b7da-e13dedb3c31f.png#averageHue=%23ededec&clientId=uf0d4ec3a-9a3e-4&from=paste&height=696&id=u3e3f5718&originHeight=1391&originWidth=2596&originalType=binary&ratio=2&rotation=0&showTitle=false&size=765644&status=done&style=none&taskId=u2d762ba0-0b37-42bd-8ce3-f455ccb3ddb&title=&width=1298)

- 当前language agent frameworks的问题：
   - 只是proof-of-concept（概念验证）
   - 忽视非专业人士
   - 应用层的设计太少
- 目标是real-world language agents
- Web代理利用Chrome扩展程序的功能自动导航和探索网站。该代理简化了网络浏览体验，使查找相关信息，访问所需资源等变得更容易
- 缺点：打开新页面需要手动激活插件，这点无法自动化，看起来是否可以通过启动一个客户端来完成
- 原则：
   - 面对的是有形的具体的上下文
   - 自然语言的反馈
   - 工具支持增强
- “代理”是指直接或与工具与环境交互的系统或模型。通常，这是一个大型语言模型（LLM），提示采取行动或定制的中型模型。它遵循语言指令并通过预测用特定参数激活API函数的令牌来预测操作。
- 通常，LLM在语言理解和产生方面具有很强的能力，尤其是遵循指示，计划和推理，因此可以提示作为代理的政策网络，以执行一系列任务
- 本质上，Tool是Environment的组成部分，提供了一个快捷方式，该快捷方式封装了一系列操作以易于访问。例如，Serpapi是一种简化了在Google上搜索的用户过程的工具。
- In-context Human Feedback (内在的人类反馈)机制是X-lang最关键的特性，有两个好处：
   - 协助人物完成，因为用户是最了解人物的，需要用户的反馈
   - 更深的人物探索，用户的目标是随时会变化的
- 架构和技术
   - Agent
      - 基于LangChain中的ReAct
      - LangChain的不足之处
         - 工具还是不够用
         - 控制台输入已经不够用，需要更多的界面反馈
         - 相同的信息（例如，LLM上下文）通常需要根据情况不同而以不同方式表示
         - LangChain中当前提示设计的两个主要问题：一是过分依赖工具导致的代理响应不一致性，二是提示中包含的特定短语可能对用户界面的友好性和视觉吸引力产生负面影响。
   - Environment
      - 环境的实现在很大程度上依赖于目标代理的行动空间。
      - 实际上，代理通过使用不同的工具范围和组合来适应它们的场景
      - 浏览器扩展可以对网站进行自动探索和导航
   - In-context Human Feedback
      - 两个关键部分组成：
         - 前端交互界面：[https://github.com/mckaywrigley/chatbot-ui](https://github.com/mckaywrigley/chatbot-ui) Chatbot-ui基础上增加了一些新功能
         - 内存：当前端获得人类输入时，它将其作为LLM历史上下文的组成部分转移到代理的内存中
- 我们的系统根据个人用户需求智能自动选择最佳插件。
- 想象一个工具，可以通过随着时间的推移而提高的效率和准确性来复制人类互动。这是Web Agent的本质。
   - 一个稳定的框架，目前并没有开源
   - LLM不仅仅是沟通
   - 不仅仅是页面导航
- 工作流：
   - 聊天代理
   - 网页导航代理
- 愿景
   - Web Agent的变革潜力是无限的
   - 当我们拥抱未来时，网络代理不仅旨在成为助手，而且是对自己的数字扩展。数字领域将不再令人生畏。有了Web代理，一切都在障碍范围内。

![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706762493420-c3094bbd-d046-4492-b2d8-77cc012a6bbc.png#averageHue=%23f6f7f8&clientId=ucb69abe3-1759-4&from=paste&height=458&id=ua9e2fb6c&originHeight=916&originWidth=1539&originalType=binary&ratio=2&rotation=0&showTitle=false&size=202936&status=done&style=none&taskId=ua5878bcf-ff6a-4a44-acfc-a2f0f33b41b&title=&width=769.5)

# 20240201 Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception
[https://github.com/X-PLUG/MobileAgent](https://github.com/X-PLUG/MobileAgent)

- Introduction
   - 纯视觉，独立于XMl和系统元数据
   - 无限制的操作行为，跨多应用
   - 多种视觉感知工具用于操作本地
   - 不需要探索，训练，插入和播放
- 在感知非英语屏幕截图时，GPT-4V将会产生严重的幻觉
- Mobile-eval是一种旨在评估移动设备代理性能的基准。该基准包括10个主流单应用方案和1个多应用方案。
- Grounding DINO的信息，它是一个与目标检测相关的项目，使用PyTorch实现，并提供了预训练模型。该项目的重点包括与语言结合的目标检测、零标注训练、图像分割等。
- ![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706754829821-5065739e-ae66-4914-a29b-c80e5a102ab0.png#averageHue=%23a7b5c0&clientId=uc884cdce-41de-4&from=paste&height=512&id=u0aa05777&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=916566&status=done&style=none&taskId=u35e055bc-ed43-4345-bad5-99a32e3361c&title=&width=512)
- ![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706754848111-988a83e3-9762-4a64-8fd5-6191900a5516.png#averageHue=%23c87d42&clientId=uc884cdce-41de-4&from=paste&height=448&id=u5e9b9ca4&originHeight=896&originWidth=2953&originalType=binary&ratio=2&rotation=0&showTitle=false&size=881990&status=done&style=none&taskId=u302f65ea-9f2f-4903-a144-5a4511f495d&title=&width=1476.5)
