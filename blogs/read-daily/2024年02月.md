# 20240226 Open Source AI produces STUNNING Images | NSFW, Stable Diffusion 3, DashToon, Magnific & more.
[https://www.youtube.com/watch?v=z5eXvAcARZQ&t=19s](https://www.youtube.com/watch?v=z5eXvAcARZQ&t=19s)

- 如果你需要生成图像并完全控制什么是允许的，什么是不允许的，现在Stable Diffusion可能是正确的选择
- [https://magnific.ai](https://magnific.ai/)
- [https://dashtoon.com](https://dashtoon.com/)
# 20240226 《Life of PI》Toronto and Pondicherry 2，3

1. 这是我独自一人，出于一种负罪感的愉悦，返回大海的故事，被那些猛烈的波涛吸引，它们崩溃下来并以谦卑的潮汐涟漪伸手向我，温柔的套索捕捉着那愿意被捕的印第安男孩。
# 20240225 《Life of PI》Toronto and Pondicherry 1
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1708861861397-64b0a128-88df-4067-82ef-3237b0594b63.png#averageHue=%237d7f7c&clientId=ufa619829-998e-4&from=paste&height=512&id=uf6895640&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1811798&status=done&style=none&taskId=u130ca344-0275-4ea9-ad33-33a1e9e4ca7&title=&width=512)

1. 睡觉或进食时开枪旁边的树懒几乎没有反应
2. 三趾树懒在与环境的完美和谐中过着和平的素食生活。"一种友好的微笑永远挂在它的嘴唇上
3. 生命是如此美丽，以至于死亡对它产生了爱慕之情，一种嫉妒而占有欲强的爱，抓住它所能抓住的。
4. 这些梦大多是噩梦，但都带着爱的色彩。这就是人心的奇怪之处。我仍然无法理解他怎么能如此随意地抛弃我，没有任何告别，甚至连回头看一眼都没有。
# 20240225 Gates, Altman and Bezos SHOCK the Entire Industry! Figure AI, Reddit IPO, Tyler Perry Shocked and T2
[https://www.youtube.com/watch?v=sSKxxVtAANQ&t=15s](https://www.youtube.com/watch?v=sSKxxVtAANQ&t=15s)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1708826097183-712266cd-6e9f-4dcd-a13b-8e13c2fad4cc.png#averageHue=%23e8edeb&clientId=u2d5273f0-7662-4&from=paste&height=512&id=u53f34447&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=933895&status=done&style=none&taskId=u26cac6bb-f158-4438-9ac5-a2feeaeea65&title=&width=512)

- 一位领先的AI研究员说，“每一台移动的机器都将是自主的
- Figure AI  [https://www.figure.ai/](https://www.figure.ai/) 目前最领先的人形机器人创业公司
- 人类的手指可以感觉到小至13纳米的物体，这意味着如果你的手指有地球那么大，你甚至能感觉到房屋和汽车之间的差别，这样想起来有点令人震惊，但这正好说明了要开发出能够模拟人类能力的传感器和机器人手指需要投入什么样的技术
- 《好奇心驱动的联合移动和操纵任务学习》
- ADHD 是“注意力缺陷/多动障碍”（Attention Deficit Hyperactivity Disorder）的缩写
- Nvidia有很多这方面的工具，像Isaac Sim等等。它们模拟环境，并允许以比现实世界快上千倍的速度运行，使我们能够更快地训练这些机器人，而无需磨损和损坏
- 让GPT4编写复杂的奖励函数
- 三年前我们认为那些敏捷并具有一定通用智能的机器人还遥遥无期。现在人们开始意识到，也许情况并非如此，也许它们就在拐角处，我们应该购买拥有创造这些东西的人才和能力
- 杨立坤将AI的出现比作印刷机的发明，印刷机曾让许多人感到恐惧，包括天主教会和奥斯曼帝国。奥斯曼帝国选择禁止印刷机，这保护了如书法艺术家这样的工作，但可能也导致了帝国的衰落
# 20240224 "EVERY machine that moves will be AUTONOMOUS" OpenAI Robot, Google's Fiasco and NVIDIA's GEAR!
[https://www.youtube.com/watch?v=I0qO_xIxsi0](https://www.youtube.com/watch?v=I0qO_xIxsi0)

- 2024年将是机器人的年份，游戏AI的年份，以及仿真的年份
- "dystopian AF" 可以翻译为“极端反乌托邦”。"AF" 是 "as fuck" 的缩写
- Google的Gemini项目如何试图通过注入特殊指令来增加输出图片的种族多样性
- “Eureka”被命名为2023年英伟达十大研究项目之一,他们教会了一个模拟中的机器人用手指转动笔
- 英伟达拥有足够的资本一次性解决机器人基础模型、游戏基础模型和一般模拟的问题
- Eureka在所有任务中的表现超过了人类，特别是在高维灵巧环境中实现了更大的进步，这意味着当人类在完成非常复杂的任务，编写这些复杂任务的奖励函数变得更糟时，Eureka却能够很好地完成这些任务
- Isaac Gym是一个由GPU加速的物理模拟器，模拟了我们的物理环境，所有的摩擦力、重力和其他因素，如动量，以模拟我们的现实，但它能以一千倍的速度运行
- Jim博士在这里说，令你惊讶的是，任务越困难，Eureka的奖励与人类奖励的相关性越小。在一些案例中，Eureka的奖励甚至与人类的奖励负相关，同时提供了显著更好的控制器。这意味着，随着任务变得越来越困难，Eureka不仅比人类做得更好，它还提出了全新的、创新的、完全不同的解决任务或编写奖励函数的方法。所以当人们说，“哦，ChatGPT只是重复它所学到的，没有创造任何新东西
- 人工智能将训练下一代的人工智能和机器人。这是Ted Chow所说的，他表示在接下来的几周内将会有三到四个重大的新闻发布，这将震撼机器人和人工智能领域。
- Moravec's Paradox”（莫拉维克悖论）:在人工智能（AI）领域，让计算机执行一些高级认知任务相对容易，如棋类游戏的对弈或者在智力测试上表现出成人水平的表现。但是，让计算机执行一些对人类或者动物来说非常简单的感知和运动任务却非常困难。
- Moravec's Paradox可能是错误的，我们只是没有数据
- “根节点问题”（root node problems）这个术语在上下文中被用来形象地描述那些在科学或技术领域中核心且基础的问题， 比如核聚变， 室温超导体
- 通用人工智能（AGI）解决了一系列根本性的科学问题后，我们社会的经济结构和价值体系可能会经历根本性的变化。
# 20240224 《Life of PI》AUTHOR’S NOTE
[https://book.douban.com/subject/20326626/](https://book.douban.com/subject/20326626/)

- 本书的诞生是因为我感到饥饿

# 20240223 《A path with Heart》A BEGINNING

- 在我们的精神生活中，普遍性必须与个人性结合才能得到满足
- 我走路时就像在冥想，让蒂芙尼这样的商店和行人的人群在我的心中与我林中寺院的风和树木一样。
- 内在的幸福和变化不是来自外部条件的改变，而是通过持续的自我觉察和转化实现的
- 冥想的核心教义之一：勇敢地正视自我内心深处的各种负面情绪，如贪欲、自我贬低、愤怒、多疑以及自我膨胀，并通过这个过程，超越这些情绪，开启智慧与勇气的新境界。
- 一个整合的精神观点认为，如果我们想要将光明、智慧或同情带入这个世界，我们必须首先从自己做起。

# 20240222 There’s a fast new code editor in town
[https://www.youtube.com/watch?v=JGz7Ou0Nwo8](https://www.youtube.com/watch?v=JGz7Ou0Nwo8)

- 一家位于弗朗西斯科的初创公司Magic AI已筹集了1.17亿美元的B系列资金，以进一步开发其旨在自动化软件开发的高级AI系统。押注于编程最终会导致人工通用智能的想法
- 1969年，人们曾以为到2024年我们会有月球基地和星际光速旅行，但这项技术从未成为现实，因为人们发现我们生活在一个静止的平面上
- 一场比赛正在进行中，目的是建造最佳的AI启用的代码编辑器：Co-Pilot、MVS Code、Cursor Editor、JetBrains AI，Zed
- Zed的工作方式类似于视频游戏，将整个窗口光栅化以提供每秒120帧的效果
- 公司去年筹集了1000万美元，还有一个更侧重于团队的功能，允许多人在同一个代码库上实时协作
- 在代码中使用AI时提供了非常清晰的体验
- 插件API，但它将基于Rust, 到目前为止，最大的限制是它只适用于macOS
# 20240222 First look at the new Rust GPUI framework from Zed!
[https://www.youtube.com/watch?v=OHU-Y93eCs8](https://www.youtube.com/watch?v=OHU-Y93eCs8)

- GPUI是一个UI框架，结合了即时模式和保留模式，通过GPU加速，专为Rust语言设计
   - **Immediate Mode**（即时模式）: 在即时模式下，应用程序的GUI部分需要在每一帧中重新绘制。开发者通过编写代码来直接渲染GUI元素，比如按钮、文本框等。每次应用程序更新或需要重绘时，都会调用这些绘制指令。这种方法使得GUI的更新和渲染逻辑紧密耦合，通常使得开发者可以更直接地控制渲染过程。即时模式适合于需要高度动态更新的界面。
   - **Retained Mode**（保留模式）: 在保留模式下，GUI的结构和内容被保存在内存中，通常在一个场景图（scene graph）或DOM（文档对象模型）中。应用程序在需要时对这个结构进行更新，而渲染引擎负责根据这个结构来绘制GUI。这意味着开发者不需要在每一帧中明确地重新绘制界面，而是更新状态或数据，渲染引擎会根据需要进行绘制。保留模式适合于结构相对静态，不频繁更新的界面。
# 20240222 Let's build the GPT Tokenizer 【上】
[https://www.youtube.com/watch?v=zduSFxRajkE&t=14s](https://www.youtube.com/watch?v=zduSFxRajkE&t=14s)

- 分词是在大型语言模型工作中我最不喜欢的部分，但不幸的是，它需要被详细理解，因为它相当复杂和棘手，有很多隐藏的问题需要注意，而且大型语言模型的许多奇怪之处通常都可以追溯到分词
- Tokenization是大型语言模型中许多奇怪现象的核心。很多可能看起来像是网络架构或大型语言模型本身的问题，实际上都是词元化的问题，并且根本上可以追溯到它
# 20240221 Chain of Thought论文、代码和资源【论文精读】
[https://www.youtube.com/watch?v=H4J59iG3t5o&t=44s](https://www.youtube.com/watch?v=H4J59iG3t5o&t=44s)

- Large language models are zero Shot reasoners  : let think step by step 
- 语言模型的本质 是对任意一段文本序列的概率进行建模
- zero-shot、CoT
- few-shot,  manul-CoT, auto-CoT
- Cot的开山之作 : Chain of Thought Prompting Elicits Reasoning in Large Language Models 
- 100B  以上的模型才能很好的被归纳， A类任务
- Flat scaling curves ：一个系统、模型或算法在增加计算资源（如处理器、内存）时，性能改善不显著的现象。这意味着即使向系统投入更多的资源，其性能增长的速率也相对较慢或几乎没有变化对于推理能力无法大力出奇迹。
- CoT的作用：
   - 让推理获得更多的计算量
   - 提供了可解释性
   - 适用于人类语言所能解决所有的问题
   - 可以在每个样例中写推理步骤用于最终答案
- Cot之前的prompting知识大语言模型能力的下限
# 20240221 Understanding ReACT with LangChain
[https://www.youtube.com/watch?v=Eug2clsLtFs](https://www.youtube.com/watch?v=Eug2clsLtFs)

- 与大型语言模型打交道最难的事情是让它们做你想让它们做的事
- 让模型先进行推理再给出答案可以显著提高答案的质量
- ReACT在其工作方式中经常使用更多的令牌
- CoT： chain of thought reasoning
- 经常出现幻觉的一个原因是：如果它给出了一个答案，它就会感觉必须要证明这个答案。
- Agent scratch pad ： 便签板作为一个工具，允许模型在处理信息、执行任务或进行决策时记录和参考其“思考过程”和观察结果
- 没有理由说提示必须包含这些例子
- 如果你想获得更好的结果，你会进来自定义这个提示，以便你可以将其用于你正在进行的特定类型的推理任务和行动推理任务。
# 20240220 深度探索Agent - 对GPT-4 和 Langchain 的研究
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1708430533315-650f1698-c92c-4925-a422-253f4f2a0f09.png#averageHue=%23efefef&clientId=ue6e36c6b-5cf2-4&from=paste&height=397&id=u5285501a&originHeight=793&originWidth=1999&originalType=binary&ratio=2&rotation=0&showTitle=false&size=148859&status=done&style=none&taskId=u3d461d5c-6281-4930-bce2-a3fd9074f68&title=&width=999.5)
[https://www.bilibili.com/video/BV1kW4y1A7wt/?vd_source=ba233cc2ca5aa56e0c97eb7eec51cb2e](https://www.bilibili.com/video/BV1kW4y1A7wt/?vd_source=ba233cc2ca5aa56e0c97eb7eec51cb2e)

- 国内大部分产品其实还是停留在function call阶段
- Function Call 已经成为一个Best Line
- AutoGen 就是把LangChain的自问自答变成了多问多答的形式,相当于有一个监督者，Multi Agent, 跟AutoGen相比更能落地，但还是实验阶段，稳定性不够，比LangChain 更依赖模型的能力,GPT4 效果才会好
- 对于LM（Language Model, 语言模型）：
   - COT (Chain of Thought, 思维链)，ReAct
   - Instruction Following (指令跟随)
- 对于Framework（框架）：
   - Prompt Design (提示设计)
   - Pipeline (管道)
   - Communication (通讯)
   - Memory control (记忆控制)
- TaskWeayer [https://github.com/microsoft/TaskWeaver](https://github.com/microsoft/TaskWeaver) TaskWeaver is A **code-first** agent framework for seamlessly planning and executing data analytics tasks
- Code其实是一种tool
- 一种聊天的习惯，不应该是微调出来的,意图识别
- 单个的Agent 可以分成几个部分：
   - **工具(Tools)**: 代表AI代理可以利用的各种工具，如日历(Calendar)，计算器(Calculator)，代码解释器(CodeInterpreter)，搜索(Search)，以及更多可能未在图中显示的工具。
   - **记忆(Memory)**: 分为短期记忆(Short-term memory)和长期记忆(Long-term memory)，这可能代表AI代理存储和回忆信息的能力。
   - **代理(Agent)**: 中心组件，它使用工具和记忆来做出计划(Planning)和采取行动(Action)。
   - **计划(Planning)**: AI代理的计划过程，可能包括反思(Reflection)，自我批评(Self-critics)，思维链(Chain of thoughts)和子目标分解(Subgoal decomposition)。
   - **行动(Action)**: 代理基于计划产生的最终行动。
- MetaGPT角色扮演的工作比较超前
- Co-Learning :“Experiential Co-Learning of Software-Developing Agents”，这意味着该框架被应用于软件开发代理的学习中，使它们能够通过经验共享来进行学习和成长。
- Agent层面的MoE太费token了，自然语言的信息压缩太多了
- 多Agent的关键在于是否是角色扮演是否是并行
- 链接推荐
   1. https://github.com/AGI-Edgerunners/LLM-Agents-Papers
   2. https://github.com/zjunlp/LLMAgentPapers
   3. https://lilianweng.github.io/posts/2023-06-23-agent/

# 20240220 AgentBoard :一个多回合LLM Agent 的分析评估板-TaskComposition
[https://hkust-nlp.github.io/agentboard/](https://hkust-nlp.github.io/agentboard/)

- 四种类型的代理
   - 机器人代理理解基本代理能力方面
   - 战略游戏代理具备强大的规划能力
   - 网络代理需要高效地导航网络并在高度动态、复杂和多轮次互动中执行多样任务
   - 与外部工作的协同互动
# 20240219 Risks of Integrating Gen AI with Patient Data
[https://www.youtube.com/watch?v=LIUu4WZ3f9M](https://www.youtube.com/watch?v=LIUu4WZ3f9M)

- 但当我思考安全性时，我认为它有两个方面。一个是准确性，另一个是失败模式或不完美
- 要考虑如何尽可能提高准确性，但同时也要思考如果准确性不高，这对用户来说会是什么样子。
- 你需要做的第一件事就是理解用户和数据的使用方式,会有不同的准确性要求
- 第二个，与使用案例相关，我会说是另一个使用案例的子集，是AI系统补充现有工作流程还是替换工作流程的某些方面。
- 你需要深思熟虑地设定你的准确性要求,并将其作为构建系统的实际要求，不要仅因为达不到要求就降低标准
- 验证基本上是测试过程，以确保你构建的系统满足要求并适当地执行



# 20240218 What is RAG? (Retrieval Augmented Generation)
[https://www.youtube.com/watch?v=u47GtXwePms](https://www.youtube.com/watch?v=u47GtXwePms)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1708257925081-471c364f-127e-4992-b846-80d7ffc96e32.png#averageHue=%23786750&clientId=u26388776-6477-4&from=paste&height=456&id=ud6822c34&originHeight=912&originWidth=1660&originalType=binary&ratio=2&rotation=0&showTitle=false&size=836081&status=done&style=none&taskId=ua927c400-1d16-4886-81d9-21c72ed5b31&title=&width=830)

- RGA用途基本上是针对你自己的内容来利用大型语言模型的系统
- “提示之前的提示”就是上下文
- 内容太多事RAG要解决的最棘手的问题，解法是把内容分成多个块，每个块转化成一个向量，然后把问题向量跟这个向量进行匹配
- 这个rag系统，会根据问题找到最相关的内容，作为提示的一部分，发送给LLM，然后你实际上会得到一个好的回应。这里可能需要对内容进行压缩和优化，还有对已经有的上下文内容进行压缩。
- 这整个过程被称为rag检索，所以你从内容中检索相关文档，增强生成过程，即增强LM基于你检索的文档进行生成AI的能力，这就是所谓的检索增强生成
- 大多数LLM项目都是这种类型
# 20240217 OpenAI's Agent 2.0: Excited or Scared? 下
[https://www.youtube.com/watch?v=JfM1mr2bCuk](https://www.youtube.com/watch?v=JfM1mr2bCuk)

- SCO但对于信息更密集或结构更复杂的网站，似乎效果不佳
- GBT-4V和OCR（Optical Character Recognition光学字符识别）模型
- 但如果用户界面有很多非文本按钮这种方法就不好用
- 阿里巴巴添加了一个名为clip的新模型，专门用于提取图标的坐标
- 理想情况下，我认为正确的方法显然是不使用多个模型，而是将所有这些能力合并到一个模型中
- cook agent的开源模型，这是一个视觉语言模型，专门设计用于理解和与GUI截图交互,   [https://github.com/THUDM/CogVLM](https://github.com/THUDM/CogVLM)
- 像cook agent这样更强大的模型将能够真正解锁这种基于视觉的方法，并且在这个领域每天都有新的研究出现
- 这个领域的三个问题：
   - 速度
   - 准确性
   - 任务完成
- 尽管存在这些挑战，但通过改进的模型，这些问题是可以解决的，并且对使用这种代理方法构建有用工具持乐观态度，特别是在网页抓取这一领域
- WebQL的新项目可以用来构建一个可以导航网站并输入验证码的代理


# 20240216 OpenAI's Agent 2.0: Excited or Scared? 上
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1708092219064-9522f58b-9eaf-4c89-85bd-e45fe0f82b33.png#averageHue=%230c0c0c&clientId=ude6c95e2-9a6f-4&from=paste&height=410&id=u20b7d1e3&originHeight=820&originWidth=1966&originalType=binary&ratio=2&rotation=0&showTitle=false&size=102593&status=done&style=none&taskId=ufda1f910-c4c7-4c88-94b2-28083d8ab7f&title=&width=983)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1708155175870-73359e69-68fc-46f2-bf3f-889177588781.png#averageHue=%230f0f0f&clientId=u50c3bc03-8ef7-4&from=paste&height=373&id=u0660996c&originHeight=746&originWidth=1896&originalType=binary&ratio=2&rotation=0&showTitle=false&size=80731&status=done&style=none&taskId=uc891d5f3-8816-457e-a9f7-3a493871fd5&title=&width=948)
[https://www.youtube.com/watch?v=JfM1mr2bCuk](https://www.youtube.com/watch?v=JfM1mr2bCuk)

- 新的AI Agent 旨在执行更复杂的个人和工作任务，而无需密切监督
- 传统的AI Agent 的问题是不够通用，因为任务都是预制的。这个跟传统开发软件的预制件事相当的
- 但是新的AI Agent 只需要让它学习如何使用计算机，希望它能够自己弄清楚如何在任何新网站上执行任务，有两个优势：
   - 能够处理网站上大量的长尾用例，而无需为每一个都构建API端点
   - 大多数网站没有任何API端点
- 一些最有才华的团队已经在这个项目上工作了很长时间：
   - Hyper R&D的团队开发浏览器扩展
   - https://taxy.ai/
   - Hyper TE的Josh Bicket开发的最受欢迎的self-operating-computer，不仅能够接管浏览器，还能接管整个计算机，并能模拟像鼠标点击这样的真实交互
   - Rabbit R1
   - MultiOn
   - WebQL u开源项目 : 构建一个可以在不同网站上编写脚本的通用AI代理
- 这种可以直接控制个人计算机设备的网络、移动或桌面代理，比我们正在构建的普通函数调用代理要困难得多
- 如果这种能力实现了，那将非常令人兴奋，并为多个巨大市场开辟机会
- 模拟真实人类输入反而是最容易的，有大量的库来实现Playwright、Puppeteer、Appium，这些最初是为自动化测试设计的
- 困难的部分是让代理知道如何以及何时准确地执行这些动作，因为大多数的语言模型或多模型实际上并不是真正训练来理解界面并决定下一步该做什么
- 它通常不擅长给出非常具体的位置和坐标，以决定点击哪个UI元素
- 如何解决呢，通常有3个方法：
   - HTML/XML， 这个最早在2022年在gpt3之前就有人作出来了
   - Vision
   - Mixed
- GPT-3的上下文窗口只有2049，而与我们现在拥有的GPT-4 Turbo相比，几乎高出60倍，有128,000个令牌上下文
- Nate的处理方式是，它不会发送原始杂乱的HTML文件，而是会做大量的清理，提取最相关的信息
- 基于文本的处理方法在处理图像相关任务 还有 不支持 动态HTML
- 基于HTML和XML的方法到目前为止是最成熟的，但它有很多问题和限制
- 我们可以不用给代理提供原始的HTML代码，而是可以拍一个屏幕截图，发送给多模型模型，这种方法最难的部分是定位要交互的确切UI元素
- Set-of-Mark(SOM)是微软开发的一种方法，他们发现尽管默认情况下GBD-4V在某些任务上不擅长，但通过提供一些视觉提示，如在这张图片上覆盖一些注释，GBD-4B可以更好地完成这些视觉任务

# 20240215 AgentBoard :一个多回合LLM Agent 的分析评估板-摘要和介绍
[https://hkust-nlp.github.io/agentboard/](https://hkust-nlp.github.io/agentboard/)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1708003945667-2b0c84f4-a744-4a21-9ec6-31398807d1c0.png#averageHue=%23a9cb48&clientId=u20917fd0-6813-4&from=paste&height=2267&id=ua2aba44f&originHeight=4533&originWidth=9267&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1357502&status=done&style=none&taskId=u179954a3-b672-433c-b069-f7f5cc32fef&title=&width=4633.5)

- 评估LLMs面临的挑战：
   - 在统一框架内跨多样化场景基准测试代理性能，比如 维持部分可观察环境和确保多轮交互方面
   - 当前的评估框架大多关注最终成功率，过程中揭示的洞察少，未能提供模型能力的深入理解
- 如何解决：
   - 细粒度的进度率指标
   - 捕捉逐步进展
   - 包含了一个综合评估工具包，该工具包通过交互式可视化轻松评估代理进行多方面分析
- 能够独立感知和在各种环境中行动的通用代理被认为是人工智能领域的重要里程碑
- 现有基准中常见是： 单轮任务和完全可观察环境中的“伪”任务
- agent task 的特点：
   - 多轮交互
   - 基于长文本的决策制定
   - 各种子任务目标
- AgentBoard包含9种独特任务和1013个示例环境
- 开源权重大模型代理与商业大模型代理的差距
   - GPT-4超越所有
   - 与环境进行多轮交互的能力
   - 开源权重LLM在基础建设、世界建模和自我反思方面显示出不同程度的缺陷

# 20240214 OpenAI Introduces MEMORY and New Controls for ChatGPT | Meet your new personalized AI assistant.
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707881075556-77111a1c-2f24-498f-9119-1ace6425e25e.png#averageHue=%23dbdbdb&clientId=u6f7ca4e1-5012-4&from=paste&height=900&id=u230f946d&originHeight=1800&originWidth=1800&originalType=binary&ratio=2&rotation=0&showTitle=false&size=225520&status=done&style=none&taskId=u8c506340-85ca-4bc1-812b-5999a921da8&title=&width=900)
[https://www.youtube.com/watch?v=I8C5gLRLAu8](https://www.youtube.com/watch?v=I8C5gLRLAu8)

- Chat GPT的记忆功能会随着你的使用而变得更好，你会逐渐注意到随着时间的推移会有所改善。
- 对于明确的信息指令，您可以将其添加到您的自定义指令中，所以这些记忆似乎是更加流动的持续性事物，您可以快速更改，这将自动被排
- 敏感的信息，比如你的健康细节，它不会记住除非你明确要求它
- gpts也将有记忆，所以那些自定义gpts如果用户正在构建gpts，它们将有自己独特的记忆，作为一个构建者，用户可以选择为gpts启用记忆，现在这些记忆将不会与构建者共享
# 20240214 Sam Altman SPEAKS at WGS 2024 | GPT-5 is "smarter", Deploying AGI, Open Source GPT. Are we ready?
[https://www.youtube.com/watch?v=JVatgo0TJIw](https://www.youtube.com/watch?v=JVatgo0TJIw)

- GTP5会更加聪明，使这些模型如此神奇的是它们的普适性，所以如果它稍微好一点，如果它稍微更聪明一点，那意味着它在所有方面都会好一点
- 不是这个模型在这个任务上会变得稍微好一点，而在其他任务上并没有真正进步，你知道，不是这样，而是因为我们将使模型变得更加智能，它将在各个方面都变得更好
- 需要有一个国际原子能机构那样的全球系统
- GPT2 已经开源了
- 悲观的事是，对那种非常微妙的社会错位更感兴趣
- 年轻人是非常幸运的，你们正在经历人类历史上可能是最好的时代，你们年轻人理解这项技术，年轻人几乎总是技术的早期采用者，几乎总是，但在这种情况下肯定是这样，你们将能够使用这些工具做一些前一代人甚至无法想象的事情，你们的整个职业生涯都将充满机会和做出惊人的新事物的能力，你们将能够创办比前一代人更有影响力和成功的公司，你们将生活在这个极具扩张性和机会的时代，充满了大量的机会，你们可以做任何你们想做的事情，我认为我们所有人的地面都在变化，规则正在改变，但将创造的价值和个人创造力和意志的能力将是巨大的
# 20240213 我们10多年的外语教学的方法几乎全错了
[https://www.youtube.com/watch?v=TlP4iwFum2g](https://www.youtube.com/watch?v=TlP4iwFum2g)

- 英语知识是一种隐形知识（运动类知识）
- 听英语不要看字幕
- 单词是靠学习而不是记忆
- 两项原则：
   - 明确任务的输入输出
   - 用例子重塑大脑连接
- 注意要点：
   - 不要依靠意识
   - 以句子为单位
   - 多例子学习
   - 输出要一致

# 20240213 learning human actions on computer applications
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707812883122-1d110518-70ed-4650-b19e-d5ba251a5877.png#averageHue=%237c7f82&clientId=u1cf141c2-62bb-4&from=paste&height=612&id=u4036cb94&originHeight=1224&originWidth=2042&originalType=binary&ratio=2&rotation=0&showTitle=false&size=514402&status=done&style=none&taskId=u46c1ff42-6720-4ace-8050-4dd674d5734&title=&width=1021)
[https://www.rabbit.tech/research](https://www.rabbit.tech/research)

- 我们开发了一个系统，可以推断和模拟计算机应用程序上的人类行为，可靠且快速地执行这些操作，并且非常适合部署在各种人工智能助手和操作系统中。我们的系统称为大型行为模型（LAM）。借助最近在神经符号编程方面的进展，LAM 允许直接对各种应用程序及其上执行的用户操作的结构进行建模，而无需像文本等过渡性表示
- 通过移动应用程序提供的个性化体验的普及已成为个人计算的上一个十年的主题，这些应用程序由图形用户界面启用，允许用户进行交互而无需任何编程经验。
- 一种新型的用户交互体验出现了，其中设备的主要用户界面是通过口语自然语言而不是触摸实现的
- 主要服务提供商的应用程序编程接口（API）不可用是最大的挑战。采用了神经符号编程来直接学习用户与应用程序的交互，从而避免了翻译自然语言用户请求为严格的API的需求
- 我们的关键观察是，人机交互的固有结构与自然语言或视觉不同。这些应用程序以一种比栅格图像更结构化的形式表达，比句子或段落更冗长且嘈杂
- 虽然我们可能希望智能聊天机器人具有创造性，但 LAM 对应用程序的学习动作应该是高度规则化、极简主义、稳定且可解释的
- 虽然神经语言模型已经表现出理解和利用应用程序编程接口的能力，但用户界面与文本之间存在基本差异，因此不太适合
- 使用测试时间自适应提示模板、指令驱动或基于强化学习的微调来进行某种形式的推理。在这种情况下，语言模型需要作为端到端推理器，但它们仍然难以胜任这项任务。额外的缺点包括：丢失应用程序中重要的结构信息、标记化序列或像素数组通常过长且嘈杂，以及引入自然语言中描述的操作的模糊性
- 通常，需要为特定问题设计一个专门的形式规范，而用于解决一个问题的启发式方法往往无法很好地适用于其他问题。RPA的挑战在于泛化的困难
- 为了协助新模型的开发，我们从零开始设计了技术堆栈，从数据收集平台到一个新的网络架构，该架构利用了变压器式的注意力和基于图的消息传递，结合了以示范和示例为导向的程序合成器 
- LAM的建模方法根植于模仿，或者称之为学习演示。它观察人类使用界面，并旨在可靠地复制这个过程，即使界面被以不同方式或稍微改变的方式呈现
- 随着时间的推移，LAM从演示中积累知识，深入理解了应用程序所暴露的接口的每个方面，并创建了应用程序提供的底层服务的概念蓝图。LAM可以被视为一座桥梁，通过应用程序的界面将用户连接到这些服务
- 通过在循环中利用神经符号技术，LAM处于语言建模（LM）、编程语言（PL）和形式方法（FM）跨学科科学研究的最前沿
- 今为止，还没有人将尖端的神经符号技术投入到生产中 — LAM旨在开创这一方向
- 智能放在终端用户手中是可行的，而无需沉重的客户端计算能力。
- 神经符号 LAM 在云端运行，但与之交互的硬件设备并不需要昂贵而庞大的处理器，非常环保，并且能耗极低
-  scaling law在神经系统研究的所有方面都持续存在，从过去十年的视觉 [4] 到现在的自然语言
- 理解行为将进一步帮助重新设计人机交互，并可以产生更直观和有用的自然语言驱动的系统和设备，从服务提供商、消费者和硬件制造商到软件开发人员，使所有利益相关者受益
- the future of human-machine interface
# 20240211 2024 is the Year of the AI AGENT
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707636754436-a13e5c95-b707-47f1-a05d-e60b5b579248.png#averageHue=%23a18451&clientId=u87a33967-2f24-4&from=paste&height=874&id=u67e097f6&originHeight=1748&originWidth=1346&originalType=binary&ratio=2&rotation=0&showTitle=false&size=2481337&status=done&style=none&taskId=ude924c63-431d-463d-91d5-94b65d67bd4&title=&width=673)
[https://www.youtube.com/watch?v=hmt5MnStKUI&t=379s](https://www.youtube.com/watch?v=hmt5MnStKUI&t=379s)

- Agentboard ：强调对大型语言模型（LLMs）进行分析评估，作为通用代理程序在各种环境中感知和行动的能力。[https://hkust-nlp.github.io/agentboard/](https://hkust-nlp.github.io/agentboard/)
- Voyager：具有大语言模型的开放式具身代理；"具身代理"是指一个智能代理系统，它不仅仅是一个虚拟存在或者算法，而是在物理世界中具有一定形态或身体，可以与环境进行交互、感知和行动 [https://voyager.minedojo.org/](https://voyager.minedojo.org/)
- adept ：使用计算机的新方法，建立一个机器学习模型，该模型可以与计算机上的所有内容进行交互。[https://www.adept.ai/](https://www.adept.ai/)
- Rabbit： 学习人类在计算机应用上面行动 [https://www.rabbit.tech/research](https://www.rabbit.tech/research)
- 与RPA的区别：
   - RPA，基本上是你在录制屏幕，然后部署一个算法，一个预先编程的序列，来导航你的鼠标，你的光标到XY位置，基于绝对的坐标
   - 神经符号算法更进一步，因为我们不是通过屏幕的绝对坐标来识别所有这些元素，我们从符号方法中直接提取和自动标记一些元素，并对这些元素进行推理，这意味着，如果一个应用程序完全改变了界面，也不会有关系
- **根本的哲学逻辑是，所有这些现代软件都是为了人眼来处理信息设计的，**它们必须在某个地方有一个设置
- 当前计算机技术的变革，从以前简单地执行我们指示的动作，变为像人类一样理解符号并与网站进行交互的神经符号处理
- 通过人类示范的方式进行训练
- 在语言模型的基于文本的游戏中的欺骗与合作 [https://arxiv.org/abs/2308.01404](https://arxiv.org/abs/2308.01404)
# 20240210 The next grand challenge for AI
[https://www.ted.com/talks/jim_fan_the_next_grand_challenge_for_ai/transcript?subtitle=en](https://www.ted.com/talks/jim_fan_the_next_grand_challenge_for_ai/transcript?subtitle=en)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707532853545-28fecd45-3e5a-4d91-830c-11a1293e6696.png#averageHue=%233f413d&clientId=ue97aebf6-6ec3-4&from=paste&height=409&id=uc743a1c0&originHeight=818&originWidth=1468&originalType=binary&ratio=2&rotation=0&showTitle=false&size=112788&status=done&style=none&taskId=uf17d7219-195c-426a-acd6-f21b5a95dfc&title=&width=734)

- Alphago只能单独做一件事
- Voyager是一个agent，在许多技能方面都大大扩展。
- Minecraft的玩家是英国人口的两倍
- Voyager的核心思想是coding as action
- self-reflection的feedback有三个来源：
   - JavaScript代码执行错误；
   - agent的状态，例如健康和饥饿；
   - world的状态，例如附近的地形和敌人
- 我们只给Voyager一个高级指令，那就是尽可能获取尽可能多的独特物品
- 我们没有提前编程任何这样的内容。这都是Voyager的想法。这，你在这里看到的，是我们所说的终身学习。当一个代理永远好奇，永远在追求新的冒险。与AlphaGo相比，Voyager在他能做的许多事情上都大规模扩展，但仍然只控制Minecraft中的一个身体。
- 我们能有一个适用于许多不同身体的算法吗？让我们来看看MetaMorph。这是我在斯坦福共同开发的一个项目。我们创建了一个基础模型，它不仅可以控制一个，而且可以控制成千上万个具有非常不同的手臂和腿部配置的机器人。Metamorph能够处理来自不同机器人身体的极其多样化的运动特性。
- IsaacSim的最大优势是将物理模拟加速到比实时快1,000倍。
- 这是一个有趣的主意。如果agent能够掌握10,000个模拟，那么它很可能只是概括为我们的真实世界，这只是第10,001个现实
- 我相信训练Foundation Agent将与Chatgpt非常相似。所有语言任务都可以表示为文本和文本。
- 有一天，我们将意识到，无论是在物理还是虚拟空间中，所有的AI代理，都在Wall-E，星球大战，头号玩家 上，与同一Foundation Agent都有不同的 提示词 。我的朋友们，这将是我们寻求AI的下一个大挑战。
# 20240208 NLP Course  7 ：MAIN NLP TASKS (上)
[https://huggingface.co/learn/nlp-course/chapter7/1?fw=pt](https://huggingface.co/learn/nlp-course/chapter7/1?fw=pt)

- 本章基本上是重复前面的东西，让你对整个任务有更深入的了解
- Token classification
   - 将标签归因于句子中的每个token
      - Named entity recognition (NER)
      - Part-of-speech tagging (POS)
      - Chunking
   - 数据预处理其实是最艰难的部分
   -  使用Trainer API对模型进行Fine-tuning
      - 数据批处理
      - 度量函数
- Fine-tuning a masked language model
   - 用于预读的语料库与用于微调的语料库没有太大不同，转移学习通常会产生良好的结果。
   - 对内域数据进行验证的语言模型进行微调的过程通常称为domain adaptation（域适应性）
# 20240208 The Rust Programming Language-Introduction
[https://doc.rust-lang.org/book/ch00-00-introduction.html](https://doc.rust-lang.org/book/ch00-00-introduction.html)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707395513215-134428ea-45e2-4cca-a502-a45a2ea09a36.png#averageHue=%23722218&clientId=ud5efa388-364e-4&from=paste&height=424&id=u196dd236&originHeight=847&originWidth=1259&originalType=binary&ratio=2&rotation=0&showTitle=false&size=100504&status=done&style=none&taskId=u8c3a4045-d91f-4eb0-bba3-85b4bad7ddc&title=&width=629.5)

- Rust可帮助您更快，更可靠的软件编写。在编程语言设计中，High-level ergonomics（人体工程学） 和 low-level control通常会矛盾；Rust试图解决这个冲突。
- Rust适合谁
   - 开发团队
      - 编译器
      - 工具链
   - 学生
      - 系统编程的概念
   - 公司
      - 生态
   - 开源代码开发者
   - 重视速度和稳定的人
      - zero-cost abstractions（零成本抽象）
- 本书目录
   - Chapter 1 Helloworld
   - Chapter 2 一个demo, 测试数字的游戏
   - Chapter 3 涵盖了与其他编程语言相似的RUST功能
   - Chapter 4 ownership system
   - Chapter 5  structs and method
   - Chapter 6  enums, match expressions
   - Chapter 7 模块化系统
   - Chapter 8   some common collection data structures 
   - Chapter 9 error-handling
   - Chapter 10  generics, traits, and lifetimes
   -  Chapter 11 testing
   - Chapter 12 一个命令行工具的例子
   - Chapter 13 用于函数式编程的 closures（闭包） and iterators（迭代器）
   - Chapter 14 深入Cargo
   - Chapter 15 智能指针
   - Chapter 16 并发编程
   - Chapter 17 对比传统的面向对象编程
   - Chapter 18 模型匹配
   - Chapter 19 一些先进的主题
   - Chapter 20 开发一个web服务器
# 20240207《Elon Musk》34 Falcon 9 Lifto Cape Canaveral, 2010
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707314532115-d16bc6e1-1446-4eba-8f4b-3e3b8eda5c66.png#averageHue=%237d7d7d&clientId=u883a8359-d556-4&from=paste&height=452&id=u9477663f&originHeight=904&originWidth=1332&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1053587&status=done&style=none&taskId=ueb21b0ba-36d0-43e0-a4a4-3c31eafd277&title=&width=666)

- 进入轨道
   - 对Elon的重要意义是，如果您告诉他风险并向他展示了工程数据，他将进行快速评估，并让责任从您的肩膀转移到他的肩膀上。
- ... and return
   - SpaceX不仅可以将无人胶囊推入轨道，而且还可以安全地将其返回地球。没有私人公司这样做。实际上，只有三个政府拥有：美国，俄罗斯和中国。
   - 在Musk或奥巴马出生之前，水星计划已经完成了类似的壮举
# 20240206 LangChain:  Why use LCEL ？
[https://python.langchain.com/docs/expression_language/get_started#entire-pipeline](https://python.langchain.com/docs/expression_language/get_started#entire-pipeline)

- 什么是LCEL？
   - LangChain Express Language
   - LCEL使从基本组件构建复杂的链条变得容易，并支持out of the box的功能，例如流媒体，并行性和日志记录。
   - 例子： chain = prompt | model | output_parser
   - Python代码使用了管道操作符(**|**)，这在标准Python语法中并不直接存在。这种用法可能来自特定的库或框架，它们通过重载对象的**__or__**方法来实现自定义的管道操作。这种做法在某些数据处理和流式处理库中很常见，比如Pandas的某些扩展、Dask或类似的可以链式调用的库，用以简化代码并提高可读性。 是一种内部DSL
- why?
   - 通用的接口：每个 LCEL 对象都支持invoke, batch, stream, ainvoke, …
   - 原子组合
- ![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707221553404-5c79d55e-b2ad-4ffa-bf15-a4b997915290.png#averageHue=%23606355&clientId=u15361ee1-1e74-4&from=paste&height=512&id=ud25664e0&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1825108&status=done&style=none&taskId=u5499bc7b-54da-4dbb-851a-376152be307&title=&width=512)

# 20240204  NLP Course  6 ： THE 🤗 TOKENIZERS LIBRARY (下)
[https://huggingface.co/learn/nlp-course/chapter6/3b?fw=pt](https://huggingface.co/learn/nlp-course/chapter6/3b?fw=pt)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707117984912-3c08ac8e-5218-4c8f-865c-e7f4b9839fc3.png#averageHue=%23fdf8ef&clientId=u2f759465-0fc4-4&from=paste&height=158&id=ucc9df4b1&originHeight=316&originWidth=1735&originalType=binary&ratio=2&rotation=0&showTitle=false&size=42034&status=done&style=none&taskId=ua4c0938f-2ea3-4337-b574-bd1eccec057&title=&width=867.5)

- Fast tokenizers in the QA pipeline
   - QA pipeline需要处理和返回长文本
   - return_overflowing_tokens=True允许分词器(tokenizer)返回所有因超出最大长度(max_length)而溢出的tokens，这些溢出的tokens被组织成多个块。通过设定stride值，我们可以控制这些块之间的重叠部分，确保上下文的连贯性和完整性，从而在不丢失重要信息的前提下，有效处理长上下文。
- Normalization and pre-tokenization
   - SentencePiece算法是 reversible tokenization（可逆令牌），BERT tokenizer 是不可逆的
   - 三个主要的subword tokenization算法：
      - BPE (used by GPT-2 and others), 
      - WordPiece (used for example by BERT)
      - Unigram (used by T5 and others)
- Byte-Pair Encoding tokenization
   - OpenAI使用的，用在Transformer模型
   - 将单词拆分成字符，然后从两个字符开始合并
- WordPiece tokenization
   - google 开发的，跟BPE非常相似
   - google并没有开源其实现，所以这些实现都是猜测的
   - 给定一个单词，算法从最长可能的片段（在词汇表中）开始匹配，然后逐步减小片段长度，直到找到匹配的tokens。
- Unigram tokenization
   - 应用在 SentencePiece
   - 基本思想是从一个大的候选词汇集合出发，通过优化概率模型来逐步减少词汇集合的大小，最终得到一个高效的分词结果
   - Unigram算法能够自适应不同语言和领域的文本，因为它基于数据的统计特性来建立词汇表。
- Building a tokenizer, block by block
   - tokenization的四个步骤
      - **标准化(Normalization)**：可能包括去除空格、标点符号、文本中的特殊字符，进行Unicode标准化，以及删除或转换口语词汇和缩写等。这有助于减少文本中的变异性，确保相似的文本片段在处理时被视为相同。
      - **预分词(Pre-tokenization)**：通常是词(words)或子词(subwords)
      - **通过模型处理(Running the input through the model)**：根据所使用的分词算法（如BPE、WordPiece或Unigram），预分词单元可能会被进一步分解成更小的单元或被转换成模型的词汇表中的索引。
      - **后处理(Post-processing)**：、生成注意力掩码(attention masks)和token类型IDs(token type IDs)。特殊tokens用于模型理解句子的结构，如区分两个句子或表示句子的开始和结束


# 20240204  NLP Course  6 ： THE 🤗 TOKENIZERS LIBRARY (上)
[https://huggingface.co/learn/nlp-course/chapter6/1?fw=pt](https://huggingface.co/learn/nlp-course/chapter6/1?fw=pt)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707055180554-33ccfd5b-0db8-4e96-838a-6ca932ca8343.png#averageHue=%23fdfaf5&clientId=u7e71d0d0-0cbb-4&from=paste&height=193&id=u31289722&originHeight=385&originWidth=1735&originalType=binary&ratio=2&rotation=0&showTitle=false&size=39974&status=done&style=none&taskId=uf59c2a3b-0230-4bd4-a897-873f6f6ba4d&title=&width=867.5)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1707055315192-8cc8cf94-dbb2-4922-9898-0f385754d275.png#averageHue=%23fcf8ed&clientId=u7e71d0d0-0cbb-4&from=paste&height=512&id=u85c3ee33&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1486364&status=done&style=none&taskId=ue3544c4c-3ac7-40a3-99b7-955ad25ccf2&title=&width=512)

- 一个在英文语料库上训练的Tokenizer在日文文本的语料库上表现会很差，因为两种语言中空格和标点符号的使用非常不同
- Training a new tokenizer from an old one
   - 大多数Transformer模型使用subword(子词)分词算法
   - 为了识别哪些subwords(子词)是有趣的并且在手头的语料库中最常出现，tokenizer需要仔细查看语料库中的所有文本 —— 这个过程我们称之为training。
   - 训练一个tokenizer(分词器)与训练一个模型不同！模型训练使用stochastic gradient descent(SGD)(随机梯度下降)使每个批次的loss(损失)稍微减小。它本质上是随机的（意味着你必须设置一些seed(种子)以在进行相同训练两次时获得相同的结果）。
   - 训练一个tokenizer(分词器)是一个统计过程，试图识别哪些subword(子词)是给定语料库中最佳选择，而用于选择它们的确切规则取决于tokenization algorithm(分词算法)。它是deterministic(确定性的)，意味着在相同的语料库上使用相同的算法训练时，你总是获得相同的结果。
   - 使用python的Generator Expression（生成器表达式）而不是List Comprehension（列表推导式）用于节约内存
   - 快速分词器由🤖 Tokenizers 库支持，后者是用 Rust 编程语言编写的。
   - 模型计算核心的矩阵乘法是使用 CUDA 编写的，这是一种针对 GPU 优化的 C 库。
- Fast tokenizers’ special powers
   - Fast tokenizer 的快速除了并行之外还有 “跟踪来自偏移列表每个令牌的文本跨度”
   -  fast tokenizer 需要进行 post-processing，主要是增加了上下文信息（比如偏移量），并且用rust实现包装性能和效率
# 20240202 Announcing Multion：与AI Agents 为人类建立更美好的未来
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706885972970-f8fb0f60-093a-4aa1-982c-c2ca23008da8.png#averageHue=%238c9e8f&clientId=ue927c512-cbf0-4&from=paste&height=334&id=u3e91d129&originHeight=667&originWidth=1000&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1139109&status=done&style=none&taskId=u92dee6d2-fecb-4c49-99bb-c23a8e0bdf5&title=&width=500)
[https://www.multion.ai/blog/multion-building-a-brighter-future-for-humanity-with-ai-agents](https://www.multion.ai/blog/multion-building-a-brighter-future-for-humanity-with-ai-agents)

- Multion是一家旨在开发AI产品和技术的开拓性AI初创公司，旨在开发AI产品和技术
- Multion是AI代理，它采取行动并与数字世界进行互动，以解决人们宁愿将其委派给助手的平凡任务
- MultiOn的创意来自斯坦福大学的2个人 Div Garg 和 Omar Shaya
   - Div同时有三份工作，在斯坦福教课，机器人初创公司，副业。他想从无聊平凡的工作中解放出来，去做一些有创意和有意义的工作
   - Omar，一个追求技术和创业目标的环球旅行者，一直认为技术可以做更多的事情来帮助他在新的地方定居，就像朋友和家人在家乡所能提供的一样
- Div在斯坦福，他的研究聚焦于大型语言模型和强化学习，将它们应用于如能在视频游戏比赛中赢得顶级奖项的AI代理、可以通过语言控制的机器人、以及获得广泛媒体报道的最先进自动驾驶系统等项目
- Omar拥有丰富的计算机科学和消费产品经验，曾在微软和Meta领导开发消费者AI产品的团队。奥马尔对社交媒体平台的算法优化和微软的AI助手开发的深刻理解，为他创立MultiOn和制定其独特产品愿景提供了坚实的基础。
- Multion的愿景不是替代人类的机器，而是增加人类
- 最早的demo取得了很大的成功
- 亚马逊Alexa Fund的董事保罗·伯纳德（Paul Bernard）说：“跨越正在重新定义AI时代的最前沿。Multion的AI代理具有与Internet上几乎任何设备或接口连接的能力，令人印象深刻。”
# 20240202 MultiOn AI
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706882599310-2e192e90-347f-48c7-9b74-775291fda917.png#averageHue=%23fcfbfb&clientId=u51acee71-69a5-4&from=paste&height=329&id=u1a602f60&originHeight=658&originWidth=1834&originalType=binary&ratio=2&rotation=0&showTitle=false&size=141056&status=done&style=none&taskId=u940c53c0-0602-4928-b421-91bac78d278&title=&width=917)
[https://docs.multion.ai/](https://docs.multion.ai/)

- Multion是下一代Web AI代理，可以代表您在Internet上采取行动
- 通过浏览器插件，可以完全自动化
- 支持两种模式 step by step 和 auto
- 也支持通过api写代码的方式进行操作， 无代码 和 代码
   - 每个会话都是隔离的
   - 集成Langchain ，LlamaHub， OpenAI Assistants API
   - LlamaHub是一个开源项目，提供了一系列数据连接器，这些连接器可以将来自各种源的原始数据转换为向量，以便大型语言模型（LLMs）如ChatGPT和Google Bard等更容易地访问和转换这些数据
- 盈利模式

![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706886794855-28596678-c113-4126-b4ae-1ea5fbd16ab3.png#averageHue=%23333333&clientId=uc5046217-dcf9-4&from=paste&height=763&id=u4e1ab751&originHeight=1526&originWidth=2584&originalType=binary&ratio=2&rotation=0&showTitle=false&size=546936&status=done&style=none&taskId=ua70b853e-08c8-432c-9a16-c6193245208&title=&width=1292)
# 20240202 LangChain Introduction
[https://js.langchain.com/docs/get_started/introduction](https://js.langchain.com/docs/get_started/introduction)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706869769957-58c45cd4-7136-449a-a664-4f976d5573c5.png#averageHue=%239bb4cd&clientId=u5f68a4b6-623a-4&from=paste&height=630&id=ua0133044&originHeight=1260&originWidth=1568&originalType=binary&ratio=2&rotation=0&showTitle=false&size=547096&status=done&style=none&taskId=u03625e9c-e3e2-4d41-9f32-34ca2433db6&title=&width=784)

- 定义：LangChina 是一个用于开发大模型应用的开发框架
- 提供两个能力：
   - 上下文感知
   - 推理
- 组成部分：
   - LangChain Libraries： 
      - 组件： 组件是模块化的
      - Off-the-shelf（现成的） chains
   - LangChain Templates: 各种不同任务的参考架构集合，目前只支持python
   - LangSmith: 一个运维平台
- LCEL：LangChain Expression Language
   - LCEL是构成链条的声明性方法。
   - LCEL从第1天开始设计，以支持将原型放在生产中，没有任何代码更改，从最简单的“提示 + LLM”链到最复杂的链条。
- modules： 标准的，可扩展的接口和集成
   - Model I/O
   - Retrieval: 应用特有的数据接口
   - Agents: 让模型选择使用的给定高级指令的工具



# 20240201 OpenAgents: An Open Platform for Language Agents in the Wild
[https://github.com/xlang-ai/OpenAgents](https://github.com/xlang-ai/OpenAgents)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706776082319-cd2bd575-bbfa-4f08-b7da-e13dedb3c31f.png#averageHue=%23ededec&clientId=uf0d4ec3a-9a3e-4&from=paste&height=696&id=u3e3f5718&originHeight=1391&originWidth=2596&originalType=binary&ratio=2&rotation=0&showTitle=false&size=765644&status=done&style=none&taskId=u2d762ba0-0b37-42bd-8ce3-f455ccb3ddb&title=&width=1298)

- 当前language agent frameworks的问题：
   - 只是proof-of-concept（概念验证）
   - 忽视非专业人士
   - 应用层的设计太少
- 目标是real-world language agents
- Web代理利用Chrome扩展程序的功能自动导航和探索网站。该代理简化了网络浏览体验，使查找相关信息，访问所需资源等变得更容易
- 缺点：打开新页面需要手动激活插件，这点无法自动化，看起来是否可以通过启动一个客户端来完成
- 原则：
   - 面对的是有形的具体的上下文
   - 自然语言的反馈
   - 工具支持增强
- “代理”是指直接或与工具与环境交互的系统或模型。通常，这是一个大型语言模型（LLM），提示采取行动或定制的中型模型。它遵循语言指令并通过预测用特定参数激活API函数的令牌来预测操作。
- 通常，LLM在语言理解和产生方面具有很强的能力，尤其是遵循指示，计划和推理，因此可以提示作为代理的政策网络，以执行一系列任务
- 本质上，Tool是Environment的组成部分，提供了一个快捷方式，该快捷方式封装了一系列操作以易于访问。例如，Serpapi是一种简化了在Google上搜索的用户过程的工具。
- In-context Human Feedback (内在的人类反馈)机制是X-lang最关键的特性，有两个好处：
   - 协助人物完成，因为用户是最了解人物的，需要用户的反馈
   - 更深的人物探索，用户的目标是随时会变化的
- 架构和技术
   - Agent
      - 基于LangChain中的ReAct
      - LangChain的不足之处
         - 工具还是不够用
         - 控制台输入已经不够用，需要更多的界面反馈
         - 相同的信息（例如，LLM上下文）通常需要根据情况不同而以不同方式表示
         - LangChain中当前提示设计的两个主要问题：一是过分依赖工具导致的代理响应不一致性，二是提示中包含的特定短语可能对用户界面的友好性和视觉吸引力产生负面影响。
   - Environment
      - 环境的实现在很大程度上依赖于目标代理的行动空间。
      - 实际上，代理通过使用不同的工具范围和组合来适应它们的场景
      - 浏览器扩展可以对网站进行自动探索和导航
   - In-context Human Feedback
      - 两个关键部分组成：
         - 前端交互界面：[https://github.com/mckaywrigley/chatbot-ui](https://github.com/mckaywrigley/chatbot-ui) Chatbot-ui基础上增加了一些新功能
         - 内存：当前端获得人类输入时，它将其作为LLM历史上下文的组成部分转移到代理的内存中
- 我们的系统根据个人用户需求智能自动选择最佳插件。
- 想象一个工具，可以通过随着时间的推移而提高的效率和准确性来复制人类互动。这是Web Agent的本质。
   - 一个稳定的框架，目前并没有开源
   - LLM不仅仅是沟通
   - 不仅仅是页面导航
- 工作流：
   - 聊天代理
   - 网页导航代理
- 愿景
   - Web Agent的变革潜力是无限的
   - 当我们拥抱未来时，网络代理不仅旨在成为助手，而且是对自己的数字扩展。数字领域将不再令人生畏。有了Web代理，一切都在障碍范围内。

![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706762493420-c3094bbd-d046-4492-b2d8-77cc012a6bbc.png#averageHue=%23f6f7f8&clientId=ucb69abe3-1759-4&from=paste&height=458&id=ua9e2fb6c&originHeight=916&originWidth=1539&originalType=binary&ratio=2&rotation=0&showTitle=false&size=202936&status=done&style=none&taskId=ua5878bcf-ff6a-4a44-acfc-a2f0f33b41b&title=&width=769.5)

# 20240201 Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception
[https://github.com/X-PLUG/MobileAgent](https://github.com/X-PLUG/MobileAgent)

- Introduction
   - 纯视觉，独立于XMl和系统元数据
   - 无限制的操作行为，跨多应用
   - 多种视觉感知工具用于操作本地
   - 不需要探索，训练，插入和播放
- 在感知非英语屏幕截图时，GPT-4V将会产生严重的幻觉
- Mobile-eval是一种旨在评估移动设备代理性能的基准。该基准包括10个主流单应用方案和1个多应用方案。
- Grounding DINO的信息，它是一个与目标检测相关的项目，使用PyTorch实现，并提供了预训练模型。该项目的重点包括与语言结合的目标检测、零标注训练、图像分割等。
- ![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706754829821-5065739e-ae66-4914-a29b-c80e5a102ab0.png#averageHue=%23a7b5c0&clientId=uc884cdce-41de-4&from=paste&height=512&id=u0aa05777&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=916566&status=done&style=none&taskId=u35e055bc-ed43-4345-bad5-99a32e3361c&title=&width=512)
- ![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1706754848111-988a83e3-9762-4a64-8fd5-6191900a5516.png#averageHue=%23c87d42&clientId=uc884cdce-41de-4&from=paste&height=448&id=u5e9b9ca4&originHeight=896&originWidth=2953&originalType=binary&ratio=2&rotation=0&showTitle=false&size=881990&status=done&style=none&taskId=u302f65ea-9f2f-4903-a144-5a4511f495d&title=&width=1476.5)
