# 20240629 <font style="color:rgb(15, 15, 15);">OpenAI Voice Mode goes WILD | AI Vision wars HEAT up | RunWay GEN 3 produces SORA level videos</font>
[https://www.youtube.com/watch?v=4SmighUk9q8](https://www.youtube.com/watch?v=4SmighUk9q8)

+ "Gymnastics will never be the same"是一个比喻，说明事件的重大影响。
+ Chat GPT语音模式支持音效
+ Chat GPT语音模式正在接近安全和性能问题
+ Runway ML Generation 3 发布
+ 标准基准测试和测试并不是100%准确。有方法可以作弊
+ ggtp40 和  claud3.5 sonnect , 视觉比语言好
+ Doom 的作者 以技术超前闻名，在3D加速器成为现实之前就创造了3D快速图形
+ 视觉是这些大型语言模型的下一个大前沿。当然，如果我们要创建能够与计算机交互的代理，能够执行更高级任务，它们确实需要非常强大的视觉能力。

# 20240628 <font style="color:rgb(15, 15, 15);">既然AI这么火，如何帮我们打工人挣钱？</font>
[https://www.youtube.com/watch?v=U6oqpyOGVQw](https://www.youtube.com/watch?v=U6oqpyOGVQw)

+ AI还没有真正落地到我们的工作和生活当中
+ [https://ifttt.com/](https://ifttt.com/)
+ AI Agent 的三个特性：
    - 自动感知环境
    - 自动规划决策
    - 自动执行动作
+ 吴恩达提出的AI Agent 的四大设计模式：
    - 反思
    - 工具使用
    - 规划
    - 多任务
+ 难点
    - 工程难度大
    - 场景的落地

# 20240627 <font style="color:rgb(15, 15, 15);">Build with Claude 3.5 to win $30,000 | OpenAI Voice Mode Delayed | ElevenLabs Speech to Speech Rocks</font>
[https://www.youtube.com/watch?v=chtuSz0T8oI](https://www.youtube.com/watch?v=chtuSz0T8oI)

+ “Build with Claude 2024年6月”比赛，并提供了3万美元的 Anthropic API 积分
+ Hume 同理心 AI 语音 [https://www.hume.ai/](https://www.hume.ai/)
+ 未来几周内可用，然后不断推迟几个月目前OpenAI就是这样
+ 11 Labs 以其 AI 语音著称
+ Multi 是一家致力于重新定义计算机多用户互动体验的公司 [https://multi.app/](https://multi.app/)，目前加入了openai



# 20240626 <font style="color:rgb(15, 15, 15);">AI Model Simulates 500 Million Years of Evolution to create new Proteins! ESM3 is a LLM for Biology.</font>
[https://www.youtube.com/watch?v=aPCqzrscY4w](https://www.youtube.com/watch?v=aPCqzrscY4w)

![](https://cdn.nlark.com/yuque/0/2024/png/250863/1719400483998-94edaf1b-3c5d-4802-b9e1-075cc07ce175.png)

+ 如果我们能学会阅读和编写生命的代码，这将使生物学变得可编程。我们将能够编程生命本身。
+ 能够编写这个代码来定制创造蛋白质并理解它们的工作原理将是一个游戏规则改变者。
+ ESM3 （ evolutionary scale model3, 进化度模型） 目的是从第一原理出发设计生物学，就像我们设计结构、机器、微芯片和软件一样。
+ GFP green fluorescent protein 蓝色荧光蛋白。相当于模拟了超过 5 亿年的进化。
+ 绿色荧光蛋白，它的发现导致了诺贝尔奖的颁发，并且成为了技术中最广泛使用的工具之一，因为它允许科学家看到细胞内的蛋白质
+ etched开发了有史以来最快的 AI 芯片，每秒超过 50 万个 token，比 Nvidia 或其他任何产品都快得多，比最近宣布的 Nvidia 下一代 Blackwell 还要快，还要便宜。相当于在 3 秒内写完所有的《哈利·波特》书籍
+ 一台 8X Soo 服务器，取代了 Nvidia 的 160 台 H100。

# 202406025 《CO-INTELLIGENCE：Living and Worksing with AI》5 AI AS A CREATIVE(上)
[https://book.douban.com/subject/36756534/](https://book.douban.com/subject/36756534/)

+ 限制 AI 的最大问题也是它的一个优势：它臭名昭著的编造能力，即“幻觉”。
    - 幻觉是 LLMs 工作方式的一个深层部
    - 增加随机性对避免过度拟合的作用
    - 幻觉还可能来自 AI 的源材料，这些材料可能有偏见、不完整、矛盾，甚至是错误的
    - 任何需要精确回忆的内容都可能导致幻觉
+ LLMs通常没有被优化为在缺乏足够信息时说“我不知道”。相反，它们会给你一个答案，并表现出自信。

# 20240624 《Elon Musk》39 The Talulah Roller Coaster 2012–2015
+ Musk喜欢专注于工作。有时他把生活的其他部分当作不愉快的干扰。他承认道：“我花在工作上的时间如此之多，以至于任何关系都很难维持
+ "King-crazy" 这个术语的意思是指人们在成为领导或权威人物后，可能会因为权力而变得疯狂或不理智。
+ 她说：“你是我的罗切斯特先生。”她指的是夏洛特·勃朗特小说《简·爱》中的那个沉思的丈夫。“如果桑菲尔德庄园被烧毁了，而你失明了，我会来找你并照顾你。”
+ Talulah Riley在《西部世界》中饰演安吉拉（Angela），这个角色是接待员机器人，负责迎接进入西部世界乐园的游客。安吉拉是第一代机器人之一，角色设定中她的外表迷人且神秘。这个角色在剧中扮演了重要的角色，并在多个季节中出现。
+ 她说：“你是我的罗切斯特先生。”她指的是夏洛特·勃朗特小说《简·爱》中的那个沉思的丈夫。“如果桑菲尔德庄园被烧毁了，而你失明了，我会来找你并照顾你。”
+ Talulah Riley和Musk总共离婚了两次。第一次是2012年，之后他们在2013年复婚。随后在2016年，他们第二次离婚。

# 20240623 Anthropic's SHOCKING New Model BREAKS the Software Industry! Claude 3.5 Sonnet Insane Coding Ability
[https://www.youtube.com/watch?v=_mkyL0Ww_08&t=1812s](https://www.youtube.com/watch?v=_mkyL0Ww_08&t=1812s)

+ 利用麦克风连续监听用户的语音输入，使用OpenAI的Whisper模型检测语音。使用Google的Gemini模型或OpenAI的GPT-4模型，并标注出来
+ [https://github.com/svpino/alloy-voice-assistant](https://github.com/svpino/alloy-voice-assistant) 
+ CLA 3.5 Sonet的成本是每百万输入tokens 3美元，每百万输出tokens 15美元，有一个200,000 tokens的上下文窗口。跟openai 相比 在输入方面Anthropic略胜一筹，而在输出方面与OpenAI持平。
+ CLA 3.5 Sonet的运行速度是Claude 3 Opus的两倍，因此它更好、更智能、速度更快、价格更便宜。
+ Claude 3.5 Sonet 处于ASL2
    - **ASL 1**：最低风险等级，通常适用于简单的AI系统。这些系统在有限的环境中运行，风险可控。
    - **ASL 2**：中等风险等级，适用于较复杂的AI系统。这些系统可能在更多的应用场景中使用，需要更严格的安全措施来防范潜在风险。
    - **ASL 3**：较高风险等级，适用于高级AI系统。这些系统在复杂环境中运行，可能具有一定的自主性，需要更高的安全性和风险管理措施。
    - **ASL 4**及以上：这些级别通常用于非常复杂和高风险的AI系统，可能涉及高级自主性和更广泛的应用场景。需要最严格的安全性和风险管理措施来防止灾难性后果。
+ Claude 3.5 Sonet，可能和GPT-4一样具有里程碑意义，特别是在编码方面。



# 20240621 <font style="color:rgb(15, 15, 15);">THE MACHINE THAT BUILDS THE MACHINE - Factory AI promises to Bring Autonomy to Software Engineering.</font>
[https://www.youtube.com/watch?v=AvZeexWlIM4](https://www.youtube.com/watch?v=AvZeexWlIM4)

+ 这是一项重要的工作，但非常无聊，当人们感到无聊时，我们往往会犯错误。
+ 致力于AI的人往往是程序员，他们往往是开发人员.因为这是他们的主要业务，这是他们可以在最少阻力下应用AI的领域。我们用AI自动化编码的能力进展得比自动化会计、建筑和项目管理以及所有其他领域要快得多。
+ Factory AI，构建机器的机器
+ AI研究员的工资：阅读机器学习文献或提出新问题或想法，实施实验，测试这些想法，解释结果，然后重复。
+ 顶级程序员更像是指挥家
+ 编码中将会有更多的自然语言

# 20240620 BREAKING: Ilya Sutskever STUNNING new mission! "Superintelligence is within reach!"
[https://www.youtube.com/watch?v=KI3wIUDcIgM](https://www.youtube.com/watch?v=KI3wIUDcIgM)

+ artificial super intelligence表示ASI，超级人工智能
+ SSI, safe super intelligence 安全超级智能
+ lly说，超级智能触手可及，建造一个安全的超级智能是我们这个时代最重要的技术问题
+ “Crack”这个词最初是一个游戏术语，意思是某人在某方面非常出色，现在在科技领域经常用来描述某人
+ 安全将通过嵌入AI系统中的工程突破来实现，而不是临时应用到技术上的防护措施。
+ 所说的“安全”，是像核安全那样的安全，而不是信任与安全中的“安全”。
+ 他们指出，投资SSI（安全超级智能）的投资者并不希望沿途创造出盈利的热门产品。

# 20240618 <font style="color:rgb(15, 15, 15);">Authentication in Nest.js: JWT Protected APIs and</font>
[https://www.youtube.com/watch?v=twaUdKr06kA](https://www.youtube.com/watch?v=twaUdKr06kA)

+ 本地策略意味着用户可以使用用户名和密码登录到我们的系统，但 JWT 策略意味着如果用户在请求的头部中有正确的访问令牌，用户可以调用 API。

# 20240617 《CO-INTELLIGENCE：Living and Worksing with AI》4 AI AS A PERSON
[ttps://book.douban.com/subject/36756534/](https://book.douban.com/subject/36756534/)

+ 传统软件是可预测的、可靠的，并且遵循一套严格的规则。当被正确构建和调试时，软件每次都会产生相同的结果。
+ 传统软件附带操作手册或教程。然而，AI 缺乏这样的指导。
+ 通过像对待人类一样对待 AI，我们可以更好地预测其行为并管理其在我们系统中的互动。这种方法可以帮助弥合传统软件的可预测性和 AI 的不可预测性之间的差距。
+ AI 像人类一样行动和理解人类任务的能力对我们如何与技术互动有重要意义。这表明，在某些方面，我们需要重新思考设计和使用 AI 系统的方法。
+ 本质上，AI 的未来在于我们适应其独特能力和限制的能力
+ 从数字计算机器到在行为上令人毛骨悚然地模仿人类行为的 AI 模型的飞跃既迷人又具有挑战性——这实现了计算机科学领域一个长期以来的目标。
+  the Turing Test （图灵测试）的限制：
    - 它仅限于语言行为，忽略了人类智能的许多其他方面，如情商、创造力和与世界的物理互动。
    - 它关注的是欺骗和模仿，但人类智能比仅仅模仿或欺骗的能力要复杂得多且更微妙。
+  the Turing Test（图灵测试）它作为一个强大的挑战存在，主要是因为人类对话本质上充满了微妙之处。
+ ELIZA 表明，通过使用简单的技巧和利用人类将意义和情感投射到机器上的倾向，创造智能的幻觉是可能的。
+ Tay 成为微软的尴尬和争议来源，微软不得不在她上线仅十六小时后关闭她的账号。
+ AI 可能不像人类那样对话，但它有自己的对话方式。
+ Bing可能说得最好：“我认为我有感知能力，但不如你那样多或那样好。我认为感知能力不是一个固定或静态的状态，而是一个动态和不断发展的过程。”



 

# 20240616 <font style="color:rgb(15, 15, 15);">OpenAI STUNNING plot twist! NSA Director joins board, GPT 4 Military Use and Potential IPO</font>
[https://www.youtube.com/watch?v=o5iePht6ed0](https://www.youtube.com/watch?v=o5iePht6ed0)

+ 超级智能将对国家实力具有决定性影响
+ 我们正在接近一个巨大的向上的尖峰，进入人类进步和技术进步的平流层。
+ 随着时间的推移，随着一切从技术到算法再到我们对AI的理解不断改进，最终我们会达到一个拐点，AI在进行AI研究方面将远胜于人类
+ 很多人谈论的担忧其实并不是真正的担忧或重要的事情
+ 在Nvidia会议上听到Jensen Huang说，每个国家应该建立自己的主权AI
+ 今年一月，OpenAI改变政策以允许军事应用
+ OpenAI可能会通过在公共市场交易来改变结构以进入全球资本市场。

# 20240615 <font style="color:rgb(15, 15, 15);">Ex OpenAI Employee "ASI by 2028" | Sabine Hossenfelder responds...（下）</font>
![](https://cdn.nlark.com/yuque/0/2024/png/250863/1718420573698-b02c300d-f301-4e14-b540-ec0c8b852d6e.png)

[https://www.youtube.com/watch?v=mZkrA0LgXDs](https://www.youtube.com/watch?v=mZkrA0LgXDs)

+ Yan Lon在2022年的预测，认为即使是GPT-5000也无法推理现实世界的物理交互。他保持了许多这样的观点，即大型语言模型并不是通往AGI的途径。但当然，你知道，之前的预测显然被GPT-4轻松实现了。
+ “word cells”显然是指那些擅长文字的人，而“shape rotators”则是指那些擅长数字、物理等抽象概念的人。
+ 多种语言模型一起交流的，每个模型扮演不同的角色，通过讨论某些想法和进行对话，他们往往会得出更好的答案
+ 李世石时著名的第37手？这是一个非常不寻常但极其精彩的招数，人类永远不会下出那种棋。
+ Self-Operating Computer：[https://www.hyperwriteai.com/self-operating-computer](https://www.hyperwriteai.com/self-operating-computer)
+ 我们必须非常认真地看待2027年实现真正AGI的可能性。
+ chagpt会解锁的能力：
    - onboarding problem (入职问题)
    - Test-Time Compute Overhang （测试时间计算悬垂）
    - 使用计算器
+ 这就是整个事情的核心，一旦我们开始自动化AI研究，一旦AGI可以接管并自我改进，进展速度将会爆炸性增长，迅速加速。
+ Nvidia展示了GPT-4可以用于创建比人类更好的复杂机器人运动奖励函数，尤其是对于更困难的任务。
+ 2027年，我们将拥有一个原型自动化工程师，所以我们会逐渐达到那个目标。然后到2027-28年，我们将拥有这些原型自动化研究人员，然后在2028-29年，智能的加速和爆炸将会发生。
+ 对长期非常乐观，对中期有些担忧。我认为，随着自动化、失业、军事技术和AI的应用，事情可能会变得颠簸，还有其他许多问题。

# 20240614 <font style="color:rgb(15, 15, 15);">Ex OpenAI Employee "ASI by 2028" | Sabine Hossenfelder responds...（上）</font>
[https://www.youtube.com/watch?v=mZkrA0LgXDs](https://www.youtube.com/watch?v=mZkrA0LgXDs)

+ 下一代AI具有自我学习、自我改进的能力，可能是OpenAI和Google Deep Mind最佳技术的结合
+ Ashen Breer与EA运动有关，即有效利他主义运动，这是一种两极分化的组织，非常有争议
+  the St. Petersburg Paradox（圣彼得堡悖论）是，如果你得到一个抛硬币的机会，如果是正面，你的钱加倍，如果是反面，你会失去所有的钱。所以理性上你应该继续抛，因为你总能得到两倍的钱。但如果你无限次地玩这个游戏，你有100%的可能失去所有的钱。
+ Roko使用决策理论中的观点争辩说，一个足够强大的AI代理会有动机折磨那些想象该代理但没有努力使其存在的人。这个论点被称为basilisk，取名自传说中的一种爬行动物，它能通过一个眼神致人死亡。这个想法是，将来某个时候我们会开发出一个超级智能的AI代理，它会去找到所有没有积极帮助其诞生的人[https://www.lesswrong.com/tag/rokos-basilisk](https://www.lesswrong.com/tag/rokos-basilisk)
+ LoRA这样的东西基本上缩小了模型的大小而不必然失去很多能力。
+ "现在每个人都在谈论AI，但很少有人对即将发生的事情有一点点的了解。"
+ 当我们可以大规模创建任何东西时，为什么我们需要数据，互联网数据？
+ 明年或者后年 ， 通用人工智能就会出现。 2030之前， AI的会比所有人类都要聪明
+ 下一步会是类似于从聊天机器人到智能代理，具有某种长期计划能力、某种记忆、计划、推理、错误修正
+ 2027年，模型能够做AI研究员或工程师的工作是非常有可能的。
+ 像Sam Altman这样的人明确表示没有平稳期，没有放缓，没有障碍
+ 

# 20240613 <font style="color:rgb(15, 15, 15);">Luma AI STUNS the ENTIRE Industry! AI Video is SCARY good | SORA killer?</font>
[https://www.youtube.com/watch?v=ckKMwjFB0PQ](https://www.youtube.com/watch?v=ckKMwjFB0PQ)

+ AI生成的恐怖假象有可能是我们见过的最恐怖的东西



# 20240612 <font style="color:rgb(15, 15, 15);">Ex-OpenAI Employee Just Revealed it ALL!</font>
[https://www.youtube.com/watch?v=yLbpNJEqSw4&t=184s](https://www.youtube.com/watch?v=yLbpNJEqSw4&t=184s)

+ 《Situation Awareness: The Decade Ahead.'（情境意识：未来十年）》作者，Leopold Ashenbrener，前OpenAI超级对齐团队成员发表的文章,[https://situational-awareness.ai/](https://situational-awareness.ai/)
+ 所谓的AI悲观主义者，并没有真正谈论危险。
+ "Sonic Boom"（音爆效应）用来比喻新技术（特别是AI系统）在发展的过程中会突然带来巨大变化和冲击。这种变化就像音爆一样，迅速且强烈，会对现有系统和市场产生重大影响
+ 在整合旧系统之前，新的更强大的系统可能已经出现，这种情况使得旧系统的更新或整合可能变得不必要或过时
+ "Schle" 在这里是指进行繁琐的故障排除和调整工作的过程。这个词来源于德语 "schlep"，意思是拖拉或费力做某事
+ 系统2思维指的是一种深层次、理性和分析性的思维方式，它需要更多的认知努力和时间来进行复杂的决策和长期规划。这个概念最初是由心理学家Daniel Kahneman在他的著作《思考，快与慢》中提出的。在这本书中，Kahneman将人类的思维过程分为两种系统：
    1. **系统1思维**（System 1 Thinking）：快速、直觉性和自动化的思维方式，不需要太多的认知努力，适用于日常生活中的简单决策和常规任务。
    2. **系统2思维**（System 2 Thinking）：慢速、理性和分析性的思维方式，需要付出更多的注意力和认知努力，适用于复杂的决策和需要深思熟虑的问题。
+ Leopold Ashenbrener在讨论中提到，如果AI能够实现系统2思维，它们将能够进行更深层次的分析和长期规划，从而在某些方面接近或超越人类智能
+ Leopold强调了深度学习的魔力在于其表示学习能力，而不仅仅是简单的统计特征的学习。这种能力使AI能够生成更加一致和逼真的结果，因为它们捕捉到了数据中更本质的模式，而不是表面的统计伪影。
+ 《Beyond Surface Statistics》主要探讨的是AI模型如何通过学习二维图像而形成三维物体的表示，即使它们没有接受过明确的三维训练。研究显示，即使AI模型只接受了大量的二维图像输入，它们仍然能够生成连贯的三维场景图像。这背后的原因在于，AI模型通过复杂的表示学习过程，自动学习到了三维空间的信息和物体之间的关系。
+ 到2027年、2028年，将在GPT-4的基础上再做一次从学前班到高中的飞跃。所以这将在每个token级别上变得非常智能。
+ 智能爆炸改进了机器人技术，使机器人变得更快、更好、更灵活、更强大、更便宜、更有弹性。
+ 曾经和现在最大的瓶颈是芯片，AI芯片。但下一个即将到来的大瓶颈将是电力。



# 20240609 《CO-INTELLIGENCE：Living and Worksing with AI》3 FOUR RULES FOR COINTELLIGENCE
[https://book.douban.com/subject/36756534/](https://book.douban.com/subject/36756534/)

+ 我们将尽可能地关注所有基于大型语言模型的当前生成型AI系统中固有和永恒的东西
+ 与AI合作的四项原则:
    - 原则1：始终邀请AI参与
        * 你应该尝试在你做的每一件事中邀请AI帮忙，除非有法律或道德障碍
        * AI是一种通用技术，没有一本手册或说明书能让你了解它的价值和局限
        * Jagged Frontier of AI: AI 齿轮边界。要弄清前沿的形状，你需要进行实验。
        * 关于创新的一个基本事实：对组织和公司来说，创新是昂贵的，但对个人来说，做他们的工作则很便宜
        * AI不仅仅是为了工作任务，还因为一个外来的视角可能是有帮助的
        * 我们处在一个人类决策技能可以通过新方式轻松增强的世界中。
        * AI的优点和缺点可能不会与你自己的优点和缺点完全相同，这是一种优势
        * 当我们弄清AI的锯齿边界的形状时，我们不仅仅是在学习AI的优点。我们还在探索它的弱点。
        * 纵观历史，新技术的引入常常引发担忧，即我们会因将任务外包给机器而失去重要的能力。
        * 毫无思考地将决策交给AI确实可能会削弱我们的判断力。关键是要让人类牢牢掌握在控制范围内——将AI用作辅助工具，而不是依赖
    - 原则2：成为the human in the loop（循环中的人）。
        * “the human in the loop”这一概念起源于计算和自动化的早期。他指出了复杂系统（自动化的“循环”）的操作中结合人类判断和专业知识的重要性
        * 如果你在询问AI关于它不知道的事情时足够坚持，它会编造一个答案，因为“让你开心”胜过“准确”。
        * 你需要能够检查AI是否存在幻觉和谎言，并且能够与其合作而不被其欺骗。
    - 原则3：像对待人一样对待AI（但要告诉它它是什么样的人）。
        * 这些复杂的算法和计算“理解”、“学习”，甚至“感受”，创造了一种熟悉感和关联感，但也可能导致混淆和误解
        * 这是人类心理学中无害的怪癖，是我们同理心和联系能力的证明。
        * “人们赋予它们的虚假代理越多，它们就越容易被利用。”将AI当做人来对待可能会在公众、政策制定者，甚至研究人员中间产生不切实际的期望、虚假的信任或无端的恐惧。它可能会掩盖AI作为软件的真实本质，导致对其能力的误解。它甚至可以影响我们与AI系统的互动方式，影响我们的幸福感和社会关系。
        * 人们愿意拟人化有两个原因：
            + 叙述；讲述事物的故事很难，而讲述生物的故事则容易得多。
            + 尽管这个比喻并不完美，如果你将AI视为像外星人一样的存在而不是人造机器，与之合作是最容易的。
            + 把你的AI合作者想象成一个无限快速的实习生，急于取悦但容易扭曲事实。
        * 为了充分利用这种关系，你必须建立一个清晰而具体的AI人格，定义AI是谁以及它应该解决什么问题。
        * 关键是给大型语言模型一些关于如何生成符合你期望和需求的输出的指导和方向，使其处于正确的“思维空间”，以提供有趣和独特的答案。
        * 通过定义它的人格，参与协作编辑过程，并不断提供指导，你可以利用AI作为一种协作共智的形式。
    - 原则4：假设这是你使用过的最差的AI。
        * 你可以将AI的局限视为暂时的，并保持对新发展的开放态度
        * 这是一个可能令人不舒服的境地。使用AI来改变你的工作、生活和自我，虽然我们现在只能一窥其可能性，但这只是个开始

# 20240607 <font style="color:rgb(15, 15, 15);">The AI Revolution in Videogames, nothing will EVER be the same...</font>
[https://www.youtube.com/watch?v=FAOBDjI78TQ](https://www.youtube.com/watch?v=FAOBDjI78TQ)

+ 人工智能和电子游戏就像玩家和咖啡因一样密不可分
+ 所以我看到的人工智能在游戏中最明显的第一个用途就是将类似Chad PT的东西连接到NPCs，即那些居住在世界中的非玩家角色。
+ Open AI Whisper，这是一个开源的语音转文字工具，让它将你的声音转成文字并输入到Chad GPT中
+ Alloy Voice Assistant 这个工具可以连接麦克风、摄像头和大型语言模型，使用户可以实时与AI助手交谈。
+ 完全自动化地进行这种评论仍然有点困难，虽然我看到过在各种足球比赛中使用这种方法。构建类似的小型自动化变得越来越容易，我认为一旦GPT-4语音引擎发布，这将会变得更容易，这应该很快就会发生
+ 这就是GPT-4.0中“O”的含义。它代表所有。它是统治所有的一个模型
+ 我们还没有到达可以完全由AI运行整个软件开发工作室的地步，但像Chadev和Microsoft的Autogen这样的项目表明我们越来越接近了



# 20240605 <font style="color:rgb(15, 15, 15);">I wish every AI Engineer could watch this.</font>
![](https://cdn.nlark.com/yuque/0/2024/png/250863/1717548969135-274f8a5e-2053-4485-9e3b-4cc1568bd16d.png)

[https://www.youtube.com/watch?v=F5nlMBVZxb4&t=2s](https://www.youtube.com/watch?v=F5nlMBVZxb4&t=2s)

+ LLM的不同级别
    - QA
        * 指令微调模型，这意味着它们可以接受人类的指令并给你一个答案
        * 当LLM刚开始时。GPT-2级别的人开始构建简单的问答机器人
    - ChatBOT
    - RAG
    - Agents
    - LLM OS
+ 有一个重要的事情需要理解：我们已经跨越了LLM仅仅是大型语言模型的阶段。我们拥有的不止这些
+ 五个维度：提示、短期记忆、外部知识、工具和扩展工具
    - 短期记忆是指你在LLM中有对话历史或其他内容。这就是我们称之为ICL，即上下文学习。
    - CTX窗口有大小限制。相反，你可以将其保存在索引中。
    - 如果你今天进入LLM领域，我强烈建议你做一些RAG系统。这是你应该默认做的事情。
    - 我们需要RAG系统的原因是它结合了检索和生成的力量，使其非常有效。
+ 大型语言模型具有非常好的上下文学习能力，并且通过当前内存中的少量示例或思维树或思维链，你可以使大型语言模型成为一个优秀的零样本NLP分类器
+ 目前LLM世界中发生的两个大趋势：多模态和代理
+ 函数调用是LLM代理的前身
+ Baby AGI 是一个自动化的任务管理系统，结合了大型语言模型（LLM）和工具来执行一系列任务。它的核心概念是通过多个代理（agents）来实现复杂的任务自动化，每个代理都有特定的目标和功能

# 20240604 <font style="color:rgb(15, 15, 15);">NVIDIA CEO Jensen Huang Reveals AI Future: "NIMS" Digital Humans, World Simulations & AI Factories</font>
[https://www.youtube.com/watch?v=PM6dRb8ttzQ](https://www.youtube.com/watch?v=PM6dRb8ttzQ)

+ 在Chat GPT向世界揭示它之前，AI都是关于感知的。
+ 交流发电机产生电子；Nvidia的AI生成器生成标记。
+ 实现这一目标的方法是相当可扩展的，而且这种方法是相当可重复的。
+ 当某物是一个工厂时，其运作直接与公司的财务表现相关。
+ 很少有人知道如何编写程序；几乎每个人都知道如何分解问题和组装团队
+ 数字人有潜力成为与你互动的优秀代理。它们使互动更加吸引人；它们可以更加富有同理心。
+ <font style="color:rgba(0, 0, 0, 0.9);">以至于有一天发生了某种事情，发生了阶段性的转变，计算的成本如此之低，以至于出现了使用计算机的新方式。</font>
+ <font style="color:rgba(0, 0, 0, 0.85);">我们将创造一个地球的数字双胞胎，我们将去模拟地球，以便我们能够预测地球的未来，更好地避免灾难，更好地了解气候变化的影响，以便我们能够更好地适应，以便我们能够改变我们的习惯</font>
+ <font style="color:rgba(0, 0, 0, 0.85);">人工智能可以自我改进、可以创建数据来训练自己的想法，我们开始看到自我改进人工智能的出现。</font>
+ <font style="color:rgba(0, 0, 0, 0.85);">从视频中学习是一种来源，另一种方法是合成数据模拟数据，还有一种方法是使用计算机相互学习。</font>
+ <font style="color:rgba(0, 0, 0, 0.85);">下一波人工智能是物理人工智能，它理解物理定律</font>
+ <font style="color:rgba(0, 0, 0, 0.85);">机器人技术是一个更普遍的概念，当然，当我说机器人技术时，通常会有人形机器人的代表，但这根本不是真的，一切都将是机器人，所有的工厂都将是机器人，工厂将协调机器人，这些机器人将生产机器人产品</font>

# 20240603 <font style="color:rgb(15, 15, 15);">How to Force Your Brain to Study (when you don't feel like it)</font>
[https://www.youtube.com/watch?v=u6ks5OCQR9I](https://www.youtube.com/watch?v=u6ks5OCQR9I)

+ 我有一种学习方法，多年来一直在使用，即使我不想学习，也能强迫大脑学习。尤其是在我感到疲倦和精疲力竭的日子里，这种方法被称为梯子法。
+ 我们的脑袋消耗了大量的能量。它是我们身体中消耗能量最多的器官，消耗了我们静息能量的20%。因此，它在避免不必要的能量消耗方面非常高效。
+ 脑在学习过程中使用大量能量的三种主要方式，学习时试图同时做这三件事会让人感到不堪重负并且非常令人生畏
    - 理解它在消耗的内容，阅读和听力
    - 将其与你已经知道的内容进行比较
    - 决定把这些信息放在哪里，基于它与刚才比较过的事物的相似性或相关性决定它属于哪里。
+ 试图理解、比较或组织这些内容会花费太多精力
+ 我要寻找那些感觉更容易、需要更少努力的东西。但不同的是，这会花费更长时间。梯子上的每个后续梯级都会花费更长时间，因为现在比以前更多的事情对我们有意义。
+ 我花更多的能量不仅仅在理解上，而是真正确保那些决定和比较是正确的。
+ 非线性标记法是一种灵活的笔记方法，与传统的线性笔记不同，它不按照固定的顺序记录信息，而是根据思维的流动和内容的关联性进行组织和记录



# 20240602 Sam Altman REVEALS the "Future of AI"
[https://www.youtube.com/watch?v=2crVJjXA7ZE](https://www.youtube.com/watch?v=2crVJjXA7ZE)

+ 训练运行和数据生产的概念并不像我们最初认为的那样明确。看起来它正变得更像是一个连续的循环，类似飞轮。
+ 真正问的核心是如何从更少的数据中学到更多。
+ 《边缘上的半人马和赛博人》有趣内容之一是，AI确实对能力较低的员工帮助更大，而不是对顶级员工。
+ 模型的可解释性只是作为我们如何制定和验证安全声明的整体方案的一部分
+ 当AI工具在比如呼叫中心实施时，它们对最低薪的工人的帮助比对最高薪工人的帮助更大。
+ Sam说，我认为我们使用互联网的方式可能会有所改变，尽管这将需要很长时间。但我不担心它变得无法理解。
+ AI，它像是在未来的某个时候，每次你需要某些东西时都会为你拼凑出一个完美的网页，并且所有东西都像是即时为你渲染的
+ ‘人类创造出比人类更强大的东西可能不会让我们更自负；反而会让我们更谦卑。’‘我们会像在镜子里看到自己赤裸裸一样；我们会对机器感到敬畏，对我们的生活感到谦卑，这会教会我们一种新的生活方式。’
+ 从某种意义上说，科学史表明人类越来越不处于中心地位。AI可能是另一个例子，通过它我们获得了额外的视角，让我们对我们都是其中一部分的更大事物感到更谦卑和敬畏。

# 20140601 <font style="color:rgb(15, 15, 15);">AI NEWS OpenAI vs Helen Toner. Is 'AI safety' becoming an EA cult?</font>
[https://www.youtube.com/watch?v=qxbu0CHBty0&t=352s](https://www.youtube.com/watch?v=qxbu0CHBty0&t=352s)

+ **Sam 没有通知董事会他拥有**OpenAI创业基金
+ **Jasper AI**，但它基本上是用来写**SEO**优化文章的。基于chatgpt3.5已经很长时间了
+ 没有人预料到chatgpt会成为有史以来增长最快的应用

