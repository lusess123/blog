# 20251122 How Industry Uses RAG in 2025 (8 Architectures with Code & Live Chatbot Demo)2
+ [https://www.youtube.com/watch?v=4_-SnxReJ4M](https://www.youtube.com/watch?v=4_-SnxReJ4M)
+ 所谓的 _corrective RAG_，简称 **CRAG**，是一种更“警惕”的检索增强生成方式，它在给出最终回答之前，会额外增加一个自我检查的步骤。
+ _corrective RAG_ 中，系统会在生成答案之前，先评估这些检索到的文档的“质量”和“相关性”。
+ 当“准确性”至关重要，或者“知识库可能不完整 / 不一致”的时候，_corrective RAG_ 就尤其有价值。
+ 找到一个“合适的相关性阈值”非常困难。阈值太严格会错过有用信息；太宽松又会让噪音混进来。
+ **上下文漂移（context drift）**。如果有多次纠正循环（multiple correction loops），而又没有正确过滤，反而可能引入噪音，使答案越来越偏离主题。
+ 现在几乎所有框架都提供了某种形式的“自我纠错”机制。本质上，它就像一张“安全网（safety net）”。

# 20251120 Grant Lee: Building Gamma’s AI Presentation Company to 100 Million Users 3
+ [https://www.youtube.com/watch?v=fBfY7tWCecU](https://www.youtube.com/watch?v=fBfY7tWCecU)
+ 有时候会出现某种形式的网络效应；同时，在网络效应这块，品牌本身也能变成一种“护城河”。
+ 当你有了这种自下而上的用户喜爱以后，就会出现这样的情况——用户开始教其他用户如何使用
+ 在我们刚起步的时候，团队内部基本就只有两条“口号”：**“让创作极度简单，让分享极度简单。”如果你做到这两点，你就把整个飞轮闭环了
+ “让产品天然具备传播性”必须是你做产品时最基本的出发点之一。
+ **“Hire painfully slowly（宁可痛也要慢慢招）。”**即使在高速增长阶段，我们也一直坚持这点。这让我们在取得如今这些成果的情况下，团队规模仍然保持相对精简。里面那个 **pain（痛）** 其实非常关键——你要先搞清楚：**这个组织现在真正“痛”的地方在哪里？**
+ 我们真正花心思在想的是：我们希望这最初的七个人，就是我们的 **MVP crew（最小可行团队）**。这个小队需要具备“从头到尾把一个产品做出来并交付出去”所需要的一切能力。
+ **Brian Chesky** 也说过类似的话——你一定要把最初的 10 个人，甚至最初的 100 个人“选对”。
+ 很长一段时间，团队里四分之一的人都是产品设计师
+ **Ben** 有一句特别棒的话，大概是十五年前说的，到现在都一点不过时：“如果你自己没干过这份工作，你怎么知道自己在招什么样的人？”
+ 如果对方连你都不如，而你又只是靠自己摸索才学会这些东西，那很大概率就不是一个合适的人选
+ 我们内部有一条价值观就是：**“不要无聊（don't be boring）。”**
+ **创始人有责任**去当那个品牌的“管家 / 守护者（steward）”。

# 20251118 Grant Lee: Building Gamma’s AI Presentation Company to 100 Million Users 2
+ [https://www.youtube.com/watch?v=fBfY7tWCecU](https://www.youtube.com/watch?v=fBfY7tWCecU)
+ 在产品这件事上，我们是那种“极端自家吃狗粮（dogfooding）”的团队
    - 每周都有一个叫 **Gamarama** 的内部活动，公司里任何人都可以用 **Gamma** 做一份有趣的演示，给大家“上课”，分享任何主题。
+ 定期把这些需求、想法做一个大致的“优先级排序”，挑出最重要的，推到产品路线图上去做
+ 千禧一代，几乎一直泡在 Instagram 上
+ Word of mouth（口碑），是唯一真正重要的指标。在你真正拥有强口碑之前，千万别骗自己，以为已经达到了 PMF。在做那些“砸钱动作”之前，必须先确保：我们的口碑是真的足够强。
+ 第一次 AI 发布前的三到四个月里，整个团队只盯着一件事。“我们要把产品体验的**前 30 秒**打磨到极致。”
+ 做 B2B的时候，你多半必须走 “founder sales（创始人亲自卖）” 这条路，你必须成为那个第一个真正知道如何讲清楚自己产品故事的人，然后你才能把这些方法传授给你的 **AEs（Account Executives，销售/客户经理）**，把他们顺利“拉上船”。
+ 大家其实都已经非常熟悉 **ChatGPT** 的定价，而且心理价位已经被它“锚定”了。
+ 从只剩 12 个月现金跑道，到 3 个月内实现盈利。当我们正式推出定价和套餐之后，大概只花了三个月，就做到接近 **100 万美元 ARR**，并成功整体转为盈利。
+ 战略，就是在一个人们真心喜爱的产品之上，去搭建整个业务。这句话本身的简单和清晰，其实非常“点醒人”，因为你真的可以把一切都浓缩成这一点。
+ 一方面有“自下而上的喜爱”，另一方面还有“**自上而下的需求（top-down demand）****，只有先赢得那种自下而上的喜爱，才有资格成为这种“默认标准”**。

# 20251116 Grant Lee: Building Gamma’s AI Presentation Company to 100 Million Users
![](https://cdn.nlark.com/yuque/0/2025/png/250863/1763293953261-a48d6b4e-2795-4f18-bed6-0e434587997e.png)

+ [https://www.youtube.com/watch?v=fBfY7tWCecU](https://www.youtube.com/watch?v=fBfY7tWCecU)
+ 2020 年底，正好处在疫情最严重的高峰期，基本所有的融资都是在 **Zoom** 上远程完成的
+ 如果我们还想有哪怕一点成功的机会，那产品和增长这两件事，就必须在战略层面紧紧绑在一起。
+ “要快、要高效”是我们的产品愿景属性。**AI** 几乎像一份天降的礼物，极大地加速了我们整个实现这个愿景的过程。
+ David Kelly，第一只 Apple 鼠标发明人，他把当时的三键鼠标做成了一键鼠标： 你必须对用户所处的状态极度共情。
+ 我们现在大概处在 AI 的“一键时代”。
+ 如何应对“前 AI 时代”的产品的2个陷阱？
    - 他们只是在现有“幻灯片软件”的基础上做一点点小改进。但是，“不一样”比“更好一点”更关键。所以对我们来说，我们想做的是“从底层就不一样”：去思考有哪些完全不同的“原子组件 / 积木模块”。
    - 作为一家“AI 原生”的创业公司，你会非常依赖那些 AI 模型本身，默认这些模型会越来越强（这点没错），但它们反而会变成你的拐杖。这里面的挑战是，在大模型搞定一切之前，如何做一个‘中间形态’，既能给用户一个很好起点，又能让人类持续参与其中
+ 为什么不怕被巨头的超级AI应用颠覆？
    - 作为创作者，你必须感觉到自己在里面有很大的话语权和参与度。你会希望深度参与这个过程，因为你讲的是“自己的故事”，而不是“AI 的故事”。这里面有好多事情，比如多人协作，素材管理
    - 理论上超级应用也可以做这些事情，但如果它真这么做，就会开始一点点偏离自己的主线。它们不得不牺牲掉很多这种细颗粒度的垂直解决方案，因为这些东西未必符合它们的长期蓝图。
+ 回到 **Gamma** 这个产品最基础的出发点，很多洞见也来自于这样一个事实：我们几乎都是“偏视觉的学习者”，但真正“有视觉设计背景”的人其实非常少
+ 这是一件挺严重的事——如果人们无法好好地表达自己的想法，那就意味着，这些想法永远走不出他们的脑袋。也许可以用 **AI avatars**，或者让演示文稿本身“开口说话”，用你的声音替你把想法讲出来。
+ Gamma 希望做的是从 **inkling of an idea → narrative / story arc → outline → first draft → 设计 / 编辑 agent 搭档 → 分享 & 反馈 loop → 迭代优化** 的 **end-to-end** 全链路工具。
    - 

# 20251115 How Industry Uses RAG in 2025 (8 Architectures with Code & Live Chatbot Demo) 1
+ [https://www.youtube.com/watch?v=4_-SnxReJ4M](https://www.youtube.com/watch?v=4_-SnxReJ4M)
+ 所谓标准 RAG（有时也叫“**naive RAG**”）和带记忆的 RAG 之间，唯一的区别只是我们给 RAG 聊天机器人额外加了一个记忆组件。
+ 你可以把它想象成：先请图书管理员帮你找几本与问题相关的书，再让一位专家把这些书读一遍，然后用自己的话来回答你。
+ Standard RAG： 因为足够简单被称为naive RAG
+ Conversational RAG： AI 每次回答时就不再是“从零开始”，而是会回顾之前聊过的内容，从而给出更连贯、更个性化的回答。
+ 挑战：
    - memory drift 记忆漂移：上下文累积
    - 存储成本
    - 召回质量： 它很大程度上取决于嵌入精度，糟糕的嵌入会导致糟糕的记忆。
    - 管理文档chunk的大小、保持文档清洁、确保文档是最新的
+ 记忆可能是聊天机器人中最难处理的部分。因此，管理与之相关的所有内容有一定的局限性，必须非常小心。尤其是记忆漂移，这在行业中是非常常见的问题。
+ 你可以想象一种更聪明的聊天机器人，它在“第一步”就能做一个决策：
    - “我需不需要去向量数据库里做一次检索？
    - 还是说，这个问题仅靠对话记忆就能回答？
    - 又或者，我根本可以直接用模型自身的知识来回答？”

# 20251114 Michael Truell: How Cursor Builds at the Speed of AI  下
+ [https://www.youtube.com/watch?v=deMrq2uzRKA](https://www.youtube.com/watch?v=deMrq2uzRKA)
+ 你应该先把 **RDS** 实例纵向扩容；这在相当长一段时间里都有效。最终你会遇到上限，然后问题就变成：要不要把数据库做分片（**shard**）
+ 你会以为这些公有云一切都安排妥当，但实际上，真正来到“极致规模”的只是非常少的一部分客户，而云厂商也在边走边摸索。
+ **PlanetScale** 的表现非常出色——我们从所谓的“Limitless”转向了 **PlanetScale**。
+ 我们认为，编辑器内的工作方式变化，开始影响团队协作方式。这既是重大战略机会，也是必要条件——若要拥有最好的编辑器，就还需要一个“互补体”，去更好地支持团队评审与协作。
+ 许多创始人低估了从单一产品到多产品在 **GTM（Go-to-Market）** 上的复杂度——这真的非常复杂
+ 作为一家小公司，在最初几位工程师阶段，我们更倾向于先让候选人短期合作（contract），而不是走常规的 **LeetCode** 式面试流程
    - 其一，它能测试到“与常规代码面试**正交**”的一些能力
    - 其次，它还能帮助双方判断“我们是否愿意彼此相处”。
    - 第三个益处，是它能让候选人充分了解公司，以及“第一天上班会是什么感觉”。这通常会带来更高的“匹配成功率”。
+ 在 AI 之前有一句流行的“老话”是：初创公司绝不要去收购另一家初创公司。
+ 对我们来说，每当这个领域里出现一个新的、看起来可行的产品方向，我们可能会先尝试自己在内部做；也可能会看看市场上已经有什么人、在做什么，如果正好有一群创始人做的东西特别契合，我们也很愿意和他们“合到一起”。大概这就是目前我们对并购这件事的思路。
+ 我觉得公司未来、包括过去已经在面对的一个关键挑战是：我们所在的这个市场，已经经历过一次类似 **iPod moment** 的时刻，接下来还会迎来一次 **iPhone moment**，甚至多次 **iPhone moment**。

# 20251113 Michael Truell: How Cursor Builds at the Speed of AI  上
![](https://cdn.nlark.com/yuque/0/2025/png/250863/1762994783246-4f98a539-7501-4edd-8c5f-27942114d9db.png)

+ [https://www.youtube.com/watch?v=deMrq2uzRKA](https://www.youtube.com/watch?v=deMrq2uzRKA)
+ 两个关键时刻，让我们对“创办一家公司”这件事变得非常兴奋：
    - “存在性证据”：**AI** 不再只是实验室里的研究对象，而是“真的可以在现实世界里做出有用系统”的东西
    - 缩放定律（scaling laws）：即使这个领域暂时“想不出新点子”，光是扩大模型规模，模型本身的表现似乎也会持续变好。
+ 而我们自己，则想去做一个“更冷门、竞争没那么激烈”的方向。我们最初是在做机械工程相关的东西——试着用模型帮机械工程师在 **CAD** 系统里更高效地建模、做设计，同时还想自己打造一套类似的 CAD 系统。
+ 有时候我几乎会想：在那六七个月里，如果我们干脆去相关公司做一段时间实习生，真正沉到这个行业里去，也许会更好。
+ 当我们决定放弃这个方向、转去做编程时，对那段经历几乎有点“PTSD（创伤后应激反应）”了。
+ 我觉得 **Cursor** 之所以在早期跑出来，其中一个原因是：你们异常地专注。你们选择了 **VS Code**，而且在那之前 **Copilot** 已经把市场教育了好几年——你们就专注在这么一个很窄的方向上，做出了一个“好太多、好太多、好太多”的产品，这就成了关键。
+ 而我们当时的策略，就是尽可能快地把一个东西推出来。
+ 承诺装置（commitment device）：其实就是每月一次的“投资人月报”——大概当时也没什么人真的看，但对我们而言，这就像一个自我约束。
+ 一开始我们甚至连 **VS Code** 的分支都没用，而是从零开始自己搭了一个编辑器，并且每天把它当主力工具（_daily driver_）来用。
+ 我觉得我们当时在“一定要**掌握界面入口（own the surface）**”这件事情上，是真的非常非常坚定。
+ 所以我们很清楚：只要你能做出一个“更好的捕鼠器（better mousetrap）”，你就有机会让大家换工具——只是门槛会非常高。
+ 同时，我们也非常刻意地规划：**将来有一天**，我们一定要去掌控“模型这一侧”。后来确实也在这条路上慢慢“倒着走了回来”，模型侧也成了我们很重要的产品杠杆。
+ Cursor曾经把某家大型云服务搞挂了
+ 我们在跑一个非常非常大的 **Kubernetes** 集群，规模甚至比很多更大的公司还要大——而那时候整个公司一共也就 5 个人，只能一边踩坑、一边“边学边搞”，自然会有各种小故障、小翻车。
+ 解决问题的关键就不再只是“技术多聪明”，而更多是**关系层面**的事情。
+ 从策略上看，把请求分摊到多家有**预付合约（committed contracts）**的平台上，其实更安全。于是我们就变得非常擅长：在全世界范围内“**把所有的 Sonnet tokens 都挖出来用上**”。

# 20251111 ElevenLabs CEO: Why Voice is the Next AI Interface 
+ [https://www.youtube.com/watch?v=ZqCEHR4wjxg](https://www.youtube.com/watch?v=ZqCEHR4wjxg)
+ 🏗️ 组织与团队
    - 有一个基础设施团队，从最开始的创始3个人到刚好现在11个人
    - 小型（通常5–10 人）的 independence 团队快速交付：
        * high ownership 带来的好处会超过high independence的坏处
        * 6 个月试点验证期；验证成功就保留并长期运营。
        * 控制Slack频道访问来强制注意力聚焦
        * 保持相当扁平的结构，坚持no title 的政策
        * 在团队结构上，我们也划分PMF前与PMF后的产品。PMF前，使命是不断迭代发版直至命中，一般给六个月；否则就下线该产品。
+ 🌍 Remote working 优先，并与 枢纽（hubs） working 相结合：
    - 在哪儿有人才，就到哪儿去
    - 规模超过 30 人后，我们意识到：新成员若能有一个与他人比邻的空间，会更好地沉浸文化、了解公司正在进行的项目。于是我们在伦敦、华沙、旧金山设立枢纽（hubs），供大家线下协作。职场早期的同学，我们尽量在hub里招聘，让你沉浸式融入；习惯远程也没问题，随时可来 hub。这个模式效果很好。
+ 👥 招聘与人才
    - 对于工程师，我们抵制凭履历/名校背书（credential）的传统LinkedIn 式招聘方式
    - 持续招收非传统背景的人才，并与传统背景、能带教（teach others）的人融合——例如销售。
    - 最难招聘的岗位之一就是法务
    - 美国人确实比欧洲人更热衷于谈论工作
+ 🛠️ 工程与产品
    - 做Demo很容易，但做到生产级很难，需要 测试、版本控制、评估与监控，并随时间进行fine-tune
    - 实现4个9或5个9的可靠性——在AI领域这非常难
    - 面向企业时会明确区分alpha阶段；由客户/伙伴决定是否接入alpha，并清楚标注其不够稳定。
    - research若短期可解则坚持研究优先，若research预计 >3 个月，product可以先行，用增补模型/扩展（extensions）等方式解题
+ 🛤️ Go-to-Market｜销售
    - 最初的看法是要做一家工程驱动的公司，甚至想“重塑销售”，让工程师来做销售。但现在是80%销售、20%工程。
    - **PLG**与**sales**的显著差异在于周期更长。我们起初需要“屏蔽”部分信息，让大家先相信节奏；12个月后事实证明有效。文化上最难的是让所有人都在“一列车”上保持同向。
    - 即使按佣金规则你能拿到钱、但你觉得这单不该做，就回来找我们——我们可以给你佣金，但把单砍掉。
    - 不能把产品卖给基础模型公司

# 20251106 ElevenLabs CEO: Why Voice is the Next AI Interface 2
+ [https://www.youtube.com/watch?v=ZqCEHR4wjxg](https://www.youtube.com/watch?v=ZqCEHR4wjxg)
+ 最难招聘的岗位之一就是法务
+ 最初的看法是要做一家工程驱动的公司，甚至想“重塑销售”，让工程师来做销售。但现在是80%销售、20%工程。
+ 做Demo很容易，但如何真正做到生产级？如何测试、做版本控制、评估与监控，并随时间进行**fine-tune**？
+ 目标是实现“**4个9**或**5个9**”的可靠性——在AI领域这非常难。
+ **PLG**与**sales**的显著差异在于周期更长。我们起初需要“屏蔽”部分信息，让大家先相信节奏；12个月后事实证明有效。文化上最难的是让所有人都在“一列车”上保持同向。
+ 我们希望快速发布，但面向企业时会明确区分**alpha**阶段；由客户/伙伴决定是否接入**alpha**，并清楚标注其不够稳定。
+ 在团队结构上，我们也划分**PMF**前与**PMF**后的产品。**PMF**前，使命是不断迭代发版直至命中，一般给六个月；否则就下线该产品。
+ 即使按佣金规则你能拿到钱、但你觉得这单不该做，就回来找我们——我们可以给你佣金，但把单砍掉。
+ 不能把产品卖给基础模型公司；公司内部对此有清晰共识。

# 20251105 ElevenLabs CEO: Why Voice is the Next AI Interface 1
+ [https://www.youtube.com/watch?v=ZqCEHR4wjxg](https://www.youtube.com/watch?v=ZqCEHR4wjxg)
+ 11libs 不光做TTS 还做 voice agent , 还创建了一个fully licensed的音乐模型
+ 基础设施团队是从最开始的3个人到刚好现在的11个人
+ 用小型（通常**5–10 人）、high ownership、 high  independence 的团队来快速交付。ownership带来的好处会超过independence带来的重复建设和速度不一致的影响
+ 研究若短期可解则坚持研究优先，若**研究**预计 **>3 个月**，**产品**可以先行，用**增补模型/扩展（extensions）**等方式解题
+ **远程优先**：在哪儿有人才，就到哪儿去。
+ **在工程侧，我们抵制**凭履历/名校背书（credential）**的传统**LinkedIn 式招聘
+ 规模**超过 30 人**后，我们意识到：**新成员**若能有一个**与他人比邻**的空间，会更好地**沉浸文化**、了解公司**正在进行的项目**。于是我们在伦敦、华沙、旧金山设立**枢纽（hubs）**，供大家**线下协作**。**职场早期**的同学，我们尽量在**hub**里招聘，让你**沉浸式**融入；习惯远程也没问题，随时**可来 hub**。这个模式效果很好。
+ 持续招收**非传统背景**的人才，并与**传统背景**、能**带教（teach others）****的人****融合（fuse）**——例如销。这样的**组合**效果很好
+ 美国人确实比欧洲人更热衷于谈论工作
+ 保持了**相当扁平**的结构，第一年就采取了no title 的政策
+ **创建试点团队**，给**6 个月验证期**；验证成功就**保留并长期运营**。
+ 把人**放进所有 Slack 频道**会导致**分心**；需要**控制访问**来**强制注意力聚焦**
+ 我们推出了**声音市场**：你可**创建自己的声音并分享**；**被使用**就能**获得收入**。目前已有**近 1 万个**声音条目，**累计向社区支付 1000 万美元**分成。

# 20251104 What Is an AI Stack? LLMs, RAG, & AI Hardware
+ [https://www.youtube.com/watch?v=RRKwmeyIc24](https://www.youtube.com/watch?v=RRKwmeyIc24)
+ **小型语言模型**，更“轻”，可适配更轻量的硬件。但它们的“思考能力”可能不及大型模型，相对更**专门化**，适合更具体的任务。
+ **专门化**。这有时与规模相辅相成。有的模型在**推理**、**工具调用（tool calling）****或****代码生成**等方面更擅长。
+ 向量数据库这一步，会把外部数据**向量化**为可保存的**embeddings（嵌入向量）**，以便模型更快地**检索上下文**，并用这些基础模型不具备的**新增知识**进行增强。
+ 在界面层面，要具备**修订（revisions）**、**引用（citations）****等能力，这样当用户看到模型给出的结果时，既能****进一步编辑**，也能**追问/查询更多**细节。
+ AI 技术栈的这些层面——从**硬件**、**模型**、**数据使用**、**编排方式**，到**应用与可用性**——都**至关重要**，因为当我们清楚地理解它们如何**彼此契合（fit together）时，才能看清真正可实现的空间**，

# 20251103 Deep Agent CLI: Coding Assistant with Memory
+ [https://www.youtube.com/watch?v=IrnacLa9PJc](https://www.youtube.com/watch?v=IrnacLa9PJc)
+ **deep agent CLI** 是一个开源的编码工具，构建在 **deep agents** 包之上，它能让你编写、编辑并理解代码。
+ 一个关键差异点是：它内置了“记忆”功能。之后你可以在不同时间点访问它们，并把它们“迁移”到不同项目，甚至不同终端窗口等场景
+ 介绍 **deep agents** 仓库：一个用于构建 **deep agents** 的 Python 包，具备更高级的能力，比如规划、子智能体、文件系统访问，以及更细致的提示词工程。
+ 当我运行 **deep agent** 命令时，会加载与我所选智能体关联的记忆。
+ 核心思想是：让智能体随时间**累积上下文**，并**自我管理**这些上下文——决定**该记什么/不记什么**，并在未来再次引用。

# 20251102 AI is a commodity?
+ [https://www.youtube.com/watch?v=I4jbVyOqZgA](https://www.youtube.com/watch?v=I4jbVyOqZgA)
+ **2021 年 11 月** **GPT3** 发布时，费用约为每 **100 万 tokens 60 美元**。而**三年后**，性能相近的模型仅约 **$0.06/百万 tokens**。
+ **AI** 的创新更像**能量脉冲式**爆发，而非**缓慢复利式**累积。这也解释了**AI 寒冬**：若久无**新一轮爆发**，人们会失去信心，**市场萎缩**，**资本枯竭**。
+ 每次**创新爆发**都会形成**短暂的支配窗口**，直至**市场追平并收敛**，等待下一次爆发。行业在**小垄断**与**商品化**之间**来回振荡**；每一波发现都会**重置赛场**。因为“**智能**”是**动态靶标**；每次跃迁都会**打破均衡**，带来**暂时优势**，随后又被追上
+ 但维持这种“振荡博弈”**代价不菲**——**算力**就是代价。
+ 当前行业**一边缺算力**，一边**等待**多年的**大型训练中心**建成，处于**尴尬阶段**。**品化**与**受限创新周期**之间的**张力**，使当下更像**混合型**经济阶段。
+ 一旦**算力瓶颈**真正消除、**24 小时内**即可训练出模型，**AI 经济**将更接近**真正的商品化市场**——因为**创新周期更快**，**优势窗口更短**。

# 20251101  Speech to Text: Fine-Tuning Generative AI for Smarter Conversational AI
+ [https://www.youtube.com/watch?v=jEZ159wzSJY](https://www.youtube.com/watch?v=jEZ159wzSJY)
+ **speech-to-text** 的任务就是把**音频波形**转换成**文本**，构建 **phonemes**（音位，构词的最小语音单位），
+ 你**大概从未听过**这种说法——这正是为什么**定制化**对特定领域的模型性能提升至关重要。
+ 语音识别会利用**上下文线索（context clues）****来提升识别率**，**置信度被提升**；该短语内部**凝聚性（cohesion）**很强
+ 这对 **STT** 引擎来说是**真正的挑战**，因为除了这个单词本身，**没有任何上下文**。
+ 通过**定制化**来**缩小语言模型的搜索空间（search space）**，让它更有机会**准确命中**目标词。
+ 所谓语料库，就是你**预期模型会遇到**的**词/短语清单**；你用这套语料来**提示（nudge）****模型：嘿，这些****语音序列**就是在我这个领域里**会出现**的。
+ 把**本领域常见**、但在**通用语言**里不常见的**词、短语或序列**都收进去。
+ 可以为语言模型制定一套**更严格的规则**，称为 **grammar**（形式**文法**/语法约束）。

