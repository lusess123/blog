# 20250203 OpenAI DEEP RESEARCH Surprises Everyone "Feel the AGI" Moment is here...
+ [https://www.youtube.com/watch?v=2sdUG1FtzH0](https://www.youtube.com/watch?v=2sdUG1FtzH0)
+ Humanity’s last exam 这是一项最近推出的基准测试，它包含超过 3000 道选择题和简答题，覆盖了超过 100 个学科，从 Linguistics 到火箭科学，从经典文学到生态学
+ deep research  得分 26.6%；该系统配备了浏览（browsing）和 python tools 等功能，使你能够通过多种方式获得答案。
+ 就像许多早期模型一样存在“幻觉”（hallucination）问题——但当加入了搜索功能后，这种问题大大减少了
+ OpenAI 关注 agents，因为我们相信它们将会彻底变革知识型工作
+ Deep Research 是一种在互联网上进行多步骤研究的模型。它能发现内容、综合内容，并对这些内容进行推理；在不断获取更多信息的过程中，它会调整自己的计划。
+ Deep Research 的一个重要特点（也是我们称其为 Deep Research 而不仅仅是 Research 的原因）在于，我们取消了模型的延迟限制。
+ 我们认为，让我们的模型在无监督的情况下更长时间地执行自主任务是非常重要的；这也是我们 AGI 路线图的核心所在
+ 我认为，我们最终的愿景是构建出一种能够自我发现和揭示新知识的模型
+ 这个模型非常擅长处理既有明确要求又稍微开放式的信息，并利用这些信息展开调查，获取你所需的所有数据
+ Deep Research 在多个知识型工作领域表现非常出色，因此，我们已经看到人们利用它进行市场调研，以及在物理、计算机科学、生物学等不同学术领域的研究。
+ **Deep Research** 由我们即将发布的 **Student to be Released O3 Reasoning Model** 的一个经过精细调优的版本驱动，我们使用端到端（**end-to-end**）强化学习对复杂浏览以及其他推理任务进行了训练
+ 通过率与预估经济价值的相关性比与完成任务所需时间的相关性更高，这表明模型所认为困难的任务，不一定与人类认为耗时的任务相同
+ 该模型在寻找极其零散信息方面的出色能力

# 20250202 o3-mini is the FIRST DANGEROUS Autonomy Model | INSANE Coding and ML Abilities（上）
+ [https://www.youtube.com/watch?v=CqpDXeMIY1Q](https://www.youtube.com/watch?v=CqpDXeMIY1Q)
+ **03 mini** 是第一个达到中风险级别的模型，它没有被评为高风险，因为我们仍然认为它实际上还不具备执行现实世界机器学习任务的能力
+ 使用 OpenAI Gym，可以方便地构建标准化的实验环境，并利用它提供的 API 来交互式地训练和评估 AI 代理（agents）。
+ torch用于诸如 computer vision（计算机视觉）和 natural language processing（自然语言处理）等应用，最初由 Meta AI 开发，现在隶属于 Linux Foundation Umbrella
+ 每当开始尝试新事物时，总会经历一段令人不适的学习期；一旦熬过那段阶段，你将能做更多事情，不仅仅是在一般意义上，更是在技术层面上
+ 5年前——你必须学习的内容量巨大，才能入门并开始动手。而现在，借助众多 AI 模型，这个学习过程大大压缩了，因为你可以更快地开始开发项目。

# 20250202 DeepSeek R1 Replicated for $30 | Berkley's STUNNING Breakthrough Sparks a Revolution.
+ [https://www.youtube.com/watch?v=E_h8xt0X1Kg](https://www.youtube.com/watch?v=E_h8xt0X1Kg)
+ **Berkeley** 的研究人员仅花 30 美元就复制了 **DeepSeeks R1** 的核心技术
+ “aha 时刻”指的是：利用 **reinforcement learning** 让模型“self-evolution”（自我进化），最终展现出涌现性能力，其中包括相当先进的推理能力和未被明确教授的策略
+ 同样的自我进化——那种“顿悟”时刻——不仅会出现在大型昂贵的模型中，也会出现在这些仅需 30 美元的模型中；预计这些模型明年只需 8 美元，后年只需 2 美元
+ 模型通过自我反思，自主地认识到需要为某个问题分配更多思考时间
+ 在 2026–2027 年左右，模型将在大多数任务上超越人类
+ Iliay几年前说：“这些 transformers，这些 neural nets，它们只是想学习。”
+ 百分之百确信，每家美国公司之间也都曾互相模仿过这种做法，大概从**GPT 4**开始就是如此.这才是科学应有的样子：大家都将成果公之于众，彼此借鉴并在此基础上不断创新。
+ 这篇论文——虽然尚未正式成为论文，但这项研究所展示的内容，再次预示着其可能产生巨大的影响（可能非常巨大）——首先，它类似于一种自我进化，一种 aha moment
+ 这种隐性学习与隐性理解的能力，比大多数人预想的要早就出现在规模远小的模型中
+ 对于开源和更好地利用 AI 来说，最大的杠杆作用在于构建多样化的 **reinforcement learning** 环境。这种方法对那些能够为其特定任务找出合适 **reinforcement learning** 策略的人来说，影响将是巨大的
+ “寒武纪爆发”原指数亿年前的急速进化时期，如今在如此众多的开源贡献面前，这个比喻实在贴切。

