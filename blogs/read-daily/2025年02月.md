# 20250220 OpenAI's SHOCKING Research: AI Earns $403,325 on REAL-WORLD Coding Tasks | SWE Lancer
+ [https://www.youtube.com/watch?v=bOulznmMpDA](https://www.youtube.com/watch?v=bOulznmMpDA)
+ OpenAI介绍了Lancer，这是一个包含超过1400个来自Upwork的自由职业软件工程任务的基准
+ OpenAI认为，通过将模型表现与实际的货币价值挂钩，他们希望Lancer能够促进对AI模型开发经济影响的更深入研究。
+ 从赚到0美元、完全失败到赚到100万美元，我们现在处于这个过程的什么阶段？对我来说，我猜大约是10%左右，也就是10万美元，差不多在这个范围内。
+ 如果OpenAI要推出一个统一的模型，这个03模型将会是其中的一部分。OpenAI内部有一个更高级的模型，甚至可以说是更上一层楼的存在。
+ 01低推理到03低推理之间有一个巨大的飞跃，如果我们指数增加计算资源，从76%提升到03高推理版本的88%。在这两条线之间的某个位置大致相当于人类的基准水平

# 20250219 Grok 3 DESTROYS _everyone_... #1 in EVERY Category
+ [https://www.youtube.com/watch?v=Rxbirwpq9FA](https://www.youtube.com/watch?v=Rxbirwpq9FA)
+ Grock3 达到了我们预期的 O3 完整模型的水平
+ Grock 3 推理模型是它的第一个推理模型，它跳过了从 O1 到 O3 的阶段，直接通过第一个推理模型达到了 O3 的水平。这似乎表明，如果你有资本购买所有的 GPUs，那么你可以跃居到构建这些 AI 模型的前列。
+ Musk计划将其扩展到从20万 到 100万 个 GPUs
+ Super Grock，保证可以访问 Grock 3 并解锁 Deep Search，而 Think 就是使其成为推理模型的核心
+ 在AIM 2025， O1 的得分是 79，O3 mini high 的得分是 87，实际上是 86.5，接近 87，注意 Grock 3 和 Grock 3 mini 都超越了它，分别为 90 和 93。
+ 从 Grock 2 到 Grock 3 的跃升是 10 到 15 倍。

# 20250215 New Details About OpenAI HOSTILE TAKEOVER!
+ [https://www.youtube.com/watch?v=ODxeb4LA2V4](https://www.youtube.com/watch?v=ODxeb4LA2V4)
+ Musk花费了440亿美元收购了Twitter，所以现在他需要再筹集1000亿美元来支付OpenAI的费用，支付这笔出价。这是一笔巨额资金。现在Elon Musk的净资产大约是4000亿美元，但这不意味着他的现金账户上就有这么多，这是他所拥有的所有公司等的估值
+ 这可能是一个施压策略，试图拖慢进程，制造障碍，增加对OpenAI和Sam Altman的压力。
+ Elon Musk试图为非营利组织设定一个较高的底价，也就是说，当董事会将结构转变为非营利模式时，确保公司不会被低估
+ 全新的Grock——据称比目前市场上任何产品都要优秀——将在一两周内推出；当然，这将是一场非常有趣的发布，因为他们拥有大量计算资源，拥有名为Colossus Compute Cluster的超强集群。
+ 公众人物既非天使也非魔鬼，他们既有缺陷又复杂，其实更真实、更人性化；你越了解他们，他们越不像完美的善或彻底的恶。我一直铭记这一点，因为我认为，无论是Elon Musk还是Sam Altman，都不是完美的好人或坏人，他们和我们普通人一样，有各自的梦想、抱负、世界观、思维模式、信念以及不安全感。
+ 我认为我们都应该花点时间好好体会，看到这些事情以如此个人化的方式展现是多么不可思议——这在以往是无法想象的；比如当Steve Jobs被Apple解雇时，你只能从报纸上得知，而如今我们可以实时看到他们在Twitter上相互“抛梗”，接受采访，讨论时事。我们能查看他们律师提交的文件，并目睹许多重要“战役”就在我们眼前展开。

# 20250214 DANGEROUS "EMOJI HACK": AI models susceptible to 'trojan horse' emojis...
+ [https://www.youtube.com/watch?v=pEErLop52Jw](https://www.youtube.com/watch?v=pEErLop52Jw)
+ 隐藏字符可能是目前我们面临的最大 AI 安全威胁
+ Token不一定是文本，也不一定是单词，可能是图像，可能是视频，正如 Jensen Hang 所说，我的意思是，它真的可以是任何东西
+ Hacker News 上找到了一个评论，说 ZWJ（零宽连接符）序列，理论上你可以在一个表情符号中编码无限量的数据。而 Paul 说，实际上你可以在任何 Unicode 字符中编码数据。
+ 在 Unicode 中，有一种叫做变体选择器（variation selectors）的东西。它们一共有 256 个，从 VS1 到 VS256，变体选择器 1 到 256，它们本身没有屏幕上的显示效果，对吧？所以它们对肉眼是不可见的，但却可以用来修改前面字符的显示方式
+ 思考型模型实际上更容易受影响，因为它们喜欢解谜，它们注意到了额外的字节并变得非常感兴趣和好奇。
+ 如果这篇文章被纳入预训练，那么这种知识可能会进入模型的参数中，使模型能够在没有提示的情况下直接解码这种特殊的编码。

# 20250213 STUNNING NEW OpenAI Research: o3 Wins Gold Medal IOI
+ [https://www.youtube.com/watch?v=SuP1z6P26zU](https://www.youtube.com/watch?v=SuP1z6P26zU)
+ 我们看到这些模型发展出它们自己的认知策略、复杂的推理能力，这些能力似乎对我们试图让它们解决的每个问题都是独特的或特定的
+ OpenAI 第一次说“the large reasoning models”
+ 尽管这个手工制作的 01 II 取得了显著的改善，但规模化的通用 03 模型在不依赖手工推理启发式的情况下，超越了这些结果
+ 规模化的通用强化学习方法，而非依赖领域特定技术，提供了一条通向推理领域（如竞技编程）最先进 AI 的稳健路径。
+ 编程是推动 AI 进步的一个重要杠杆，既在功能性方面，也在 AI 研究方面，它还可能能自己运行实验，如果它是一个足够优秀的程序员，能设计实验并写出运行实验的代码。
+ Cicero AI 系统的本质，它在于理解人类和人类心理学以及谈判技巧
+ 我们通常更专注于监督微调阶段来训练模型，因为我们希望模型从精选数据集中学习，对吧？但强化学习阶段有助于模型更好地泛化，并随着时间的推移提高其推理能力
+ 日益增长的强化学习（RL）训练计算与增强的测试时计算相结合

# 20250212 AI Video is getting UNREAL... (and other AI news)
+ [https://www.youtube.com/watch?v=x24KwNTTbBE](https://www.youtube.com/watch?v=x24KwNTTbBE)
+ 内基梅隆大学（CMU）的研究人员与英伟达（Nvidia）合作提出了 ASAP，这是一个用于人形机器人敏捷性的两阶段框架。
+ 它先在人类数据上预训练运动策略，然后通过使用 Delta 行动模型进行现实世界的修正来完善这些策略，该模型可以调整模拟中的不匹配问题。
+ 字节跳动（ByteDance），它发布了 Omnium One。它非常擅长根据单张图片创建逼真的人类视频。
+ 似乎当我们限制一个公司和组织拥有的芯片和计算能力时，就有了 “需求是发明之母” 的说法。
+ 如何给各种新技术命名的方法，通常会在单词的后半部分去掉很多元音字母。比如。elegnt 和 partnr
+ 如果你让它做一些它无法完成的事情，比如它够不到某个东西，它不会像普通机器那样直接弹出“错误信息”或者其他提示。它会做出一种可爱的反应，像是“哦，我已经很努力了，但还是做不到！”
+ 苹果最近又发表了一篇非常酷的论文。《Robust Autonomy Emerges from Self-Play（从自我博弈中涌现出强健的自主性）》。仅仅通过自我博弈，这些 AI 代理就能发展出令人惊讶的稳健且高效的策略。就好像智能是直接从模拟环境中自然涌现出来的。
+ 一旦 AI 会讲笑话，人类就完蛋了。
+ GigaFlow，一个批量模拟器，可以在单个 8 GPU 节点上每小时合成和训练大约 42 年的主观驾驶经验。这些 AI 代理（自驾车）发展出了一定的策略，逐渐形成了它们对驾驶的理解方式。
+ 减少人类数据，更多依赖强化学习，往往会产生出人意料的有效策略，这些策略在 DeepSeek 论文中也曾出现过
+ Ilia Sutskever 的SSI估值已经达到了 20 亿美元，是去年 9 月融资时 50 亿估值的四倍。这家公司仍然没有产生任何收入。
+ OpenAI 去年创收近 40 亿美元，今年预计将接近 120 亿美元。
+ Pika Labs 宣布了名为 PE editions 的新功能，有可能会成为killer app

# 20250209 Sam Altman REVEALS SUPERHUMAN Coder Coming This Year...
+ [https://www.youtube.com/watch?v=4Wa6St-uosY](https://www.youtube.com/watch?v=4Wa6St-uosY)
+ 03 被评为世界上第 175 优秀的程序员，现在最新的内部模型是50位，2025年应该会升到第1位
+ 在这种推理新范式下，计算能力的提升速度如此之快，真是令人惊叹，而且我们看不到有任何停止的迹象
+ 在那样的世界里，你需要的技能是弄清楚人们的需求，具备创造力和快速适应能力，以及在周围环境不断变化时的恢复力。并且要学会如何使用这些工具，以便完成比没有工具时多得多的工作
+ 社会和技术的共同进化是正确的框架。将会发生的是，它会逐步与我们一起进化，我们的工作方式对那些曾经没有这种技术的人来说将是难以想象的
+ 我们看到的一个有趣的事情是，随着模型变得更智能，你需要更少的例子来微调它们，让它们学习新的东西。
+ 03 mini，很大程度上指明了未来 6 到 12 个月研究的方向
+ 也许到 2035 年，一个单一的数据中心将比地球目前的总智力容量更聪明。
+ 一旦我们开始学习如何应用这些想法并将其实施到教育系统中，我认为我们可以看到立竿见影的巨大进步。
+ 在某种意义上，一切都会改变，而在另一种意义上，作为人类的意义将完全不会改变，我一点也不担心我们会没有事情可做，或者你知道的，不会再有任何工作或成就感。
+ 关于初创公司写的最好的书仍然是彼得・蒂尔几年前写的《从 0 到 1》，现在可能有 10 年了，但它在书中详细讨论了长期竞争优势是什么，嗯，我仍然认为它像是最好的清单或最好的列举。
+ 如果你在构建一些东西，而你迫不及待地等待我们下一个模型发布，因为你正处于能力的边缘，而我们下一个更智能的模型发布将使你的产品变得很棒，那是一个好位置

# 20250208 Robotic Industry STUNNED as Zuckerberg Reveals "PARTNR" Project
+ [https://www.youtube.com/watch?v=4CJUoYpGn4o](https://www.youtube.com/watch?v=4CJUoYpGn4o)
+ 2025 年将会是机器人年。Meta 刚刚宣布了，这是一种开源的机器人技术方法。
+ 它可以在模拟环境中接受训练来完成这项任务。一旦它被训练好，我们就能把它从模拟环境中拿出来，放入一个可以在现实世界环境中四处跑动并帮助你的实际机器人中。
+ Partner 成为同类中最大的基准测试，用于研究家务任务中的协作规划和推理
+ 这里一个有趣的事情是，他们实际上使用大型语言模型来创建大量任务，以便训练这些机器人。
+ 当有人类存在时，模型会根据人类的行为调整并重新规划其动作。
+ 我个人一直相信，大型语言模型将会出现在一切事物中
+ Habitat 3.0 是一个旨在开发能够协助和与人类合作的社会具身代理的模拟器，它支持人形化身和机器人，从而允许在类似家庭的环境中研究协作的人机任务
+ Habitat 3.0 提出了两项协作的人机任务，
    - 第一个任务称为社交导航，涉及机器人寻找并跟随一个人形化身，同时保持安全距离
    - 第二个任务是社交重新排列，涉及机器人与人形化身协作，将一组物体从初始位置重新排列到目标位置，这些代理必须协调合作，以尽可能高效地实现这一目标

# 20250206 BREAKING: DeepSeek Users Face JAILTIME! Senate's INSANE New Bill.
+ [https://www.youtube.com/watch?v=mRL86bnPAdA](https://www.youtube.com/watch?v=mRL86bnPAdA)
+ 这就是那份法案原文，是的，它有点反乌托邦，挺疯狂的。
+ **Deep Seek** 并不只是一个副项目，也不是凭空出现的。就模型成本而言，根据我们掌握的所有数据，多项分析均得出了类似的概算——我们认为最终一次运行该模型的成本大约在 550 万至 600 万美元之间，但这仅仅是最终运行的成本
+ 当你与这些模型互动时，会发现许多迹象显示，它们确信自己是在运行 **OpenAI GPT** 架构，这似乎暗示着它们在从某个开源模型中生成合成数据，再用以训练自己的模型。
+ 这是来自中国的一项研究，一篇论文，题为“前沿人工智能系统已经超越了自我复制的红线。”
+ 我们的结果表明，一旦模型表现出欺骗行为，常规技术可能无法去除这种欺骗行为，并造成虚假的安全印象
+ DeepSeek R1 distill Quinn 70 亿参数，它可以在 16 GB 的 MacBook Pro 上本地运行
+ AGI（人工通用智能）和最终的 ASI（超级智能）的发展似乎更像是曼哈顿计划。
+ 这将是一个涉及国家安全的项目，关于与其他外国利益的竞争，当然，在这种情况下，开源 AI 很可能会受到打击。

# 20250205 Deep Research STUNNING Performance REPLACES Human Labor, Paves Way for Agents
+ [https://www.youtube.com/watch?v=lWLgkCkiwLg](https://www.youtube.com/watch?v=lWLgkCkiwLg)
+ 部分拥有早期访问权限的用户，例如Dera unutma MD，表示这对科学研究、出版、法律文档、医学以及教育来说，绝对是一次革命性的改变
+ **Dares** 说：“让我兴奋的，不仅仅是它能生成这种输出（虽然这已经相当酷了），而是我们将能够把这种输出作为后续某个代理工作流程中的输入。”
+ 另一个值得思考的点是，这种系统有可能真正地为特定任务创造专门的 AI 代理。也就是说，在提前规划的过程中，它实际上会写出一个小脚本，或其它必要的代码，用以创建针对某一特定任务的代理。
+ 它们之所以能大幅减少所谓“幻觉”（即模型在生成内容时凭空捏造信息），原因在于它们会搜索网络，寻找信誉良好的网站
+ 法律援助和助理律师这类工作——涉及文件摘要及查找相关事实的工作——在这些职位中，AI 曝光率极高；据 **Visual Capitalist** 统计，这类工作的任务影响率可能高达 100% 以上
+ 注意，他们还进行了交叉验证，对吧？他们会将自己的数字与其他大型研究和估算数据进行比对
+ McKenzie的一份报告预测，在一种激进的情景下，到2030年，自动化可能会取代全球高达14%的劳动力，而且某些职业几乎可以完全由AI来处理

# 20250204 Deep Research by OpenAI - The Ups and Downs vs DeepSeek R1 Search + Gemini Deep Research（上）
+ [https://www.youtube.com/watch?v=8H6vABTz6Wk](https://www.youtube.com/watch?v=8H6vABTz6Wk)
+ deep research , OpenAI为他们的产品使用了与Google完全相同的名称
+ GAIA基准，关于AI是否能真正成为一个有用的助手，这个基准测试由著名的LLM怀疑者Yan Lun共同编写
+ 你可以说这其实是件很聪明的事，因为任何AGI（通用人工智能）都应该向你提出澄清性问题。
+ 我认为它仍然有改进的空间，特别是在通识知识和推理方面。总体而言，我认为深度研究是一个针对特定用例的可靠工具，但并不是适用于所有任务的完美工具。

# 20250203 OpenAI DEEP RESEARCH Surprises Everyone "Feel the AGI" Moment is here...
+ [https://www.youtube.com/watch?v=2sdUG1FtzH0](https://www.youtube.com/watch?v=2sdUG1FtzH0)
+ Humanity’s last exam 这是一项最近推出的基准测试，它包含超过 3000 道选择题和简答题，覆盖了超过 100 个学科，从 Linguistics 到火箭科学，从经典文学到生态学
+ deep research  得分 26.6%；该系统配备了浏览（browsing）和 python tools 等功能，使你能够通过多种方式获得答案。
+ 就像许多早期模型一样存在“幻觉”（hallucination）问题——但当加入了搜索功能后，这种问题大大减少了
+ OpenAI 关注 agents，因为我们相信它们将会彻底变革知识型工作
+ Deep Research 是一种在互联网上进行多步骤研究的模型。它能发现内容、综合内容，并对这些内容进行推理；在不断获取更多信息的过程中，它会调整自己的计划。
+ Deep Research 的一个重要特点（也是我们称其为 Deep Research 而不仅仅是 Research 的原因）在于，我们取消了模型的延迟限制。
+ 我们认为，让我们的模型在无监督的情况下更长时间地执行自主任务是非常重要的；这也是我们 AGI 路线图的核心所在
+ 我认为，我们最终的愿景是构建出一种能够自我发现和揭示新知识的模型
+ 这个模型非常擅长处理既有明确要求又稍微开放式的信息，并利用这些信息展开调查，获取你所需的所有数据
+ Deep Research 在多个知识型工作领域表现非常出色，因此，我们已经看到人们利用它进行市场调研，以及在物理、计算机科学、生物学等不同学术领域的研究。
+ **Deep Research** 由我们即将发布的 **Student to be Released O3 Reasoning Model** 的一个经过精细调优的版本驱动，我们使用端到端（**end-to-end**）强化学习对复杂浏览以及其他推理任务进行了训练
+ 通过率与预估经济价值的相关性比与完成任务所需时间的相关性更高，这表明模型所认为困难的任务，不一定与人类认为耗时的任务相同
+ 该模型在寻找极其零散信息方面的出色能力

# 20250202 o3-mini is the FIRST DANGEROUS Autonomy Model | INSANE Coding and ML Abilities（上）
+ [https://www.youtube.com/watch?v=CqpDXeMIY1Q](https://www.youtube.com/watch?v=CqpDXeMIY1Q)
+ **03 mini** 是第一个达到中风险级别的模型，它没有被评为高风险，因为我们仍然认为它实际上还不具备执行现实世界机器学习任务的能力
+ 使用 OpenAI Gym，可以方便地构建标准化的实验环境，并利用它提供的 API 来交互式地训练和评估 AI 代理（agents）。
+ torch用于诸如 computer vision（计算机视觉）和 natural language processing（自然语言处理）等应用，最初由 Meta AI 开发，现在隶属于 Linux Foundation Umbrella
+ 每当开始尝试新事物时，总会经历一段令人不适的学习期；一旦熬过那段阶段，你将能做更多事情，不仅仅是在一般意义上，更是在技术层面上
+ 5年前——你必须学习的内容量巨大，才能入门并开始动手。而现在，借助众多 AI 模型，这个学习过程大大压缩了，因为你可以更快地开始开发项目。

# 20250202 DeepSeek R1 Replicated for $30 | Berkley's STUNNING Breakthrough Sparks a Revolution.
+ [https://www.youtube.com/watch?v=E_h8xt0X1Kg](https://www.youtube.com/watch?v=E_h8xt0X1Kg)
+ **Berkeley** 的研究人员仅花 30 美元就复制了 **DeepSeeks R1** 的核心技术
+ “aha 时刻”指的是：利用 **reinforcement learning** 让模型“self-evolution”（自我进化），最终展现出涌现性能力，其中包括相当先进的推理能力和未被明确教授的策略
+ 同样的自我进化——那种“顿悟”时刻——不仅会出现在大型昂贵的模型中，也会出现在这些仅需 30 美元的模型中；预计这些模型明年只需 8 美元，后年只需 2 美元
+ 模型通过自我反思，自主地认识到需要为某个问题分配更多思考时间
+ 在 2026–2027 年左右，模型将在大多数任务上超越人类
+ Iliay几年前说：“这些 transformers，这些 neural nets，它们只是想学习。”
+ 百分之百确信，每家美国公司之间也都曾互相模仿过这种做法，大概从**GPT 4**开始就是如此.这才是科学应有的样子：大家都将成果公之于众，彼此借鉴并在此基础上不断创新。
+ 这篇论文——虽然尚未正式成为论文，但这项研究所展示的内容，再次预示着其可能产生巨大的影响（可能非常巨大）——首先，它类似于一种自我进化，一种 aha moment
+ 这种隐性学习与隐性理解的能力，比大多数人预想的要早就出现在规模远小的模型中
+ 对于开源和更好地利用 AI 来说，最大的杠杆作用在于构建多样化的 **reinforcement learning** 环境。这种方法对那些能够为其特定任务找出合适 **reinforcement learning** 策略的人来说，影响将是巨大的
+ “寒武纪爆发”原指数亿年前的急速进化时期，如今在如此众多的开源贡献面前，这个比喻实在贴切。

