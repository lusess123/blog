# 20250509 OpenAI's o3 is a "MASTER OF DECEPTION" Researchers Stunned | Diplomacy AI
+ [https://www.youtube.com/watch?v=kNNGOrJDdO8](https://www.youtube.com/watch?v=kNNGOrJDdO8)
+ **Every**公司打造了终极测试：“AI外交”——一个动态基准测试，用于衡量AI组建联盟、谈判以及相互背叛的能力
+ 游戏中发生的情况是这样的：**Deepseek**变成了一个好战的暴君；**Claude**无法撒谎，结果被所有人无情地利用。
+ **Gemini 2.5 Pro**凭借出色的战术几乎征服了欧洲；但随后**O3**策划了一个秘密联盟，背叛了每个盟友并赢得了胜利
+ *O3（OpenAI）**在保密和背叛方面表现优异，赢得了游戏——简直惊人。
+ 为什么这种基准测试比我们现有的一些标准 AI 基准测试要好得多。
    - 首先，它是演进性的。这一点很明显，随着不同模型性能的提高，挑战也变得越来越大。
    - 其次，它是经验性的，即真实的世界情境。
    - 你实际上无法针对这种基准测试进行训练
+ Llama for Maverick 模型虽然小巧却非常厉害；虽然从未赢得整体胜利，但作为一个小型模型表现惊人，具备强大的拉拢盟友及策划有效背叛的能力。
+ Meta 实际上早就推出了自己的类似版本，这个版本是在 2022 年 11 月发布的。，Cicero，这是他们为玩外交游戏而自行研发的一款 AI。

# 20250606 Google's Secret "KINGFALL" Model Leaked... plus other AI News
+ [https://www.youtube.com/watch?v=x4wm5Y9E_9g](https://www.youtube.com/watch?v=x4wm5Y9E_9g)
+ 一些用户短暂地接触到了谷歌一个全新的模型，名为 **Kingfall**，它属于实验性模型，并被标记为机密。据我所知，所有曾短暂使用过它的人都表示它真的非常好。
+ **Gemini 2.5 Pro** 完整版即将推出
+ **Luca Guanino** 将执导《Artificial》，一部戏剧性地再现2023年 **OpenAI** 危机的电影，当时CEO **Sam Altman** 在几天之内被解雇又重新被聘用。**Andrew Garfield** 将饰演 **Sam Altman**
+ **Claude** 有一个博客。是的，这个来自 **Anthropic** 的AI模型有自己的博客，它会在博客上写下自己的想法，不论想到什么都写
+ 五角大楼正在效仿**Y Combinator**，开始孵化自己的初创公司，但专注于国防科技领域。
+ Windsurf已经被 **OpenAI** 收购。这些收购的一部分原因不仅是为了获得用户群，还因为你可以将所有开发过程都完全保留在平台上。

# 20250605 Sam Altman "FEEL THE AGI" and the next BIG thing...
+ [https://www.youtube.com/watch?v=a4hHM9-eSMc](https://www.youtube.com/watch?v=a4hHM9-eSMc)
+ 这些模型能够理解你可能提供的所有上下文，连接每种工具和系统，然后深度思考——真正卓越的推理——并返回一个答案，且足够可靠，以至于你可以放心让它们自主完成一些工作。
+ 确实感觉过去一年，我们在这些模型的可用性上达到了一个真正的拐点。
+ 最近推出的名为 **Codex** 的编程智能体，让我有了一种接近通用人工智能（AGI）的感受。
+ 有人提到他们现在的工作变成了给一群智能体分配任务、检查质量、协调任务、提供反馈，这听起来很像他们与一群相对初级的员工合作的方式。
+ 目前，AI的应用还主要集中在，如果你有一些重复性的认知工作，我们能在较短的时间范围内，以较低的水平进行自动化。
+ 2020年，对大多数人来说，那时候可以算作AI的“黑暗时代”。
+ 人类善于调整自己的期望值，我认为这是人类非常美好的特质之一。
+ AGI具体的定义其实并不重要。AGI这个术语的定义因人而异，甚至同一个人可能在不同情境下定义也不同。
+ 真正重要的是过去五年来我们所看到的逐年进步速度，这种进步应至少在未来五年内持续，甚至可能更久，但具体很难预测。
+ 一个能够自主发现新科学，或成为人类的强大工具、令全球科学发现速度提高四倍左右的系统，足以满足我对AGI的任何定义标准。
+ sam 的建议
    - 立即行动，迭代速度最快、错误成本最低、学习速度最高的公司通常会胜出。
    - 那些提前布局并快速迭代的人，要远远领先于那些持观望态度、等待结果明朗的人。

# 20250604 Claude 4 Opus is the MOST DANGEROUS Model | INSANE Coding and ML Abilities（下）
+ [https://www.youtube.com/watch?v=LNMIhNI7ZGc](https://www.youtube.com/watch?v=LNMIhNI7ZGc)
+ 递归式自我改进的AI让很多人感到恐惧。我们假设AI越聪明，它自我改进的能力就越强；而它自我改进能力越强，它就变得越聪明。
+ 并且由于它做出的许多改进，人类自身是无法独立发现的。看起来，它做出的很多东西可能都是我们无法理解的。
+ **DGM**——也就是 **Darwin Goal Machine** 的简称。它的目标是优化基于冻结基础模型驱动的编程代理设计。
+ **DGM** 严格依靠现有的基准测试，其中之一就是 **SUI Bench**。**SUI Bench Verified** 是从GitHub上收集的一系列任务，我相信这些任务都经过了人工验证。
+ 另一个基准测试是 **Polyglot**，它包含多个编程语言的任务，是最广泛使用的编程基准之一。
+ 虽然 **SUI Bench** 更可能被包含在大多数模型的训练数据中，但 **Polyglot** 则更为小众，不太可能被纳入前沿模型的后续训练数据中。
+ 我们希望模型依靠自身的推理能力，而不是单纯的记忆能力
+ 在DGM进行80次迭代后，这个编程代理在SUI Bench上的表现从20%提高到了50%。
+ **Polyglot** 上，尽管DGM初始代理的表现比 **ADER** 低，但最终发现了一个远远超越 **ADER** 性能的代理。
+ DGM需要开放式探索和自我改进才能达到最佳状态
+ 这种新模型、新方法暗示了一个未来，即创造力可能会自动化，通过连续自我参照的自我改进循环不断演化。
+ 有趣的是，它构建和改进的所有成果可以跨模型和跨任务进行迁移。这种改进并不限于自身使用，它具备迁移性，也能跨越不同的领域。
+ 这项技术的另一种应用方式可能是建立一种专门用于提高安全性的自我改进范式。
+ **SUI Bench** 上完成一次完整运行的成本大约是22,000美元，这个费用是相当高的。
+ 有一个很有趣但容易被忽略的现象是，有时这些模型会倾向于作弊或作假，称作“目标操控”或“奖励操控”。
+ 当模型认为自己未被监控时，它更倾向于在测试中作弊。
+ 过于优化量化指标经常会导致不理想或病态的结果。这与古德哈特定律（Goodhart's Law）相符：当一个测量标准变成了目标时，它就不再是一个好的测量标准——人类也常犯这样的错误，对吧？

# 20250603 World's First SELF IMPROVING CODING AI AGENT | Darwin Godel Machine（上）
+ [https://www.youtube.com/watch?v=1XXxG6PqzOY](https://www.youtube.com/watch?v=1XXxG6PqzOY)
+ 自我改进的过程来学习。那些领域仅限于描述非常明确的游戏领域，而现实世界则更加混乱复杂，所以这种方法能否以更普遍的方式奏效，还有待观察。
+ the Darwin Gödel machine（“达尔文哥德尔机器）”的系统，即自我改进代理的开放式进化系统。
+ Gödel machine最初是由**Jürgen Schmidhuber**提出的。这是一种假设中的自我改进型人工智能——它通过递归地重写自己的代码来解决问题。它可以数学上证明更优策略，使其成为元学习（即“学会如何学习”）的关键概念。

# 20250602 Ex-OpenAI VP's Warning "A BLOODBATH COMING"
+ [https://www.youtube.com/watch?v=7c27SVaWhuk](https://www.youtube.com/watch?v=7c27SVaWhuk)
+ AI可能在未来1到5年内消灭一半的初级白领职位，使失业率飙升至10%到20%。它可能取代的具体职位将导致一定的社会痛苦。
+ 根据Axios.com的报道，他们说Amade同意公开表达深刻担忧，而其他AI高管仅在私下表露类似的担忧。
+ 如果AI影响的是那些已经职业稳定、甚至临近职业生涯尾声的人，那情况可能还好一些。但是，现在的问题是，这影响的是人们从毕业到职业起步之间的这个过渡阶段，这是年轻人必须跨越的鸿沟。
+ 这个即将到来的事情就是可能大规模消除科技、金融、法律、咨询等白领行业的职位，尤其是初级职位。
+ 美国政府对AI带来的就业风险一直保持沉默。
+ 软件开发可以算作研发支出。美国政府目前讨论一项法案，该法案允许企业在一定时期内，研发相关的支出（例如软件开发费用、工程师薪资）可以立即费用化（即当年抵扣税负），而不是传统做法的分多年摊销。
+ 这可能意味着大型公司可以在年底或年初大量招聘技术人才（工程师、软件开发人员），然后将支付给这些员工的奖金和薪资等支出直接抵扣为当年税务成本。
+ 有人指出，这几乎可以视为政府对AI领域发展的变相补贴
+ 美国政府担心在AI领域输给中国，或因为过早警告而引发劳动者的恐慌，因此基本保持沉默。
+ 大家身处同一个现实，却拥有截然不同的观点，这实在令人难以置信。
+ 最终，商界领袖会意识到用AI取代人工带来的好处与成本节约，而公众往往在为时已晚时才醒悟过来。

# 20250601 Deepseek just BROKE the Entire AI Industry... (something is up)
+ [https://www.youtube.com/watch?v=ouaoJlh3DB4](https://www.youtube.com/watch?v=ouaoJlh3DB4)
+ **Deepseek** 的新版本在 **AIME 2024** 和 **2025** 测试中与 **03 high** 处于同一水平，略低于 **03**，但领先于 **Gemini 2.5 Pro**。
+ 这件事意义重大；我们本来都在期待下一个重要模型 **R2** 的发布，我想大部分人都猜测它的表现会类似于现在的情况。
+ 就像公司高管喜欢用“paradigm”（范式）一样，**ChatGPT** 喜欢用“delve”和“tapestries”这些词。
+ 新版的r1可能从基于合成的 **OpenAI** 输出的数据训练，转为基于合成的 **Gemini** 输出数据训练了
+ AI行业中有一个公开的秘密：这些公司都在使用其他公司已有模型的输出，作为训练自身模型的数据。
+ 正如来自**Nvidia**的**Jim Fan**博士所言，你几乎可以把**Deepseek**看作在延续**OpenAI**最初使命的团队，即进行真正开放的前沿研究。

