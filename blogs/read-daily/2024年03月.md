# 20240322 Open Source AI Agents STUN the Industry | Open Interpreter AI Agent + Device (01 Light ) is out!
[https://www.youtube.com/watch?v=jWr-WeXAdeI](https://www.youtube.com/watch?v=jWr-WeXAdeI)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1711073871268-8e30ac70-ba22-4639-a877-cc1a6ea90a39.png#averageHue=%23f6f6f5&clientId=ub01e52b5-e352-4&from=paste&height=504&id=u15acee0e&originHeight=1008&originWidth=1254&originalType=binary&ratio=2&rotation=0&showTitle=false&size=246360&status=done&style=none&taskId=u2183d6fe-01b9-4558-b6f1-5f0694d27ae&title=&width=627)

- 01 Light,第一台开源的语言模型计算机
- 未来几周AI设备的寒武纪大爆发
- 在Facebook、Instagram和Twitter时代之前,有一些开发者在我们其他人之前就准确地知道将要发生什么
- 大多数软件都有一个开源的一面
# 20240321 Elon Musk Reveals His STUNNING Human Neuralink Patient | The Brain Computer Interface N1
[https://www.youtube.com/watch?v=STLkq978tL8](https://www.youtube.com/watch?v=STLkq978tL8)

- 如果你想象失去了与现实世界互动的如此多的功能,至少恢复了与电脑互动以及通过电脑获得的所有东西的能力,我的意思是,这似乎是一件非常非常重要的事情
- 如果你想一下,你能多快地思考,而你能多快地,比如,大声说出来,或者甚至用手打字,如果你能用这样的东西做,做这件事,你与任何电脑或任何你正在使用的东西互动的能力会快得多,无缝得多。
# 20240320 NVIDIA Reveals STUNNING Breakthroughs: Blackwell, Intelligence Factory, Foundation Agents [SUPERCUT]
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1710945704807-3bf82e52-492e-4cf6-9ccf-da0e625d42a1.png#averageHue=%23040404&clientId=ud3328e8d-6f2e-4&from=paste&height=472&id=ub8cf4a5d&originHeight=944&originWidth=1788&originalType=binary&ratio=2&rotation=0&showTitle=false&size=408544&status=done&style=none&taskId=uf4bef5eb-5d7d-4a51-9250-9117513326c&title=&width=894)
[https://www.youtube.com/watch?v=INnxrkmTvkg&t=24s](https://www.youtube.com/watch?v=INnxrkmTvkg&t=24s)

- 如果你将模型的大小增加一倍,就是将大脑的大小增加一倍,你需要两倍的信息来填充它。
- 大约几万亿个参数,大约几万亿个令牌,当你将它们相乘时,大约每秒30、40、50亿万亿次浮点运算。
- Blackwell的推理能力是Hopper的大约30倍
- NVLink交换机的通信速度比过去使用最快网络快了近10倍
- 可以从视频中理解人类,在仿真中训练模型,并最终将它们直接部署到物理机器人上
- Isaac Lab、Osmo和Groot,我们正在为下一代AI驱动的机器人技术提供构建模块



# 20240319 Sam Altman "SHOCKING UPDATES" to Lex | AGI, GPT-5, Elon Musk, Ilya, Living in a Simulation and Sora
[https://www.youtube.com/watch?v=7G7noECab4A](https://www.youtube.com/watch?v=7G7noECab4A)

- 我认为AI和惊喜是不搭配的
- 开源模型绝对有一席之地,特别是人们可以在本地运行的较小模型。我认为对此有巨大的需求,我认为将会有一些开源模型,也会有一些闭源模型,在这方面它不会与其他生态系统不同。
- im Fan博士说,如果Sora是在大量合成数据上训练的,例如使用虚幻引擎5,他不会感到惊讶
- 液体模拟需要38小时,然后渲染需要40小时
- 如果有一个比人类更酷、更好的东西,人类只会关注它两天,然后就会回到人类身上,这似乎是根深蒂固的。
- 1997年,国际象棋特级大师卡斯帕罗夫在与来自IBM的国际象棋计算机"深蓝"对弈后辞职,你知道,他说他失去了斗志
- 来编程语言可能会发生很大的变化,自然语言可能会在编程中扮演更重要的角色。英伟达的首席执行官黄仁勋似乎也表达了类似的观点,认为未来计算机和程序应该不需要编程,人们只需要专注于自己的领域知识和技能
# 20240318 Elon Musk STUNNING Reveal of Grok | NOT aligned, MUCH Bigger, Open Source. There is no doubt left...
[https://www.youtube.com/watch?v=AcxAYo4QyeQ](https://www.youtube.com/watch?v=AcxAYo4QyeQ)

- GROK 有3140亿个参数,是一个由8个专家模型组成的混合专家模型,并且不是RLF
- 将混合专家模型的参数数量与单一模型的参数数量进行比较并不恰当,因为它们的结构不同
# 20240318 Swarms of AI Agents STUN the Entire Industry | 100 Million Jobs GONE? | Devin, Maisa, Groq & more
[https://www.youtube.com/watch?v=g78Sp-X4ykg](https://www.youtube.com/watch?v=g78Sp-X4ykg)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1710688269367-357e9a3e-e126-4f7f-8b64-f74e5ab77079.png#averageHue=%23fcf0e0&clientId=u9102dbef-4cda-4&from=paste&height=366&id=u480f4ec1&originHeight=732&originWidth=1200&originalType=binary&ratio=2&rotation=0&showTitle=false&size=344195&status=done&style=none&taskId=u4c4034b3-46b7-4b77-b3eb-67216a96325&title=&width=600)

- 在Cognition实验室宣布Devin之后,许多其他类似的代理也随之而来
- Devon这个AI编码器真正有趣的地方在于全新的交互模式,你可以随时像对一个人一样与它交谈,它就会在后台一直运行,执行和调试你的想法
- Groq自研的是一种名为张量流处理器（TSP）的新型处理单元，并将其定义为「语言处理单元」，即LPU；Groq的使命是为生成式人工智能推理速度设定标准
- Maisa推出的一种新型技术框架：KPU 通过将推理与数据处理分开，优化和提升了大语言模型处理复杂任务的能力。
- 捣蛋鬼行为可能会令人讨厌,即使是大科技公司现在似乎也在从事各种形式的捣蛋鬼行为,试图让他们的产品看起来比实际更好,以压过竞争对手
- 二手谣言： Sam Altman 认为 GPT-4.5 将使全球 1 亿个工作岗位自动化
- 大多数地方发现要有一个开放的网络而不出现机器人几乎是不可能的,几乎没有办法防御这种情况,无论你的防御多么彻底
- 很久以前,世界上最聪明的人都在从事各种物理项目、核能等方面的工作。稍微近一点,世界上最聪明的人都在研究如何让你点击广告,如何让你参与到各种在线内容中。而现在,所有这些最聪明的人 - 现在他们的数量多得多,当他们能在全球范围内相互交流时 - 他们都在研究这个:AI智能体、芯片,这个基础设施中他们能派上用场的任何东西。
- 模型排名 [https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)
- 人类智能非常昂贵。
- 拥有一些东西来跟踪你的日程,这曾经只有最富有的人才能享受,雇佣人员,雇佣助手
- 我们的工作是创造计算技术,使得没有人需要编程,编程语言就是人类语言。
- 现在世界上每个人都是程序员。这就是人工智能的奇迹。
- 我们提高每个人的技能至关重要。提升技能的过程将是令人愉快和惊喜的。
- ,你需要擅长你选择擅长的任何事情,而人工智能提供了你可能需要的所有其他东西。
- 但我认为这里真正重要的一点是,我们都需要提升技能,而且可能不是我们习惯的相同技能。



# 20240315 Extropic Beff Jezos on AGI Computing | Better than Quantum Computing? | Accelerate or Die
[https://www.youtube.com/watch?v=vHfzaQz43PU](https://www.youtube.com/watch?v=vHfzaQz43PU)

- 摩尔定律：微芯片上的晶体管数量大约每2年翻一番
# 20240314《Elon Musk》36 Manufacturing Tesla, 2010–2013
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1710423268562-c8ff1012-c259-4681-8f3b-a56fde7cdb9a.png#averageHue=%238d8d8d&clientId=uc94effa2-49ea-4&from=paste&height=746&id=ubd21085f&originHeight=1492&originWidth=1210&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1089503&status=done&style=none&taskId=u6dcda181-efc7-4909-addc-b5fe2c50977&title=&width=605)

- Fremont
   - 通过将工厂迁往国外,美国公司节省了人工成本,但他们失去了每天改进产品的感觉。Musk逆转了这一趋势,主要是因为他想要严格控制制造过程。
   - Musk认为,设计用于制造汽车的工厂——"制造机器的机器"——与设计汽车本身同样重要
   - Tesla的设计-制造反馈回路给予其竞争优势,使其能够每天进行创新。
   - "Steve只需要把概念和软件搞定,但制造是外包的,"Oracle CEO Ellison说,"Elon承担了制造、材料、巨大的工厂。"乔布斯喜欢每天走过苹果的设计工作室,但他从未参观过他在中国的工厂。相比之下,马斯克花在走装配线上的时间比走设计工作室的时间还多。
   - 在Tesla收购工厂的一个月后,Musk就让公司上市,这是自1956年福特以来美国汽车制造商的首次IPO。到了当天结束时,股市下跌了,但Tesla的股票上涨超过40%,为公司提供了2.66亿美元的融资
   - 2008年底时,Tesla几乎已经死了。而现在,仅仅18个月后,它就成为了美国最火爆的新公司。
- 产品质量
   - Musk最喜欢的一个词——也是一个概念——是"hardcore（硬核）"。
- The Nevada battery Gigafactory
   - "一开始看似是一个完全无解的问题,"施特劳贝尔说,"实际上变成了一个非常有趣、无拘无束、疯狂的头脑风暴机会,让我们可以说'哇,这实际上是一个做些独一无二的事情的机会。'"
   - "他是个行为反复无常的人,你无法预料他会说什么做什么。但突然之间,他就把一切都掌控好了。"
   - 当被问及为什么松下决定达成这笔交易时,他回答说:"我们太保守了。我们是一家有95年历史的公司。我们必须改变。我们必须借鉴一些Elon的思维方式。"

# 20240313 World's First AGI Agent SHOCKS the Entire Industry! (FULLY Autonomous AI Software Engineer Devin)
[https://www.youtube.com/watch?v=1RxbHg0Nsw0](https://www.youtube.com/watch?v=1RxbHg0Nsw0)

- Devon已经成功通过了 AI公司的实际工程面试，并且甚至在Upwork上完成了真实的工作
- BS：胡说八道
- ASAP： as soon as possible
- Cognition Labs已经筹集了由Founders Fund领投的2100万美元A轮融资
- 这件事真正有趣的地方在于，通常当你构建面向开发者的工具时，你会比面向所有人的工具有更少的限制
- 在解决现实世界GitHub问题的基准测试中,Devon的表现明显优于GPT-4。
# 20240312 Elon Musk to Open Source Grok AI | "Murdering AI, Cloning Humans & AI Gods" OpenAI's Scott Aaronson
[https://www.youtube.com/watch?v=jrQW2eA8FSc](https://www.youtube.com/watch?v=jrQW2eA8FSc)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1710255286170-8961fef0-8559-41ef-b94d-fb6f40a86c59.png#averageHue=%23dbcf83&clientId=u6a123dae-1bfc-4&from=paste&height=512&id=u659a4a46&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1823207&status=done&style=none&taskId=u79cce687-f95a-4545-87bb-f67392845ce&title=&width=512)

- 一个重大问题:当人工智能在各方面都比我们强时会发生什么,是什么让我们与众不同,是什么让我们独一无二,以及如何安全地创造人工智能,使其不会因我们低人一等而决定消灭我们。
- 数字水印的解决方案：通过利用语言模型的概率性质,在生成过程中秘密编码一个信号,后续可以用来检测文本是否由人工智能生成
- 即使数字水印技术真的部署了,有足够知识和决心的人也能够移除水印,或者从一开始就生成没有水印的输出。
- 肖邦的名言:"天才击中了别人看不见的目标,而天赋击中了别人打不中的目标"
- 当我尝试用GPT写诗或用Dell画画时,我注意到一个奇怪的现象,那就是,无论人工智能的创作多么好。它可以创作出比我之前给你看的那首诗好得多的作品,但无论艺术品或诗歌有多好,我从来不会想要把它们裱框挂在墙上,真正将它们与众不同地区别对待
- 人类的短暂性、脆弱性、必死性将成为他们相对于人工智能的特殊性的核心来源.作为人类来说，First thing to do is to understand the fear of death，That's the root to everything 
- 如果其他所有区分人类和人工智能的特殊性来源都消失了,那么人类的短暂性、脆弱性和必死性将成为最后的区别所在
- 大脑本质上是嘈杂或模拟的,在当前的神经科学看来,就像讨厌的随机噪音,但实际上正是这些东西将个人身份,甚至可能是意识联系在一起
- 量子力学中有一个基本事实叫做不可克隆定理,它说没有办法制造一个未知量子态的完美复制品。
- 事实上,当你测量一个量子态时,你不仅通常无法了解复制它所需的所有信息,而且通常会破坏你拥有的
- Geoffrey Hinton,,深度学习的创始人之一,最近提出一个想法,也许在我们解决对齐问题之前,我们应该只构建在嘈杂模拟硬件上运行的强大人工智能,就像我们的大脑一样。
- 给人工智能灌输一种新的宗教,其核心教义是重视和保护人类的特殊性,因为人类的创造力位点是独一无二、与大脑硬件不可分割、注定会衰亡的。人工智能应该让人类和平生活,给他们自主权,支持他们繁荣,听从他们的愿望

# 20240311《Elon Musk》35 Marrying Talulah
September 2010

- “我可以走一条艰难的道路”
   - “the child within the man.”
- 东方快递
   - Riley喜欢举办有创意的派对，而Musk，尽管在社交上有些笨拙（或许正因为如此），对它们却有一种奇怪的热情。
   - Musk并没有很多稳定而踏实的关系，他的生活中也没有很多稳定而踏实的时期
- 在Musk为数不多的这种关系中，他与Riley的关系是其中之一，他与她共度的岁月——从他们2008年的相遇到他们2016年的第二次离婚——最终成为他一生中相对稳定的最长时期。



# 20240310 OpenAI is INVESTIGATED by Law Firm. The TRUTH about the Board's Firing of Sam Altman is Revealed...
[https://www.youtube.com/watch?v=Y1_EPch_MKw](https://www.youtube.com/watch?v=Y1_EPch_MKw)

- immy apples，可能是Sam Alman的替代账户，他的匿名Twitter账户
- 国际律师事务所WilmerHale调查了2023年11月和12月Sam Altman和Greg Brockman被移除出OpenAI董事会和Sam Altman作为CEO被终止职务的事件
- 事件的根本原因是人际关系和信任的失衡，而非技术或财务问题
- Anthropic的聊天机器人，“Claw”，它被故意延迟以避免推进AI能力的发展速度
- Toner过去曾将自己描述为一名有效的利他主义者
- 有效利他主义（Effective Altruism，简称EA）是一种哲学和社会运动，它强调使用证据和理性来确定如何使用资源以最有效地帮助他人。有效利他主义者认为，在做善事时，不仅要出于好意，更要确保行动的效率和效果，即用有限的资源实现最大的正面影响。
- NIST的工作人员因预期将有效利他主义AI研究员任命到美国AI安全研究所而反抗
- EA，有效利他主义，你知道，它被定义为一个使用证据和理性来确定如何尽可能地帮助他人的智力项目，但它变成了一个类似邪教的高度影响力和富有的追随者团体

# 20240309《Life of PI》Toronto and Pondicherry 5

- 的确，我们所遇之人能够改变我们，有时这种改变如此深刻，以至于我们之后的自我与从前大不相同，连名字也随之改变。举例而言，Simon被称作Peter，Matthew亦名Levi，Nathanael即是Bartholomew，那个不是Iscariot的Judas，改名为Thaddeus，Simeon有时被称为Niger，Saul转而为Paul
- 这似乎是人类自然法则，那些住在海边的人对游泳者持怀疑态度，就像那些住在山区的人对登山者持怀疑态度一样
- 重复不仅对动物的训练很重要，对人类也是如此

# 20240208 The Internet Goes EXTINCT as Gen AI Takes Over | The Dark Forest Internet & Proving Your "Humanness"
[https://www.youtube.com/watch?v=3NN5L-f0cDo&t=1s](https://www.youtube.com/watch?v=3NN5L-f0cDo&t=1s)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1709905849832-103eeb98-94ec-4952-86c3-088ccd1b4844.png#averageHue=%23fcfcfc&clientId=u2e46fc49-c8e6-4&from=paste&height=1045&id=u6085b9f5&originHeight=2090&originWidth=1800&originalType=binary&ratio=2&rotation=0&showTitle=false&size=2099912&status=done&style=none&taskId=ub28d88b8-da75-4a0d-95c2-86ab3131ccc&title=&width=900)

- 扩展的暗森林： 生成式AI证明你是网上充斥着生成式AI内容的人类
- 互联网优化已经导致了信息的泛滥，而AI技术的进一步发展可能会加剧这一问题。
- “死互联网理论”，该理论认为大部分的互联网内容是由AI生成的，能够通过人类难以区分机器与人类的反向图灵测试
- 反向图灵测试呢？图灵测试是这样一个想法，即在什么时候人工智能会变得足够智能和高级，以至于能欺骗我们认为它是人类。
- 网络开放性和机器人是无法避免的，几乎没有办法防御这种情况，无论你的防御多么彻底。
- 不过有一种方式真的很有效，那就是收取支付
- Sybil攻击是一种网络安全威胁，其中一个攻击者在网络或系统中创建大量虚假身份（被称为Sybil节点），以试图控制或破坏该网络的功能。这种攻击的名称来自于弗洛拉·瑞塔·谢伯的书《Sybil》，讲述了一个因多重人格障碍而拥有多个身份的女子的故事，象征着一个实体拥有多个虚假身份。
- 一种有效的方法来验证网络用户的人类身份，而不泄露过多的个人信息，以此来增强网络安全和减少虚假信息的传播。"人性证明"被提出作为一种潜在的解决方案，但其实施可能涉及生物识别数据的收集和处理
- 如何在缺少政府颁发的身份证明或中央化身份管理系统的情况下验证一个人的真实性。这是寻找能够提高网络安全和用户隐私保护的验证方法的动因
- UBI 是“无条件基本收入”（Universal Basic Income）的缩写。这是一种社会保障制度，旨在为所有（或几乎所有）公民或居民提供一定数量的无条件的金钱支付，无论个人的其他收入如何，都不需要工作要求或其他条件。UBI 的目的是减少贫困，提高生活标准，促进社会公正和经济平等。它也被看作是对应对自动化、人工智能发展和未来可能导致的工作岗位减少的一种解决方案。
# 20240207 华语母语者最易犯的错误及破解之道
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1709823920522-6f858513-ea98-40d7-bf34-f86341b2185b.png#averageHue=%23e9e9e9&clientId=u4542507b-314f-4&from=paste&height=329&id=u04bcc97a&originHeight=658&originWidth=1142&originalType=binary&ratio=2&rotation=0&showTitle=false&size=230596&status=done&style=none&taskId=ued3db9d7-182c-4788-a57c-e25f3725ba4&title=&width=571)
[https://www.youtube.com/watch?v=iZ60WZlZHE4&list=WL&index=2](https://www.youtube.com/watch?v=iZ60WZlZHE4&list=WL&index=2)

- Dark L 和 Light L 音
   - Light L 放在开头，比如 Light, Little , Lead 跟中文的l发音很像
   - Dark L 出现在中间或者末尾，Gril, World, Real,Milk ,Local, 有点模糊的卷起来的声音
- th 音
   - 清辅音，声带不振动，比如， Three , Thought,
   - 浊辅音，声音要带振动，比图， This, That
- Ng
   - Sing, king 鼻腔共鸣
   - n 
- V 
   - 门牙露出来，轻轻放在下嘴唇
- I
- B , D ,G , K , P, T 结尾的词，辅音结尾要短
- 元音
   1. **发音位置和方式**：元音主要通过调整舌位和嘴型来改变发音，而辅音则涉及到气流在口腔或咽喉中被阻碍的具体部位，如唇部、舌尖、喉咙等。
   2. **声音的持续性和清晰度**：元音通常能够持续发音，并且声音较为清晰；辅音的发音则比较短暂，有些辅音（如爆破音）发音非常迅速。
   3. **在单词中的作用**：元音在单词中充当核心音节，是构成音节的必要元素；而辅音主要在词首、词中、词尾位置，起到与元音搭配构词的作用。
# 20240207 Claude 3 "Self-Portrait" Goes Viral | Beats GPT-4 Benchmarks | Why does it appears SELF-AWARE?
[https://www.youtube.com/watch?v=SsbCuWe7WRs](https://www.youtube.com/watch?v=SsbCuWe7WRs)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1709812914767-d2e6431a-c7f5-4504-a609-25a0d19131c1.png#averageHue=%23d6795a&clientId=ue70f8b23-bb1a-4&from=paste&height=810&id=u4142833a&originHeight=1620&originWidth=2880&originalType=binary&ratio=2&rotation=0&showTitle=false&size=2617966&status=done&style=none&taskId=u7202e686-9169-4886-adde-078c45e68f8&title=&width=1440)

- 推理能力通常来自于结合两种模型不太可能有训练数据的不同领域。关于GPT-4的这篇研究论文称为“'Sparks of egi'（egi的火花）”
- 大象的预训练更专门化，更适合它们特定的生态位
- 当你要求它们融合两个概念以产生一种新概念或新想法时，假设这个新想法不在它们的训练数据中，一般来说，模型的质量越好，它就越能合成那种想法
- 询问模型是否能够理解两个概念并能够做出超出其训练数据的推理，这是测试这些模型的通用能力的最佳方法之一
- Cloud 3 Opus能够在大量文本中找到一个非常特定的小片段，这是以前未曾见过的行为
- 大模型的"meta-awareness"（元认知能力）是指模型能够对自己的知识、思维过程以及任务的性质有所认识和理解的能力
- TF-IDF是一种用于信息检索和文本挖掘的常用权重计算方法，用于评估一个词语对于一个文件集或一个语料库中的其中一份文件的重要性。
- 所有视觉模型都害怕的东西开始，那就是Costco收据
- 数苹果是一件这些模型做得不好的事情
# 20240206 OpenAI Insider Talks About the Future of AGI + Scaling Laws of Neural Nets
[https://www.youtube.com/watch?v=zeju5OXAVzk&t=53s](https://www.youtube.com/watch?v=zeju5OXAVzk&t=53s)

- 第一个神经网络在50年代被创建，而现代神经网络只是更深，意味着它们包含更多层
- 今天大多数主要的AI技术都源于1950年代的基础研究，结合了一些较小的工程解决方案，如反向传播和Transformer模型
- 最近AI能力的爆炸式增长只有两个原因：规模和数据
- 卡马克（Minecraft的创建者）认为AGI的技术难题在很大程度上已经被解决
- 解决AGI的关键点可能非常简洁，足以被概括在很小的空间内，很多可能被隐藏在过去几十年的各种文本和教科书中
- 人类大脑中有多少参数，突触或参数呢，通常引用的数字是100万亿，超过了银河系中的恒星数量。ChatGPT-4的参数量是1.8万亿个参数，gpt3.5是1750亿。猫有2500亿个突触，狗有5300亿个突触。突触数量通常似乎预示着更高的智力。
- 大象的数量比人类多，但表现出更低的智力，他在某种程度上解释说，数据的质量可能是这些例外的答案。
- AGI 有多少参数量呢，最大可能是1000万亿
- 一个量子计算机的专家正在OpenAI工作，涉及AI的安全性和对齐问题

# 20240305 《西藏度亡经》正文

- 初期中阴明光
- 续发中阴明光
- 实相中阴
   - 业影即时闪现
   - 中阴的6种境界：
      - 本然中阴
      - 梦境中阴
      - 等待中阴
      - 临终中阴
      - 实相中阴（目前处于这个阶段）
         - 喜乐部和持明部诸尊
         - 忿怒部饮血诸尊
      - 投生中阴
# 20240304《Life of PI》Toronto and Pondicherry 4
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1709540099056-e8c3fad4-5284-4706-8165-520d160bc034.png#averageHue=%23b3bc76&clientId=uee211344-c369-4&from=paste&height=749&id=u016bb4c4&originHeight=1498&originWidth=1124&originalType=binary&ratio=2&rotation=0&showTitle=false&size=2756681&status=done&style=none&taskId=uec4ac15b-bf4b-44a3-8a74-ee190be838f&title=&width=562)

- But language founders in such seas. Better to picture it in your head if you want to feel it.（但语言在这样的海洋中失去了方向，如果你想感受它，最好在你的脑海中描绘它）
- 一个常见的误解，即野生动物自由即意味着它们快乐
- 实际上在野外，野生动物既不在空间上自由，也不在时间上自由，甚至在个人关系上也不自由
- 动物就是这样，保守，甚至可以说是反动的。微小的变化都可能使它们不安。它们希望事物每天、每月都保持原样。惊喜对它们来说是极其不愉快的。
- 我们不是说：“没有比家更好的地方”吗？这确实是动物所感受到的。动物是有领地意识的。这是了解它们思维的关键。只有熟悉的领地才能让它们实现野外的两个不懈的要求：避开敌人和获取食物和水。
- 甚至有人会主张，如果动物能够以智慧进行选择，它们会选择住在动物园，因为动物园和野外的主要区别在于前者缺乏寄生虫和敌人，食物丰富，而后者则分别缺乏和丰富。
- 动物园不再受人们欢迎。宗教面临同样的问题。它们都被关于自由的某些幻觉所困扰

![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1709565068149-2a6ae744-5b18-4f30-ab85-e2069abf482b.png#averageHue=%233f4935&clientId=uf296e90d-dd84-4&from=paste&id=qGiQa&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1027279&status=done&style=none&taskId=u48c7ddec-3a17-4243-a29f-9c3cdba9524&title=)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1709564980951-92e95603-74b6-4ff1-896b-80e151868cae.png#averageHue=%236b8154&clientId=u652d6710-3193-4&from=paste&id=dygRB&originHeight=1024&originWidth=1024&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1084453&status=done&style=none&taskId=u03de54cb-8c4e-48dd-91cc-8dfdca2352e&title=)

# 20240303 Vercel AI SDK
[https://sdk.vercel.ai/docs](https://sdk.vercel.ai/docs)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1709469264276-ad07db95-f3c5-45ef-a344-c2973d188710.png#averageHue=%23999999&clientId=u1015d0b0-315e-4&from=paste&height=208&id=u9d131193&originHeight=416&originWidth=800&originalType=binary&ratio=2&rotation=0&showTitle=false&size=144687&status=done&style=none&taskId=u25ab698e-908d-44cc-9613-ca8fa19078b&title=&width=400)

- Vercel AI SDK ：用于构建 AI 驱动的用户界面的开源库
- 基础概念
   - Streaming（流）：流式响应可以在响应变得可用时传输部分响应而不是完整响应
   - 和 Cancellation（取消）
      - Stream Back-pressure （流背压），描述了生产者（producer）产生数据的速率高于消费者（consumer）处理数据的速率时发生的情况。在这种情况下，如果不加以控制，数据可以积累起来，导致内存使用增加，甚至系统崩溃。
      - 使用懒加载可以做到生产和消费一致，比如 生成器的 generato（生成器）r 的 next
   - 提示工程 [https://www.promptingguide.ai/zh](https://www.promptingguide.ai/zh)
   - 响应缓存
   - 工具
   - 生产式UI
      - AIState 和 UIState
      -  嵌套UI流式处理
#  20240303 China's Humanoid Robot JUST SHATTERED World Record! $90,000 Model Begins Deployment Across US and EU
[https://www.youtube.com/watch?v=WWAnJX889j0&t=365s](https://www.youtube.com/watch?v=WWAnJX889j0&t=365s)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1709460433072-d8051e0d-4a56-418a-a4c9-9f3a70149097.png#averageHue=%23303a3e&clientId=udd287200-2229-4&from=paste&height=683&id=u7a57cd51&originHeight=1366&originWidth=1568&originalType=binary&ratio=2&rotation=0&showTitle=false&size=235912&status=done&style=none&taskId=ub7b2a858-52c3-4850-b3ad-f641b7dd44d&title=&width=784)

- 人形机器人设定了一个新的世界纪录，它的最大速度达到了每秒3.3米（大约10.8英尺），超过了人类慢跑的速度
- 人形9万美元的机器人H1，在美国，这个价格与高端皮卡车相当
- 四足机器人B2 1600美元
# 20240302 BREAKING: ELON MUSK OPEN AI BOMBSHELL "AGI Achieved Internally", Q-STAR, Lawsuit to DISSOLVE OpenAI
[https://www.youtube.com/watch?v=jPuLfomqS1Q](https://www.youtube.com/watch?v=jPuLfomqS1Q)

![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1709385582438-99013e46-58c5-4697-a47b-ef0477a0a3fe.png#averageHue=%23efa79a&clientId=ue4390975-0be6-4&from=paste&height=377&id=u5924e6c8&originHeight=754&originWidth=1556&originalType=binary&ratio=2&rotation=0&showTitle=false&size=219838&status=done&style=none&taskId=ud239cd7f-a2a9-4c4f-9f90-e742f1c2be7&title=&width=778)

- 2000-2010年的早期，一个叫做深度学习的旧算法因为硬件的进步而变得实用。这导致了一场几乎一夜之间的革命，所以这种AI，我们今天谈论的通用目的AI，就是这样开始的。
- 这是从单一目的AI向更多学习型AI、通用目的AI的转变。它之所以不同，是因为这种AI通过训练实例学习每个任务，本质上是自我编程。
- Musk看到AGI的存在性威胁的地方，其他人却将AGI视为利润和权力的来源
- 法庭文件谈到了Q*，OpenAI正在开发一个秘密算法，称为Q*。这是从OpenAI泄露出来的，似乎已经被Sam Altman确认
- OpenAI最初的使命是一个非营利AI实验室的提议，其目标是赶上Google在AGI的竞赛中，但采取不同的方法和使命
- GPT-4的内部设计被保密，除了OpenAI，据信还有微软知道
- GPT-4可视为接近AGI的原型或前身
- GPT的一个限制是它不能回溯，一旦它们开始生成回应，即使结果是一个错误，它们也会继续下去
- 如果这种商业模式有效，它将彻底重新定义风险投资的实践方式；这将允许聪明的投资者基本上使用非营利组织的税前捐赠在该非营利结构下开发某物，然后通过与追求利润最大化的企业伙伴合作来丰富自己
- 马斯克要求美国法院判定Q star 是否是agi
# 20240301 The Illustrated Transformer
[https://jalammar.github.io/illustrated-transformer/](https://jalammar.github.io/illustrated-transformer/)
![image.png](https://cdn.nlark.com/yuque/0/2024/png/250863/1709296600614-7328ede1-2256-4768-bc14-56c024396f14.png#averageHue=%23fefefd&clientId=udd499d5e-4b0a-4&from=paste&height=402&id=ub0929a81&originHeight=804&originWidth=1436&originalType=binary&ratio=2&rotation=0&showTitle=false&size=145244&status=done&style=none&taskId=ueb788713-fb31-4771-a91b-eaa8ec8d622&title=&width=718)

- 在训练阶段，Transformer 架构通过自注意力机制（Self-Attention Mechanism）允许模型有效地处理序列数据
- 在推理阶段，Transformer 同样展现出其优势。由于其并行处理能力，Transformer 能够快速生成响应或完成任务，这对于需要实时响应的应用来说非常关键。此外，Transformer 的可扩展性也使得它能够通过增加模型的大小来提升性能，这是通过增加层数（depth）或者模型宽度（width）来实现的。
- encoder在结构上完全相同（但它们不共享权重）
- 前馈神经网络（FFNN）在处理序列中每个位置的输出时是独立的，并且对所有位置应用的是相同的网络结构和参数，这使得这一处理过程非常适合并行化
- 编码器的输入首先流经自注意力层，该层可帮助编码器在编码特定单词时查看输入句子中的其他单词
- 解码器具有这两个层，但在它们之间是一个注意力层，可帮助解码器专注于输入句子的相关部分
- Transformer 的一个关键属性，即每个位置的字都流经编码器中自己的路径
- 残差连接（Residual Connection）和层归一化（Layer-Normalization Step）是深度学习中用于改善网络训练效率和效果的两种技术。
- “编码器-解码器注意”层的工作方式与多头自注意力类似，不同之处在于它从其下面的层创建其查询矩阵，并从编码器堆栈的输出中获取键和值矩阵。

