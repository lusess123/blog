# 20240731 META drops another Open Source Model! SAM 2 is leagues above... #AI #每日陪读
+ [https://www.youtube.com/watch?v=5NUJWMqvz64](https://www.youtube.com/watch?v=5NUJWMqvz64)
+ segment anything model 2：第一个用于图像和视频实时提示对象分割的统一模型，[https://github.com/facebookresearch/segment-anything-2](https://github.com/facebookresearch/segment-anything-2)
+ **Rayband Meta Glass**，将AI引入虚拟世界的愿景

# 20240730 Why study positive psychology? - positive psychology 2  上 #每日陪读  #心理学
[https://www.youtube.com/watch?v=O7AvWH5Bf4U&list=PLg9esVacXkzYczOgcGpf5Iji38-BVQ1zs](https://www.youtube.com/watch?v=O7AvWH5Bf4U&list=PLg9esVacXkzYczOgcGpf5Iji38-BVQ1zs) #链接收藏

+ 这门课是为任何对积极心理学感兴趣以及想要变得更幸福的人而开的
+ 负面研究和正面研究之间的比例，你得到的比例是21:1
+ 六个月的研究中，80%的哈佛学生在过去一年中经历过抑郁
+ 47%的哈佛学生在过去一年中经历了严重到无法正常生活的抑郁
+ 为什么要关注积极的一面？
    - 关注有效的东西很重要
    - 幸福不仅仅是消极状态的否定。这并不意味着只要摆脱我所经历的抑郁或焦虑，我就会自然而然地幸福。事实并非如此。事情不是这样的。
    - 预防很重要
+ **Resilience**（韧性）——一种在重大逆境或风险背景下表现为积极适应模式的现象
+ 他们乐观的想法是，“嗯，这次可能不顺利。以后会顺利的。我从刚刚发生的事情中学到了。”
+ 成为理想主义者就是成为现实主义者，因为我们有一种真正的内部需求，天生的理想主义需求。

# 20240729 $600 Billion AI Wave... software 3.0
 [https://www.youtube.com/watch?v=Gt5b7b2Ul5o](https://www.youtube.com/watch?v=Gt5b7b2Ul5o])

+ AI agent 是 software 3.0
+ 2007 年，Andrej Karpathy 说，Software 2.0 是用更抽象的、对人类不友好的语言编写的，比如神经网络的权重。
+ Mark Zuckerberg 的教师模型
+ 下一层次的价值和影响肯定是微调到特定的声音
+ 基础模型成为在现实世界中服务于所有这些用例的最后一英里
+ 实际上世界是由非常大的小众领域组成的
+ Software1.0 是我们人类编写代码让计算机做我们想要的事情
+ Software2.0 有点像是我们告诉这个过程我们想让它做什么，然后它去创建 AI 神经网络大脑来做我们想让它做的事情。
+ Software3.0 是使用基础模型，建一个数据集，并在其基础上训练一种小模型
+ 我的猜测是，20 年后，孩子们会自己生成定制的小 AI 模型，帮助他们，我不知道，记录他们的宝可梦，什么的

# 20240729 《positive psychology》 1  What is positive psychology（下） #每日陪读
[https://www.youtube.com/watch?v=O7AvWH5Bf4U&list=PLg9esVacXkzYczOgcGpf5Iji38-BVQ1zs]](https://www.youtube.com/watch?v=O7AvWH5Bf4U&list=PLg9esVacXkzYczOgcGpf5Iji38-BVQ1zs])

+ 用一种不那么技术性的方式来说，就是帮助一个人成为他能够成为的最好的人
+ "Ask and ye shall you receive", say the Scripture(“问，你就会得到，”圣经如是说)。这堂课是我认为教育的全部，即信息和转变的追求必须始于问题。
+ 彼得·德鲁克，“管理决策中最常见的错误来源是强调找到正确的答案而不是正确的问题。”
+ 两个显著特征解释了异常成功者和成功者之间的差异: 自信 和 提问题
+ 幸福不是二元的非此即彼，幸福存在于一个连续体上
+ Carl Rogers所说，“What is most personal is most general（最个人的即是最普遍的。）”
+ 当我们更好地理解自己，当我们认同自己时，我们就更能认同他人。事实上，这在很多方面是同理心的来源，是健康同理心的来源。
+ 当我们研究自己时，肯定会有偏见，这就是为什么仅仅研究自己是不够的。重要的是要反驳它，补充它，学术工作，研究他人
+ “我不会为这种复杂性的简单付出一分钱，但我会为复杂性另一边的简单付出生命。”

# 20240728 《positive psychology》 1  What is positive psychology（上）
 [https://www.youtube.com/watch?v=O7AvWH5Bf4U&list=PLg9esVacXkzYczOgcGpf5Iji38-BVQ1zs](https://www.youtube.com/watch?v=O7AvWH5Bf4U&list=PLg9esVacXkzYczOgcGpf5Iji38-BVQ1zs])

+ 他们在错误的地方寻找解释的原因
+ 工作坊和研讨会缺乏实质内容，常常是承诺过多而兑现不足
+ 平均每篇学术期刊文章被七个人阅读
+ 积极心理学是将学术界的严谨性、实质性、经验基础和科学性，与自助或新时代运动的可接近性相结合
+ 多次通过迷宫的老鼠，学到的远比那些在迷宫后花时间休息一下的老鼠少
+ 欧美文化跟印第安文化之间的一个显著特征是他们对待沉默的方式
+ 人本心理学本质上是对当时现有心理学的反应，人本心理学在很多方面孕育了积极心理学
+ 人本心理学被认为缺乏严谨的方法论，所以很容易成为新世纪运动
+ salutogenesis 健康本源学
+ 这门课不仅仅是关于信息的，它也明确地涉及到转变
+ 幸福更多地取决于我们的心态，而不是我们的地位或银行账户的状态。
+ 我们要做的是揭示我们内在的潜力，这种潜力一直在我们体内。也许我们只是没有看到。或者被某些东西遮蔽了
+ 消除限制，消除障碍，消除对失败的恐惧，消除小时候没有的东西。消除削弱和经常伤害我们的完美主义，消除对成功的害怕，消除那些对生活中的一些事情感到的反过来限制我们的内疚，消除我们在关系中的限制
+ 灵魂的成长更多是通过减法而不是加法soul grows more by subtraction than by addition
+ 知识是关于信息。智慧是关于转变。Knowledge is about information. Wisdom is about transformation
+ 常识并不常见 。Common sense is not that common
+ 这门课的意义。每周两次的不断提醒。不断提醒你已经知道的东西，你内心的东西。你内心的大卫。

# 20240727 logseq
[https://docs.logseq.com/#/page/start%20here](https://docs.logseq.com/#/page/start%20here)

+ <font style="color:rgb(17, 24, 28);background-color:rgb(251, 252, 253);">Excel 的燃料是数字块，Logseq 的燃料是单词块</font>
+ <font style="color:rgb(17, 24, 28);background-color:rgb(251, 252, 253);">大多数笔记工具都会尝试模拟纸张和文件夹，这意味着每个笔记都位于一个文件夹中。这使得重新混合你的音符变得困难，并且通常会导致有多个略有不同的音符副本。 Logseq 旨在解决这个问题，以便您可以集中精力进行最佳思考</font>
+ <font style="color:rgb(17, 24, 28);background-color:rgb(251, 252, 253);">每个项目符号都是一个块并且它可以连接到任何其他块或块集合(页面)</font>
+ <font style="color:rgb(17, 24, 28);background-color:rgb(251, 252, 253);">开始使用 Logseq 的两种常见方法是记笔记和任务管理</font>
+ <font style="color:rgb(17, 24, 28);background-color:rgb(251, 252, 253);">每天午夜都会创建一个包含当天日期的新日记页面</font>
+ <font style="color:rgb(17, 24, 28);background-color:rgb(251, 252, 253);">我们建议您在当天的日记页面上写下所有内容</font>
+ <font style="color:rgb(17, 24, 28);background-color:rgb(251, 252, 253);">链接到页面：括号通常用于内联链接，而主题标签通常用于元数据</font>
+ <font style="color:rgb(17, 24, 28);background-color:rgb(251, 252, 253);">Logseq 的一个很酷的事情是，借助双向链接的功能，您可以从任何地方填充页面</font>
+ <font style="color:rgb(17, 24, 28);background-color:rgb(251, 252, 253);">缩进可以帮助您在 Logseq 中查找内容。Logseq 中的层次结构发生在块级别</font>
+ <font style="color:rgb(17, 24, 28);background-color:rgb(251, 252, 253);">页面引用（链接）和块引用之间的主要区别在于块引用直接显示块的内容</font>

# 20240726 Google DeepMind's AlphaProof MASSIVE MATH BREAKTHROUGH - AI teaches itself mathematical proofs
[https://www.youtube.com/watch?v=lBJvTCUakIk](https://www.youtube.com/watch?v=lBJvTCUakIk)

+ Alphabet的股价下跌；我们现在在由AI驱动的在线搜索领域有多个竞争者
+ 具备高级数学推理能力的通用人工智能（AGI）有潜力开启科学和发现的新前沿
+ 基本上，在某些时候，AI在解决更困难的任务方面比人类更好。但有趣的是，他们说他们观察到任务越难，Eureka奖励的相关性越低。换句话说，事情变得更难，人类退缩，他们在执行任务时变得更差；AI变得更好
+ AlphaProof是一个自我训练的系统
+ 大语言模型在做数学方面臭名昭著地差
+ AlphaGeometry 2是一个神经符号混合系统，其中语言模型基于Gemini，并从头开始在比其前身多一个数量级的合成数据上训练。
+ 事实上，Mark Zuckerberg称LLaMA 3.1为教师模型。

# 20240725  <font style="color:rgb(15, 15, 15);">Generative AI for Beginners 1 Introduction to Generative AI and LLMs</font>
[https://www.youtube.com/watch?v=k7HaeJs-N-o](https://www.youtube.com/watch?v=k7HaeJs-N-o)

+ 给定一个n个tokens的输入序列，最大n值因模型而异，根据一个模型的最大内容窗口长度，模型设计为预测一个单独的token作为输出。但有趣的是，预测的token随后被纳入下一次迭代的输入，创建了一个扩展窗口模式。
+ 输入是 prompt，  输出 completion

新的词汇：pinnacle，conquered， struggled，sake，revolutionizing，<font style="color:rgb(51, 51, 51);">fictional，ambitious，harnesses，inevitable，hype，significant，explicit，significantly，excelled，degree</font>

# <font style="color:rgb(15, 15, 15);">20240724 Zuckerberg goes SCORCHED EARTH.... Llama 3.1 BREAKS the "AGI Industry"</font>
[https://www.youtube.com/watch?v=QyRWqJehK7I](https://www.youtube.com/watch?v=QyRWqJehK7I)

+ 45亿参数的llama3.1发布它对世界的意义远远大于这个模型本身。Llama 3.1的表现达到了顶尖前沿模型的水平
+ 这个模型用于合成数据生成，目的是训练其他模型。利用一个大型智能模型的输出，你可以创建你自己的AI模型，这些模型非常高效，非常智能，非常有能力，达到或超过那个大模型的水平，但用于你自己的特定用例
+ 小扎认为，未来每个企业都会像今天拥有电子邮件地址、网站和社交媒体一样，拥有一个客户可以交谈的AI代理
+ 直接在405上进行推理，比直接在gpt-40上进行要便宜大约50%。
+ AI将带来所有这些令人惊叹的事情，包括生产力的提升和人们创造力的增强
+ AI 失控的危害主要是两种，无意和有意的，科幻小说里面大部分是前者
+ 一些过时的数据：如果Anthropics上运行每月需要75,000美元的输出成本。那75,000美元在OpenAI上只有30,000美元，但在运行Gro的Llama 3上只有800美元

# <font style="color:rgb(15, 15, 15);">20240723 OpenAI's new model is a "RESEARCH ARTIFACT" | Unlocks "Society of Minds"?</font>
[https://www.youtube.com/watch?v=4SrR2sXZ6hE](https://www.youtube.com/watch?v=4SrR2sXZ6hE)

+ 人们对任何不是立即达到AGI或前沿能力改进的模型发布都会感到愤怒。
+ 论文的想法往往会在六个月或十二个月后以产品形式出现
+ route llm，超过85%的成本降低，同时仍然达到了GPT-4性能的95%
+ 从2022年推出能力较弱的Da Vinci 003模型以来，每个token的成本已经下降了99%
+ 有一个强有力的理论认为，将这些东西串联在一起的力量增加了它们执行代理任务的能力。
+ 我们都需要时不时地休息一下，否则我们会发疯。电影《闪灵》非常现实，整天工作和娱乐会让Jack变得迟钝

# 20240722 <font style="color:rgb(15, 15, 15);">AI News : GPT5 Will Be Better Than We Think , Gemini 2 China Takes The Lead , , Googles New Robots..</font>
[https://www.youtube.com/watch?v=DCcMQdppW8A](https://www.youtube.com/watch?v=DCcMQdppW8A)

+ 人们认为AI幻灭低谷并且炒作即将消退，但我认为事实并非如此
+ 有两件关键的事情我们还没有做:
    - 我们还没有用尽所有可用的计算资源,
    - 在规模扩展上还没有达到边际效益递减
+ Google最近在发布软件方面采取了更激进的策略
+ OpenAI必须非常小心地发布这些系统，因为如果他们不这样做，他们将处于更糟糕的境地
+ 如果这些系统有超人般的说服能力，他们究竟如何在现实中发布真正强大的系统？
+ Elon Musk和他的团队基本上在讨论如何潜在地使用Neuralink来控制Optimus的某些部分
+ AI导致的媒体内容的超个性化可能会导致我们曾经共享的现实的破裂
+ 共享现实成为一种有限的商品



# 20240720 <font style="color:rgb(15, 15, 15);">GPT-4o Mini Arrives In Global IT Outage, But How ‘Mini’ Is Its Intelligence?</font>
[https://www.youtube.com/watch?v=IP7DjybjMHU&t=3s](https://www.youtube.com/watch?v=IP7DjybjMHU&t=3s)

+ O本来应该代表Omni，意思是所有模式，但现在推出的GPT-40 Mini仅支持文本和视觉，而不支持视频和音频
+ 每个请求最多16,000个输出Token，大约12,000个单词
+ 它的知识截至去年10月，这让我觉得它是GPT-40模型的一个检查点。
+ 一位OpenAI研究员曾强烈暗示，GPT-40 Mini的一个更大版本，甚至比GPT-40还要大，就在GPT-40 Mini发布后不久就会出现
+ 基准有时存在错误，优先考虑和优化基准性能布，往往会损害其他领域的性能
+ Gemini 1.5 Pro在没有拓扑图的情况下无法实现零-shot导航
+ 延迟问题，Gemini 1.5 Pro在视频模式下的推理时间大约在10到30秒之间。
+ 只要模型仍然在文本上训练，它们可能会在文本中被欺骗，可能会犯错误，产生幻觉，虚构内容

# 20240719 <font style="color:rgb(15, 15, 15);">Trump allies draft AI order to launch "MANHATTAN PROJECT"</font>
[https://www.youtube.com/watch?v=uhS8QPDcG-M](https://www.youtube.com/watch?v=uhS8QPDcG-M)

+ 当我们试图使AI模型变得道德和良好时，它们出现失误并不是新鲜事
+ 真思考你想给模型什么样的提示是非常重要的
+ Boston Dynamics的机器人会做空翻了
+ GPT对性别问题敏感的努力可能适得其反，导致了意外的歧视。
+ 创建无偏见的AI，但在这个过程中避免产生新的偏见
+ Peter Thiel与特朗普保持密切关系
+ a16z，这是一家非常成功、强大且非常有影响力的风险投资公司，专注于硅谷



# 20240718 《Elon Musk》40 Artificial Intelligence  
OpenAI, 2012–2015 
![](https://cdn.nlark.com/yuque/0/2024/png/250863/1721297636568-8949819e-1cd9-4ebb-b550-c8d217fe3619.png)

+ Demis Hassabis 是DeepMind的创始人，公司设计基于计算机的神经网络，以实现通用人工智能。
+ 在2014年初，Google以大约6亿美元收购了DeepMind
+ Sam Altman，一位严谨的软件企业家、跑车爱好者和生存主义者，在他光鲜的外表下，有着类似Musk的强烈个性
+ 2015年12月，Musk与其他科技名人一起创建了OpenAI，一家非营利研究公司，旨在以造福人类的方式开发通用人工智能
+ 什么更安全：由大公司控制的少量AI系统还是大量独立系统？他们得出的结论是，大量相互制衡的竞争系统更好。
+ Musk在连线采访时说：“我认为防止AI被滥用的最好防御是让尽可能多的人拥有AI。”
+ “AI对齐”：其目的是确保AI系统与人类的目标和价值观一致，正如艾萨克·阿西莫夫在他的小说中提出的防止机器人伤害人类的规则。
+ Neuralink这家公司将创立芯片，可以将人类大脑直接连接到计算机
+ 在人工智能领域的成功将来自于获取大量机器人可以学习的真实世界数据。两个宝藏是 Tesla 和 Twitter
+ 190万美元的薪水和启动奖金 从 google挖来了Ilya， 称为 OpenAI 的首席科学家
+ Optimus，一个类人机器人
+ Dojo，一台可以使用数百万视频来训练人工神经网络模拟人脑的超级计算机
+ Andrej Karpathy 从 OpenAI  到 Tesla, 2023年又回到了 OpenAI

#  20240717 <font style="color:rgb(15, 15, 15);">S4E18 壓力的正反面！如何轉化壓力為動力？</font>
[https://www.youtube.com/watch?v=dRKWaYER700](https://www.youtube.com/watch?v=dRKWaYER700)

+ 压力
    - 美国一项研究表明过去一年承担巨大压力的人死亡风险增加 43%
    - 只有那些认为压力对人有害的人，死亡风险才会提高。反而，压力越大死亡风险越小
    - 调整你对压力的观点，压力对你身心照成的伤害就会降低
    - 压力是为了让你面对调整，而不是来伤害你的身体的
    - 人生无法摆脱压力，而是转换对压力的看法
    - 压力只有值得的人才值得拥有
    - 上帝不会给你一张写不过的考卷
+ 自私的目标要用无私的方式去完成
+ 人不会改变，但是人会蜕变的，蜕变是包含了过去的自己。
+ 真正好的状态是判断不评断
+ 根除坏习惯三问：
    - 对我的身体好吗？
    - 对我精神好吗？知道代价是什么
    - 做完后会开心吗？





# 20240716 <font style="color:rgb(15, 15, 15);">How to Learn Complex Skills Quickly (And Forever)</font>
[https://www.youtube.com/watch?v=pHN7BXpdAPQ](https://www.youtube.com/watch?v=pHN7BXpdAPQ)

+  RAIL 框架：学习复杂的技能有 4 个阶段，并且对应着相应的行动
    - 第一阶段：Relevance ,  相关性， 提出好问题并收集好的信息。 
        * 使复杂技能变得复杂的原因之一是这种被称为潜伏学习期的东西：在学习和获得学习反馈之间有很长的时间间隔
        * 好的问题会引导出好的答案，而好的答案会引导出好的行动。
        * 探索和挑战
    - 第二阶段：Awareness ， 意识，进行专注练习
        * 也可以称为平台期，这个是很多人放弃的阶段
        * 要专门留出时间进行练习，并确保我们的练习是有结构和目标导向的
        * 关键标志是 犯错。进步就是尽快犯尽可能多的错误
    - 第三阶段：Iteration ,迭代， 寻求反馈并进行调整
        * RAIL 来源于四个能力阶段： 无意识无能、有意识无能、有意识有能和无意识有能
        * 如果你在还没有一致性和准确性时尝试加快速度，你只会增加错误率
        * 行动； 多样化联系和调整
    - 第四阶段：Longlife 掌握技能并发展自己的风格
        * 保持你的技能终身，所以它被称为终身阶段
        * 如果你不经常使用它，你会失去它.这是一种被称为技能衰退的现象，它可以发生在任何被忽视的技能上









# 20240713 <font style="color:rgb(15, 15, 15);">BREAKING: Q-star details LEAKED! Reuters reveals internal OpenAI documents (codename: STRAWBERRY)</font>
[https://www.youtube.com/watch?v=T9gAg_IXB5w](https://www.youtube.com/watch?v=T9gAg_IXB5w)

+ OpenAI正在开发一种新的推理技术，代号为Strawberry。显然，Strawberry现在就是QAR。QAR是去年11月至12月从OpenAI泄露出来的那个
+ Sam Alman确实确认了那次泄漏是真实的，他没有具体说明任何细节，但他说那次泄漏是不幸的。
+ OpenAI的工作人员告诉他们，QAR演示能够回答今天商业上可用模型无法触及的复杂科学和数学问题
+ 一些研究人员表示，推理是AI实现人类或超人级别智能的关键。
+ Sam Alman自己所说，最重要的进展领域将围绕推理能力展开。
+ Strawberry与斯坦福大学开发的一种方法相似，称为自我推理器或Star，通过推理进行自举推理，其背后的想法是创建一个推理循环。能够在生成推理时迭代地改进自己的答案，以及回答问题背后的思维方式。
+ Star使AI模型能够通过迭代地创建自己的框架数据，自举到更高的智能水平。
+ OpenAI正在测试他们称之为GPT mini的东西。该模型能够充当守门人或将问题路由到大模型或小模型



# 20240712 <font style="color:rgb(15, 15, 15);">BREAKING: OpenAI "model shows human-like reasoning"</font>
[https://www.youtube.com/watch?v=u4Yk7gIMd3U](https://www.youtube.com/watch?v=u4Yk7gIMd3U)

+ **OpenAI**开发的一个系统，用于追踪人类水平AI的进展，公司认为目前处于第一级，即聊天机器人级别，但正接近第二级，即所谓的推理者。
+ openAI的五级 AI系统：
    - 一级，这是大多数人认为我们现在所处的位置，聊天机器人，有对话语言的人工智能。
    - 二级将是人类水平的问题解决，具有推理能力的东西。
    - 三级代理人系统，能够代表用户采取行动，执行长时间跨度的任务和目标，观察、定向、决策和行动。
    - 四级，创新者，能够协助发明的人工智能，可能帮助推动科学进步，创造新的创新等等。
    - 五级，完整的AI组织，能够完成整个组织工作的AI系统。
+ **OpenAI**与**The Los Alamos National Laboratory**的合作， 这个实验室设计和制造了原子弹

# 20240711 <font style="color:rgb(15, 15, 15);">Both Microsoft and Apple are ditching their board seats at OpenAI...</font>
[https://www.youtube.com/watch?v=gqWXgS-OYXY](https://www.youtube.com/watch?v=gqWXgS-OYXY)

+ 微软退出 OpenAI董事会， 苹果不打算加入 OpenAI 董事会。 很着急的声明，并且拒绝评论原因
+ AI 在生命科研上的应用：将外来遗传物质引入宿主生物体内，在体外维持和繁殖细胞，以及通过离心分离细胞。
+ 一个担忧，特别是如果你有纵向整合和利益冲突，可能会有自我交易，可能会有歧视，可能会有排斥，使得大公司变得越来越大，而以其他人为代价
+ 欧盟和美国当局似乎非常有兴趣打破一些他们认为是潜在的AI垄断，这意味着什么？

# <font style="color:rgb(15, 15, 15);">20240702 OpenAI's Q* is back! Is this the real reason Ilya left OpenAI?</font>
[https://www.youtube.com/watch?v=-PS_nP2fZ-c](https://www.youtube.com/watch?v=-PS_nP2fZ-c)

+ 2016年，不知名的OpenAI 发布了 Universe， 允许AI代理像人类一样使用计算机，通过查看屏幕像素和操作虚拟键盘和鼠标。Universe让我们可以在任何人类可以用计算机完成的任务上训练单个代理。
+ 这实际上是他们开始时的初衷，这是他们的原始目标和原始想法
+ OpenAI的QStar是一个先进的AI框架，通过结合神经和符号方法，实现跨各种任务的卓越性能。QStar代表了AGI发展的一大飞跃，可能在各种认知任务中超越现有的AI技术
+ 有人认为QStar是自我对弈（Self-Play） 和 多智能体强化学习（Multi-Agent Reinforcement Learning） 两种方法的结合
+ 2019年，AlphaStar在Starcraft 2（星际2）的 Battle.net上排名高于99.8%的活跃玩家，达到了三个种族（Protoss、Terran和Zerg）的特级大师水平。
+ SEMA，Google DeepMind，2024年的最新项目，一个可以玩所有这些视频游戏的通用代理。他们使用类人界面，这意味着他们与这些游戏的互动方式几乎与你我相同



# 
