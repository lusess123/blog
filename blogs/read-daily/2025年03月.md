# 20250323 VIBE CODING is Eating the World...（上）
+ [https://www.youtube.com/watch?v=tmiuiOwf4ac](https://www.youtube.com/watch?v=tmiuiOwf4ac)
+ Andre Karpathy 发明了这个术语 Vibe coding，基本理念是，你无需亲自编写代码，而是大量依靠 AI 替你编写代码，你只需顺应 AI 的引导即，可理想情况下，你甚至可以用语音直接说出代码，而非用英文逐字打出来
+ 许多人对此都非常感兴趣，你并不需要编程或软件开发的知识，也无需太多经验，只要你愿意学习并保持灵活的态度即可。学习过程中可能会不太舒服，这完全正常。  
 Peter Levels，在组织2025年的 Vibe coding 游戏开发大赛，每个人都能提交自己用 AI 辅助开发的游戏。Andre Karpathy 和 John Karmac 当评委  
+ 基于3js的“堡垒之夜”与“我的世界”风格的游戏，效果令人赞叹。据说这个例子使用 Cursor 花了37个小时完成。另外一个例子则使用了 wind surf。
+ 如果你从未编程或接触过这些东西，只想尝试一下，最简单的方法可能就是从 Claude 入手。
+ 这种 Vibe coding 方式也遭到了一些批评，有人认为它不是一种严肃的软件开发方法。很多人对这种方式不屑一顾，甚至嘲笑，认为这只是一群不会编码的人在尝试，但他们无法做出真正先进、复杂的东西。
+ 90年代数码相机兴起的情景：当时的数码相机已足够普通消费者使用，使很多新人进入摄影领域。任何人买台相机，随意拍摄即可轻松获取照片，而无需了解胶片运作、相机原理，或如何冲洗挑选胶片。从很多方面来看，这些新人对专业摄影一窍不通，没有专业技能，许多专业摄影师因此瞧不起数码相机，认为它们没什么用。专业人士知道如何挑选正确的胶片、正确冲洗、正确曝光，以精准拍出所需的效果。
+ Vibe coding 和各种AI辅助编程工具似乎会引发类似的情况，我们可能会看到大量新人进入编程领域，尝试开发软件、游戏，以及各种他们能想到的东西。
+ Peter Levels主张编码属于每个人，并暗示那些因Vibe coding而担忧职业安全的人，如果一直持有消极态度，将真的可能面临失业。

# 20250318 OpenAI "Full Code Automation" Coming This Year... （下）
+ [https://www.youtube.com/watch?v=18UWzTnXLjc&t=603s](https://www.youtube.com/watch?v=18UWzTnXLjc&t=603s)
+ Cloud 会给任何特定的提示或项目分配多少算力呢？也就是一种“测试与计算”的概念。例如，输入“思考”、“多想想”或“再深入一些”这样的提示，可能意味着给某个任务或项目分配更多的算力资源。
+ 目前 Claude Code 并不具备真正的视觉功能，无法根据视觉反馈作决策，而 Manus 则使用一种名为 Browser Use 的开源视觉模型，直接与视觉元素交互。
+ OpenAI 发布了名为 Operator 的开源视觉模型，它能进行真实的视觉交互，不只是简单地选择网页元素，因此显得更加人性化。
+ Claude Code 仍需较多的人类指导，而 Manus 可以独立执行复杂任务，不用频繁干预。
+ 网络上确实有许多极为聪明的软件工程师。他们解释了为何自动化软件工程中那些更难的部分是如此困难。他们认为，人工智能编程将会变得一团糟，带来诸多问题和错误。它也可能使人们对编程的理解能力下降。

# 20250317 OpenAI "Full Code Automation"（上）
+ [https://www.youtube.com/watch?v=18UWzTnXLjc](https://www.youtube.com/watch?v=18UWzTnXLjc)
+ Kevin Wheel，是OpenAI的首席产品官，他提到与Anthropic公司的人交流时，对方表示到2027年，前端和后端的功能性代码有99%的可能会自动化
+ Kevin预测，根据竞赛编程的基准测试，今年AI将永久地超越人类程序员，就像计算机在70年前永久超越人类的乘法计算一样。
+ Sam Altman预测，到2025年底将会实现超越第一名的超人类级别的编程模型
+ 我认为下一代这类工具可能类似于Claude Code结合先进的用户体验设计。尽管Manis的评价褒贬不一，但它精准地把握了一些出色的设计方法，很可能会成为未来编码代理的概念蓝图。
+ 首先清晰地定义任务以收集上下文，然后再让模型进行思考，最后再增加计算资源的使用。这与Anthropic最近发布的公告相呼应，即允许用户对每个任务或项目的算力分配拥有更大的控制权。

# 20250513 livekit docs
+ [https://docs.livekit.io/home/](https://docs.livekit.io/home/)
+ livekit是一个开源的多媒体应用平台，支持WebRTC, 服务端的核心代码是go编写的，包含一个AI Agent框架
+ OpenAI, Character.ai, Retell,  Speak 的 实时对话AI产品  都是基于livekit的
+ LiveKit Cloud 提供了Edge optimized， 这个应该是他的核心盈利点
+ 集成了Krisp,用于处理背景噪声，Krisp的最核心产品是 Noise Cancellation（噪音消除）
+ livekit的AI Agent支持两种模式：
    - MultimodelAgent：多模态,端对端，类似openAI的高级语音模式
    - VoicePipeineAgent： STT， LLM， TTS 管道模式，能提供更强大的控制
+ Turn detection （讲话什么时候开始，什么时候结束）  是AI语音聊天的最大挑战之一。livekit 使用（VAD Voice activity detection，语音活动检测 ）和 Turn detection model （livekit自己的开源模型）
+ OpenAI 的 Realtime API 内置了VAD，但是针对VoicePipeineAgent，livekit集成了Silero VAD （由 Silero 开发，基于深度学习的开源VAD模型，[https://github.com/snakers4/silero-vad）](https://github.com/snakers4/silero-vad）)
+ WebRTC通常需要WebSocket作为Signaling Channel(信令通道)

# 20250309 China Releases WORLD'S FIRST AUTONOMOUS AI Agent... Open Source | Manus
+ [https://www.youtube.com/watch?v=CFo1iTd_Cc8](https://www.youtube.com/watch?v=CFo1iTd_Cc8)
+ 对大部分普通人而言，在庞大的代理市场中找到合适的代理并不容易，而 Manus 有效地解决了这个问题
+ Manis 的名字来源于拉丁词汇“manus”（手），象征着知识必须应用于实践的信念。它旨在增强人类的能力，将你的愿景变为现实。
+ 随着这些聊天机器人性能的提升，很快可能会出现这样一种情况：让 AI 聊天机器人为你定制应用程序，比你上网搜索已有软件更快
+ Adobe 软件非常强大，创造了数十亿美元的收入，但大多数用户只使用了其中大约20%的功能。试想一下，如果 AI 助手能让你直接描述你真正需要的那20%的功能，然后专门为你量身打造对应的定制软件，那将会如何？
+ 你完全可以通过自然语言指令来实现上述操作，无需复杂的用户界面。这种方式可能会极大地影响软件即服务（SaaS）公司，以及像谷歌这样的在线信息服务提供商。
+ Manus 或者 Anthropics 的 Cloud coder，二者都能通过 Linux 命令行自主地完成编码、故障排查和软件部署等任务，而完全不需要用户友好的图形界面。
+ 这种类型的自主软件部署似乎已成必然，除非政府对开源软件实施监管；否则，这种技术即将到来，并可能彻底改变整个软件即服务（SaaS）行业。

# 20250302 PT-4.5 Fails. AGI Cancelled. It's all over...
+ [https://www.youtube.com/watch?v=kkZ4-xY7oyU](https://www.youtube.com/watch?v=kkZ4-xY7oyU)
+ GPT 4.5 有粉碎性能基准吗？并没有。相比 GPT 40 它确实有些适度的提升，但远远比不上推理模型，比如 o03 mini high。输入75美元，输出150美元，无疑是目前市面上最昂贵的模型
+ 每增加0.5的版本号，大约对应着10倍的预训练算力。
+ GPT-1 勉强能生成连贯文本；GPT-2 是个混乱的小玩具；GPT-3 比较有趣；而到了 GPT-3.5，则真正引爆了 ChatGPT 的流行时刻
+ GPT-4 正是微软撰写《Sparks of AGI》论文的阶段，意味着我们从此跨越了某种原始通用人工智能（Proto-AGI）的门槛
+ 现在 GPT-4.5 的算力是 GPT-4 的 10 倍，这就是我们目前看到的情况。为什么这很重要？因为如果在不断 10 倍扩展算力 的同时，我们发现它的能力反而下降了，这可能意味着扩展规模已经遇到了瓶颈。
+ 计算能力提升十倍所带来的效果；但你会发现，这种提升非常微妙，也难以解释清楚，你必须深入探究才行——它不是显而易见的，你得真正理解问题本身，以及为何这种差异如此微妙
+ GPT 4.5能够从语境中学习，并创造出在历史背景下正确的歌词段落，效果非常不错。而GPT 40则无法做到这一点，它在上下文学习方面存在困难；与之相比，Claude 3.7 Sonnet模型则表现更好
+ GPT 4.5，这就是我们一直期待的Orion模型。这个模型规模巨大，是一个合成数据工厂。它实际上并不是为大多数人日常使用的各种任务设计的。它的真正作用是生成合成数据，用来训练下一代模型，也就是推理模型。
+ 为什么这个API价格如此昂贵？因为GPT-4曾是所有人的合成数据工厂，每个人都从中提炼知识，以创建自己的模型。对于GPT-4.5，OpenAI可能不想再次出现这种情况，因此如果有人想用它来生成合成数据，就必须支付高昂的费用。
+ 至于扩展能力是否遇到了瓶颈，我认为真正的答案只有当我们看到从这次模型中衍生出的推理模型后才能确定。
+ 4.5确实比4更好，但这种能力的提升究竟会如何转化为我们构建推理模型的效果呢？对我们来说，这些可能只是小的、微妙的改进，但当我们用这些数据进行 **RL**——强化学习——时，对于未来的推理模型系列可能意味着巨大的改进。

