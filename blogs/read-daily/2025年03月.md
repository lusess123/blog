# 20250317 OpenAI "Full Code Automation"（上）
+ [https://www.youtube.com/watch?v=18UWzTnXLjc](https://www.youtube.com/watch?v=18UWzTnXLjc)
+ Kevin Wheel，是OpenAI的首席产品官，他提到与Anthropic公司的人交流时，对方表示到2027年，前端和后端的功能性代码有99%的可能会自动化
+ Kevin预测，根据竞赛编程的基准测试，今年AI将永久地超越人类程序员，就像计算机在70年前永久超越人类的乘法计算一样。
+ Sam Altman预测，到2025年底将会实现超越第一名的超人类级别的编程模型
+ 我认为下一代这类工具可能类似于Claude Code结合先进的用户体验设计。尽管Manis的评价褒贬不一，但它精准地把握了一些出色的设计方法，很可能会成为未来编码代理的概念蓝图。
+ 首先清晰地定义任务以收集上下文，然后再让模型进行思考，最后再增加计算资源的使用。这与Anthropic最近发布的公告相呼应，即允许用户对每个任务或项目的算力分配拥有更大的控制权。

# 20250513 livekit docs
+ [https://docs.livekit.io/home/](https://docs.livekit.io/home/)
+ livekit是一个开源的多媒体应用平台，支持WebRTC, 服务端的核心代码是go编写的，包含一个AI Agent框架
+ OpenAI, Character.ai, Retell,  Speak 的 实时对话AI产品  都是基于livekit的
+ LiveKit Cloud 提供了Edge optimized， 这个应该是他的核心盈利点
+ 集成了Krisp,用于处理背景噪声，Krisp的最核心产品是 Noise Cancellation（噪音消除）
+ livekit的AI Agent支持两种模式：
    - MultimodelAgent：多模态,端对端，类似openAI的高级语音模式
    - VoicePipeineAgent： STT， LLM， TTS 管道模式，能提供更强大的控制
+ Turn detection （讲话什么时候开始，什么时候结束）  是AI语音聊天的最大挑战之一。livekit 使用（VAD Voice activity detection，语音活动检测 ）和 Turn detection model （livekit自己的开源模型）
+ OpenAI 的 Realtime API 内置了VAD，但是针对VoicePipeineAgent，livekit集成了Silero VAD （由 Silero 开发，基于深度学习的开源VAD模型，[https://github.com/snakers4/silero-vad）](https://github.com/snakers4/silero-vad）)
+ WebRTC通常需要WebSocket作为Signaling Channel(信令通道)

# 20250309 China Releases WORLD'S FIRST AUTONOMOUS AI Agent... Open Source | Manus
+ [https://www.youtube.com/watch?v=CFo1iTd_Cc8](https://www.youtube.com/watch?v=CFo1iTd_Cc8)
+ 对大部分普通人而言，在庞大的代理市场中找到合适的代理并不容易，而 Manus 有效地解决了这个问题
+ Manis 的名字来源于拉丁词汇“manus”（手），象征着知识必须应用于实践的信念。它旨在增强人类的能力，将你的愿景变为现实。
+ 随着这些聊天机器人性能的提升，很快可能会出现这样一种情况：让 AI 聊天机器人为你定制应用程序，比你上网搜索已有软件更快
+ Adobe 软件非常强大，创造了数十亿美元的收入，但大多数用户只使用了其中大约20%的功能。试想一下，如果 AI 助手能让你直接描述你真正需要的那20%的功能，然后专门为你量身打造对应的定制软件，那将会如何？
+ 你完全可以通过自然语言指令来实现上述操作，无需复杂的用户界面。这种方式可能会极大地影响软件即服务（SaaS）公司，以及像谷歌这样的在线信息服务提供商。
+ Manus 或者 Anthropics 的 Cloud coder，二者都能通过 Linux 命令行自主地完成编码、故障排查和软件部署等任务，而完全不需要用户友好的图形界面。
+ 这种类型的自主软件部署似乎已成必然，除非政府对开源软件实施监管；否则，这种技术即将到来，并可能彻底改变整个软件即服务（SaaS）行业。

# 20250302 PT-4.5 Fails. AGI Cancelled. It's all over...
+ [https://www.youtube.com/watch?v=kkZ4-xY7oyU](https://www.youtube.com/watch?v=kkZ4-xY7oyU)
+ GPT 4.5 有粉碎性能基准吗？并没有。相比 GPT 40 它确实有些适度的提升，但远远比不上推理模型，比如 o03 mini high。输入75美元，输出150美元，无疑是目前市面上最昂贵的模型
+ 每增加0.5的版本号，大约对应着10倍的预训练算力。
+ GPT-1 勉强能生成连贯文本；GPT-2 是个混乱的小玩具；GPT-3 比较有趣；而到了 GPT-3.5，则真正引爆了 ChatGPT 的流行时刻
+ GPT-4 正是微软撰写《Sparks of AGI》论文的阶段，意味着我们从此跨越了某种原始通用人工智能（Proto-AGI）的门槛
+ 现在 GPT-4.5 的算力是 GPT-4 的 10 倍，这就是我们目前看到的情况。为什么这很重要？因为如果在不断 10 倍扩展算力 的同时，我们发现它的能力反而下降了，这可能意味着扩展规模已经遇到了瓶颈。
+ 计算能力提升十倍所带来的效果；但你会发现，这种提升非常微妙，也难以解释清楚，你必须深入探究才行——它不是显而易见的，你得真正理解问题本身，以及为何这种差异如此微妙
+ GPT 4.5能够从语境中学习，并创造出在历史背景下正确的歌词段落，效果非常不错。而GPT 40则无法做到这一点，它在上下文学习方面存在困难；与之相比，Claude 3.7 Sonnet模型则表现更好
+ GPT 4.5，这就是我们一直期待的Orion模型。这个模型规模巨大，是一个合成数据工厂。它实际上并不是为大多数人日常使用的各种任务设计的。它的真正作用是生成合成数据，用来训练下一代模型，也就是推理模型。
+ 为什么这个API价格如此昂贵？因为GPT-4曾是所有人的合成数据工厂，每个人都从中提炼知识，以创建自己的模型。对于GPT-4.5，OpenAI可能不想再次出现这种情况，因此如果有人想用它来生成合成数据，就必须支付高昂的费用。
+ 至于扩展能力是否遇到了瓶颈，我认为真正的答案只有当我们看到从这次模型中衍生出的推理模型后才能确定。
+ 4.5确实比4更好，但这种能力的提升究竟会如何转化为我们构建推理模型的效果呢？对我们来说，这些可能只是小的、微妙的改进，但当我们用这些数据进行 **RL**——强化学习——时，对于未来的推理模型系列可能意味着巨大的改进。

