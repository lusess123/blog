# 20250326 ARC AGI 2 The $1,000,000 AGI Prize
+ [https://www.youtube.com/watch?v=xvqv10NDGS8](https://www.youtube.com/watch?v=xvqv10NDGS8)
+ ARC AGI 基准测试，拥有全新的一套问题，即便是最聪明的 AI 模型也会被难倒，但人类却能轻松通过。
+ 新的测试在计算资源的投入上有更强的抵抗力，因此单纯投入更多资金和算力是解决不了问题的。
+ 目前，基础语言模型（即非推理模型）得分为零，而推理模型的得分也低于 4%。
+ ARC AGI 2 的核心并不在于让语言模型展示超越人类的技能，而是为了暴露 AI 缺乏的能力，即高效地习得新技能。
+ 这不是数据记忆或某种模式识别的问题。关键问题在于：当你处理这些问题时，你是否能习得新的技能？它考察了一些关键能力，比如符号解释、组合推理和情境规则的应用。
+ 对于智能的评价，他们不再仅仅关注能力和准确性，也同时关注效率。
+ ARC AGI 2 发布后三个月内是否有人能获得70%以上的成绩，人们认为这种可能性为8%。

# 20250325 To Dominate the AI Race, Don’t “Start”a Company | LiveKit, Russ d'Sa
+ [https://www.youtube.com/watch?v=A-IsoneWlzE](https://www.youtube.com/watch?v=A-IsoneWlzE)
+ 为了创办公司而去刻意创办公司，这是我职业生涯中多次犯过的错误。
+ live kit实际上承载了25%的911紧急呼叫系统；也有像Open AI这样的公司，正在使用我们的技术来为ChatGPT提供语音模式支持。
+ live kit是一种基础设施，它能让任何开发者都轻松构建使用实时音视频流的应用。
+ 《doom》和《Wolfenstein》游戏的两位创作者，他们每天晚上都会把soft disk公司的电脑拔掉，装进卡车带回家，然后在晚上用这些机器开发自己的游戏。然后第二天早上再把电脑带回去
+ 你必须坚定地相信你的产品愿景，以及你真正想要打造的东西。
+ 选择一个大市场是有好处的，但更重要的是选对市场。同时，你还需要考虑如何平衡你的策略，在这个市场中逐渐成长，最终建立一个可持续发展的事业。
+ 我从那次经历中学到一个有趣的道理：出问题其实是好事，因为问题的出现恰恰说明你创造的东西是人们真正需要的。
+ 我们所做的一切最终都是为了实现目的，而代码只是达到目的的工具。失败与崩溃实际上是一种必经的考验，它们证明你创造了值得持续改进的东西。
+ 真正致命的并不是竞争对手，而是创始人自己。我们其实并未真正解决任何问题，只是用酷炫的技术打造了一个看似酷炫的解决方案，实际上没有对应的真实需求。
+ live kit 正在解决的问题是互联网本身并非为传输音视频而设计的
+ 人们与AI互动的方式将模仿人与人之间的互动——计算机通过摄像头“看”，通过麦克风“听”，通过扬声器“说”。你需要一个“神经系统”在AI和用户之间传递信号，而live kit正在打造的，正是这种连接组织，帮助用户与AI模型顺畅沟通
+ 我所看到的市场潜力是全球所有的键盘和鼠标，因为它们最终都会被摄像头和麦克风所取代
+ 我给对AI或机器人领域感兴趣的创业者的建议是：这两个领域都是万亿级市场，规模庞大，变化迅速，但目前还处于非常早期阶段。与直觉相反的是，稍微等待一下可能更有好处：先加入一家顶尖的AI公司，学习基础知识，了解行业快速变化，并结识未来的联合创始人。
+ 灵感最终会自然而然地出现，不要刻意强求，但一旦你清晰地意识到机会来了，就要全心全意地去追求。当灵感真正到来时，你自然会知道，此时就应该立即行动，全力以赴去追寻它。

# 20250324 3 VIBE CODING is Eating the World...（下）
# 20250324 3 VIBE CODING is Eating the World...（下）
+ [https://www.youtube.com/watch?v=tmiuiOwf4ac&t=981s](https://www.youtube.com/watch?v=tmiuiOwf4ac&t=981s)
+ 无论如何，我认为资深开发者确实有个强有力的观点：目前的AI还没有达到能够取代经验丰富、花大量时间钻研技术的人的水平。
+ 一开始，AI的表现肯定不如专业人士亲自编码那样好，但随着时间推移，AI会大大减少人们逐字逐句手动编写代码的需求。
+ 数码相机带来的第二个变化是降低了技术门槛：你不再需要掌握一大堆复杂技术，只需拿起相机按一下按钮就行。
+ 从传统数码相机再到手机上的数码相机，拍摄照片的数量呈现爆炸式增长，从过去的数亿张左右，到2007年接近一万亿张。
+ 未来大多数的代码将由那些“时间富裕”的人撰写或生成。因此，多数代码将由孩子、英语非母语学生（ESL）而非专业软件工程师编写，这与视频、照片和其他社交媒体的趋势类似
+ 写作和出版的门槛消失了；但这并不意味着天赋、技能或专业能力上的差距不存在了，而是让更多人有机会参与、练习，并变得更好。  
平庸者——那些才能或努力程度较低的人——经济上会受到影响，收入减少；此外，由于产出更多，产品实际的价格也会降低。  
+ 对于数以百万计的简单任务，如游戏、家庭自动化或我们尚未想到的全新事物，AI将使创作它们变得如同说几句话般简单。

# 20250323 VIBE CODING is Eating the World...（上）
+ [https://www.youtube.com/watch?v=tmiuiOwf4ac](https://www.youtube.com/watch?v=tmiuiOwf4ac)
+ Andre Karpathy 发明了这个术语 Vibe coding，基本理念是，你无需亲自编写代码，而是大量依靠 AI 替你编写代码，你只需顺应 AI 的引导即，可理想情况下，你甚至可以用语音直接说出代码，而非用英文逐字打出来
+ 许多人对此都非常感兴趣，你并不需要编程或软件开发的知识，也无需太多经验，只要你愿意学习并保持灵活的态度即可。学习过程中可能会不太舒服，这完全正常。  
 Peter Levels，在组织2025年的 Vibe coding 游戏开发大赛，每个人都能提交自己用 AI 辅助开发的游戏。Andre Karpathy 和 John Karmac 当评委  
+ 基于3js的“堡垒之夜”与“我的世界”风格的游戏，效果令人赞叹。据说这个例子使用 Cursor 花了37个小时完成。另外一个例子则使用了 wind surf。
+ 如果你从未编程或接触过这些东西，只想尝试一下，最简单的方法可能就是从 Claude 入手。
+ 这种 Vibe coding 方式也遭到了一些批评，有人认为它不是一种严肃的软件开发方法。很多人对这种方式不屑一顾，甚至嘲笑，认为这只是一群不会编码的人在尝试，但他们无法做出真正先进、复杂的东西。
+ 90年代数码相机兴起的情景：当时的数码相机已足够普通消费者使用，使很多新人进入摄影领域。任何人买台相机，随意拍摄即可轻松获取照片，而无需了解胶片运作、相机原理，或如何冲洗挑选胶片。从很多方面来看，这些新人对专业摄影一窍不通，没有专业技能，许多专业摄影师因此瞧不起数码相机，认为它们没什么用。专业人士知道如何挑选正确的胶片、正确冲洗、正确曝光，以精准拍出所需的效果。
+ Vibe coding 和各种AI辅助编程工具似乎会引发类似的情况，我们可能会看到大量新人进入编程领域，尝试开发软件、游戏，以及各种他们能想到的东西。
+ Peter Levels主张编码属于每个人，并暗示那些因Vibe coding而担忧职业安全的人，如果一直持有消极态度，将真的可能面临失业。

# 20250318 OpenAI "Full Code Automation" Coming This Year... （下）
+ [https://www.youtube.com/watch?v=18UWzTnXLjc&t=603s](https://www.youtube.com/watch?v=18UWzTnXLjc&t=603s)
+ Cloud 会给任何特定的提示或项目分配多少算力呢？也就是一种“测试与计算”的概念。例如，输入“思考”、“多想想”或“再深入一些”这样的提示，可能意味着给某个任务或项目分配更多的算力资源。
+ 目前 Claude Code 并不具备真正的视觉功能，无法根据视觉反馈作决策，而 Manus 则使用一种名为 Browser Use 的开源视觉模型，直接与视觉元素交互。
+ OpenAI 发布了名为 Operator 的开源视觉模型，它能进行真实的视觉交互，不只是简单地选择网页元素，因此显得更加人性化。
+ Claude Code 仍需较多的人类指导，而 Manus 可以独立执行复杂任务，不用频繁干预。
+ 网络上确实有许多极为聪明的软件工程师。他们解释了为何自动化软件工程中那些更难的部分是如此困难。他们认为，人工智能编程将会变得一团糟，带来诸多问题和错误。它也可能使人们对编程的理解能力下降。

# 20250317 OpenAI "Full Code Automation"（上）
+ [https://www.youtube.com/watch?v=18UWzTnXLjc](https://www.youtube.com/watch?v=18UWzTnXLjc)
+ Kevin Wheel，是OpenAI的首席产品官，他提到与Anthropic公司的人交流时，对方表示到2027年，前端和后端的功能性代码有99%的可能会自动化
+ Kevin预测，根据竞赛编程的基准测试，今年AI将永久地超越人类程序员，就像计算机在70年前永久超越人类的乘法计算一样。
+ Sam Altman预测，到2025年底将会实现超越第一名的超人类级别的编程模型
+ 我认为下一代这类工具可能类似于Claude Code结合先进的用户体验设计。尽管Manis的评价褒贬不一，但它精准地把握了一些出色的设计方法，很可能会成为未来编码代理的概念蓝图。
+ 首先清晰地定义任务以收集上下文，然后再让模型进行思考，最后再增加计算资源的使用。这与Anthropic最近发布的公告相呼应，即允许用户对每个任务或项目的算力分配拥有更大的控制权。

# 20250513 livekit docs
+ [https://docs.livekit.io/home/](https://docs.livekit.io/home/)
+ livekit是一个开源的多媒体应用平台，支持WebRTC, 服务端的核心代码是go编写的，包含一个AI Agent框架
+ OpenAI, Character.ai, Retell,  Speak 的 实时对话AI产品  都是基于livekit的
+ LiveKit Cloud 提供了Edge optimized， 这个应该是他的核心盈利点
+ 集成了Krisp,用于处理背景噪声，Krisp的最核心产品是 Noise Cancellation（噪音消除）
+ livekit的AI Agent支持两种模式：
    - MultimodelAgent：多模态,端对端，类似openAI的高级语音模式
    - VoicePipeineAgent： STT， LLM， TTS 管道模式，能提供更强大的控制
+ Turn detection （讲话什么时候开始，什么时候结束）  是AI语音聊天的最大挑战之一。livekit 使用（VAD Voice activity detection，语音活动检测 ）和 Turn detection model （livekit自己的开源模型）
+ OpenAI 的 Realtime API 内置了VAD，但是针对VoicePipeineAgent，livekit集成了Silero VAD （由 Silero 开发，基于深度学习的开源VAD模型，[https://github.com/snakers4/silero-vad）](https://github.com/snakers4/silero-vad）)
+ WebRTC通常需要WebSocket作为Signaling Channel(信令通道)

# 20250309 China Releases WORLD'S FIRST AUTONOMOUS AI Agent... Open Source | Manus
+ [https://www.youtube.com/watch?v=CFo1iTd_Cc8](https://www.youtube.com/watch?v=CFo1iTd_Cc8)
+ 对大部分普通人而言，在庞大的代理市场中找到合适的代理并不容易，而 Manus 有效地解决了这个问题
+ Manis 的名字来源于拉丁词汇“manus”（手），象征着知识必须应用于实践的信念。它旨在增强人类的能力，将你的愿景变为现实。
+ 随着这些聊天机器人性能的提升，很快可能会出现这样一种情况：让 AI 聊天机器人为你定制应用程序，比你上网搜索已有软件更快
+ Adobe 软件非常强大，创造了数十亿美元的收入，但大多数用户只使用了其中大约20%的功能。试想一下，如果 AI 助手能让你直接描述你真正需要的那20%的功能，然后专门为你量身打造对应的定制软件，那将会如何？
+ 你完全可以通过自然语言指令来实现上述操作，无需复杂的用户界面。这种方式可能会极大地影响软件即服务（SaaS）公司，以及像谷歌这样的在线信息服务提供商。
+ Manus 或者 Anthropics 的 Cloud coder，二者都能通过 Linux 命令行自主地完成编码、故障排查和软件部署等任务，而完全不需要用户友好的图形界面。
+ 这种类型的自主软件部署似乎已成必然，除非政府对开源软件实施监管；否则，这种技术即将到来，并可能彻底改变整个软件即服务（SaaS）行业。

# 20250302 PT-4.5 Fails. AGI Cancelled. It's all over...
+ [https://www.youtube.com/watch?v=kkZ4-xY7oyU](https://www.youtube.com/watch?v=kkZ4-xY7oyU)
+ GPT 4.5 有粉碎性能基准吗？并没有。相比 GPT 40 它确实有些适度的提升，但远远比不上推理模型，比如 o03 mini high。输入75美元，输出150美元，无疑是目前市面上最昂贵的模型
+ 每增加0.5的版本号，大约对应着10倍的预训练算力。
+ GPT-1 勉强能生成连贯文本；GPT-2 是个混乱的小玩具；GPT-3 比较有趣；而到了 GPT-3.5，则真正引爆了 ChatGPT 的流行时刻
+ GPT-4 正是微软撰写《Sparks of AGI》论文的阶段，意味着我们从此跨越了某种原始通用人工智能（Proto-AGI）的门槛
+ 现在 GPT-4.5 的算力是 GPT-4 的 10 倍，这就是我们目前看到的情况。为什么这很重要？因为如果在不断 10 倍扩展算力 的同时，我们发现它的能力反而下降了，这可能意味着扩展规模已经遇到了瓶颈。
+ 计算能力提升十倍所带来的效果；但你会发现，这种提升非常微妙，也难以解释清楚，你必须深入探究才行——它不是显而易见的，你得真正理解问题本身，以及为何这种差异如此微妙
+ GPT 4.5能够从语境中学习，并创造出在历史背景下正确的歌词段落，效果非常不错。而GPT 40则无法做到这一点，它在上下文学习方面存在困难；与之相比，Claude 3.7 Sonnet模型则表现更好
+ GPT 4.5，这就是我们一直期待的Orion模型。这个模型规模巨大，是一个合成数据工厂。它实际上并不是为大多数人日常使用的各种任务设计的。它的真正作用是生成合成数据，用来训练下一代模型，也就是推理模型。
+ 为什么这个API价格如此昂贵？因为GPT-4曾是所有人的合成数据工厂，每个人都从中提炼知识，以创建自己的模型。对于GPT-4.5，OpenAI可能不想再次出现这种情况，因此如果有人想用它来生成合成数据，就必须支付高昂的费用。
+ 至于扩展能力是否遇到了瓶颈，我认为真正的答案只有当我们看到从这次模型中衍生出的推理模型后才能确定。
+ 4.5确实比4更好，但这种能力的提升究竟会如何转化为我们构建推理模型的效果呢？对我们来说，这些可能只是小的、微妙的改进，但当我们用这些数据进行 **RL**——强化学习——时，对于未来的推理模型系列可能意味着巨大的改进。

