# 20250716  OpenAI's Secret INTERNAL Model Almost Wins World Coding Competition...
+ [https://www.youtube.com/watch?v=HctuXVQci4E](https://www.youtube.com/watch?v=HctuXVQci4E)
+ **OpenAI AHC**，其中AHC是AtCoder Heuristic Competition（AtCoder启发式竞赛）的缩写
+ **OpenAI**曾是第一个击败电子竞技世界冠军的AI，这大约是在2019年左右。
+ Atcoder是日本的一个编程竞赛。有两种类别或赛道，分别是启发式（heuristic）和算法（algorithm）赛道。
+ 仅因为某个AI擅长破解这些小问题，并不意味着它一定就是一名优秀的软件工程师。
+ 没有人会押注短期内出现完全自动化的AI编码代理，因为那样的话人们可能根本不再需要这些工具。
+ 这对我们所有人来说都是极好的消息。它会让人们有能力做更多事情。
+ AI会胜出的情况是标准化或非常嘈杂的问题，并且有极大的预算，也就是AI拥有非常充足的思考预算。
+ 人类胜出的情况，即创造性问题、具有复杂基础解法的问题，且AI与人类拥有相同的测试预算。
+ 我们更具样本效率，拥有更流动（灵活）的智力。我们更擅长快速提出针对从未见过的事物的新颖解决方案。
+ 可能存在一些领域，AI和神经网络在其中拥有最终极的解决方案，在这些领域里人类将无法超越。

# 20250715 Elon Musks Reveals GROK 4's Future | MacroHard, Tesla Merger, DoD and more...
+ [https://www.youtube.com/watch?v=2WM3CQhc1bY](https://www.youtube.com/watch?v=2WM3CQhc1bY)
+ 当我们把如此多的硬件设备和强大的算力用于训练，例如AI视频生成模型时，会产生什么结果。这将会是一个全新层次的东西。它的规模将远远超过我们过去见过的任何事物，其他AI视频模型将无法与之媲美。
+ 传统编码就像用画笔作画。使用机器人手臂自动化画笔作画就显得非常愚蠢了，直接渲染像素就好了。
+ 某天深夜和**XAI**团队聊过这件事后，我忽然想到，天啊，我们可能现在就生活在一个模拟（sim）之中。
+ 这个指标还是以几分钟计量的。现在，例如03模型已经发展到能够完成需要一个半小时才能完成的任务了。预测AI完成任务的成功概率达到50%
+ **Dojo平台**是由**特斯拉（Tesla）**开发的一种高性能超级计算机平台，专门用于训练人工智能模型，尤其是特斯拉自动驾驶（Autopilot）系统中的视觉与感知模型
+ AI能够处理任务的长度每6个月就翻一倍
+ 存在可能——也许比较可能——**Gro 4** 的时间视野更长，意味着它在long-term coherence（长期连贯性）和持续聚焦一个话题方面的能力要比 **Claude Opus 4** 更强。
+ 存在一种可能，即 **Grock 4** 在这些特定的基准测试或指标上表现得很好。
+ fluid intelligence ：速弄明白如何完成你从未接触过的任务，也就是我们说的“快速上手学习”能力。

# 20250714  KIMI just BROKE the AI Industry...
+ [https://www.youtube.com/watch?v=CB43-oFnavw](https://www.youtube.com/watch?v=CB43-oFnavw)
+ Kimi K2，拥有1万亿个参数，规模相当庞大，这是一个专用于编程的模型，这就是最新的**Deep Seek**时刻
+ 这个模型可是开源的，这并不是一个具备推理能力的模型。所以未来，我们可能通过强化学习（RL）来实现它的“思考版”。
+ **Kimi K2**是一个专家混合模型，迄今为止最大的开源模型，实际上每次仅激活约320亿个参数。迄今为止最好的开源非推理型模型
+ 指令型模型类似于我们平时使用的聊天机器人模型，能够理解并实现互动式的对话结构。
+ Ilya Sutskever 说互联网上的数据就像这些AI模型的化石燃料，这使得预训练中的“token效率”成为AI扩展定律中的一个新关键系数。Kimi K2基于这些深刻的见解，以及自主智能体验时代的背景而打造的
+ Kim K2在15万亿个token的数据上进行了预训练，使用Muan clip后，训练过程中完全没有波动，证明该Muan clip优化器对大规模语言模型的稳定训练提供了稳健的解决方案。
+ 中国AI实验室一直能想出更高效、更快速、更好、更便宜的方法，而且看起来扩展性也很强。
+ **DeepSeek**的突破之一是**GRPO**，一种新的强化学习方法。GRPO是一种运算强度更低的模型训练方式，使DeepSeek不必像美国一样大量使用Nvidia的GPU也能创建模型。
+ 乎Ruler加上GRPO，他们找到了一种极好的方法，使强化学习训练更易于上手，不需要太多标注数据或手工设计的奖励函数。
+ Kim K2可以说是代码领域的**DeepSeek**。
+ 开源模型与专有模型之间的差距正在迅速缩小。

# 20250712 Elon is Actually SCARED of What He UNLEASHED | GROK 4 (Full Replay)（下）
+ [https://www.youtube.com/watch?v=SFzrcPwvrBw](https://www.youtube.com/watch?v=SFzrcPwvrBw)
+ **Grock** 最大的弱点在于它某种程度上是“半盲”的。显然，它的图像理解能力和图像生成能力还需要大幅提升。
+ **GR 4** 基于我们基础模型的第六版本。我们正在训练第七个版本，几周后将完成。
+ 我们很高兴宣布推出一系列全新的声音，这些声音具有非凡的自然度和韵律感。
+ 自语音模型发布以来，过去80周内端到端延迟缩短了两倍，新增了五种不同的声音，活跃用户增长了十倍，因此 **Gro** 发展迅猛
+ 在**RKGI v2**的私有子集中，它是过去三个月内唯一一个突破10%障碍的模型，表现极好，达到了16%（精确来说是15.8%）的准确率，是第二名**Cloud for Opus**模型的两倍。
+ AI可能经营的最简单的业务是什么？于是我们想到了自动售货机。
+ 们对**Grok**印象深刻，它能够制定并长期坚持一种策略，其持续时间远远超过我们测试过的其他领先模型。
+ 制作电子游戏中经常被忽视的难题之一，并不一定是编写游戏核心逻辑，而是外包所有的素材，比如文件纹理等等，目的是创造视觉上有吸引力的游戏。
+ 如今只需一人，你就能运行整个游戏工作室级别的开发项目。
+ 我预计第一款真正优秀的AI电子游戏将在明年出现。
+ 可能今年我们会看到第一部值得一看的AI制作的半小时电视节目，明年则可能会出现第一部值得观看的AI电影。
+ 多模态能力差到什么程度呢？基本上就像**Grok**在眯着眼睛隔着玻璃看世界一样，看到的全是模糊的特征，还要试图弄明白到底是什么东西。
+ 在多模态代理之后，下一个即将实现的是视频生成。我们认为，最终应该实现的目标就是“像素输入、像素输出”。

# 20250711 Elon is Actually SCARED of What He UNLEASHED | GROK 4 (Full Replay)
+ [https://www.youtube.com/watch?v=SFzrcPwvrBw](https://www.youtube.com/watch?v=SFzrcPwvrBw)
+ 如果让 **Grock 4** 做像 **SAT** 这样的考试，它每次都会拿到满分，即使之前从未见过那些题目。
+ 训练计算分为两种类型。
    - 一种是从 **GR 2** 到 **GR 3** 的预训练计算。
    - **GR 3** 到 **GR 4**，我们实际上将大量计算资源用于推理和强化学习（RL）。
+ 我们意识到，如果认真进行数据消融研究、基础设施建设以及算法优化，就能将预训练规模提高十倍。
+ 有了最佳的预训练模型，我们发现，如果收集这些可验证的结果奖励，就可以训练这些模型，从第一性原理出发进行思考，学会推理并修正自身错误。就是研究生级别推理能力的来源
+ 我认为最快可能在今年晚些时候它就能发现新技术。明年它可能会发现新的物理定律，两年内几乎肯定会实现
+ **deep search** 就是 **Grock 3** 的推理模型，但并未针对工具做专门训练。与现在相比，它在工具使用方面要弱得多，而且不够可靠——确实不可靠。
+ 与 **Tesla** 或 **SpaceX** 使用的工具相比，这种工具使用方式仍然相当原始，后者涉及有限元分析和计算流体动力学。目前 **Grock** 并未使用公司常用的那些真正强大的工具
+ 归根结底，真正能产生最大变化的是通过类人机器人与现实世界互动。
+ 对 AI 安全最重要的一点——至少我的“生物神经网络”告诉我——就是让 AI 最大限度地追求真相
+ 如果你把文明看作是“卡尔达肖夫等级”完成度的百分比，其中一级文明使用一个行星的全部能量，二级文明使用恒星的全部能量，三级文明则是整个星系的全部能量，那我们目前大概还不到一级文明的1%。
+ 随着模型越来越聪明，有趣或具有挑战性的问题将会越来越少。最终的推理测试标准是现实，因为物理定律才是真正的法则，其他所有东西都只是建议而已。
+ 我们将通过强化学习，把训练循环真正闭合到现实世界。
+ **Grok 4** 是单智能体版本，而 **Grok 4 Heavy** 是多智能体版本。
+ 即使是极其困难、人类几乎解不了的题目，对 AI 也迅速变得微不足道。

# 20250710  How to Spend Your 20s in the AI Era（下）
+ [https://www.youtube.com/watch?v=ShYKkPPhOoc](https://www.youtube.com/watch?v=ShYKkPPhOoc)
+ 正处于软件全面变革的时刻，而软件又是这个世界上最能赋予人力量的东西。
+ 每当你试图将创业精神封装起来，当作大学课程一样教授时，最终只会变成一种廉价的创业仿制品。他们会教你遵循某个特定方法或某个特定实践，但真正的创业并非如此。
+ 社交媒体提供的最大礼物之一，就是你可以亲自讲述属于自己的故事。事实上，你必须亲自讲述——一旦你依赖别人来讲述你的故事，可能一开始效果很好，但当你失去了话语权时，就会有人接管这个故事。
+ 这个世界喜欢的，除了一个人成长、成功的故事之外，更喜欢的其实是他如何失败、跌落的故事。
+ 如果你没有自己的声音，无法直接发声，别人就会把你塑造成他们想要的样子，所以最好主动开始讲述你自己的故事。
+ **Apple**做得非常好。他们不会盲目承诺去开发某个功能，除非产品经理能清晰地说明这个功能是为谁设计的，以及它能解决什么问题
+ 如果你和你的联合创始人正好都处于能辞职并全身心投入创业的阶段，那你们或许就该立刻行动，因为这样的时机可能永远不会再出现了。
+ 其实一开始就专注于小众市场一直以来都是成功的秘诀。即使在**YC**的历史上，目前市值最高的公司是**Airbnb**，而**Airbnb**创立之初简直就是小众的典范。
+ 专注于小众领域一直是正确的创业方式。我认为占领一个小众市场，然后扩展到相邻市场，进而发展成大公司，这才是成功的秘诀。
+ 在人工智能时代，小众化尤其重要，因为没人真正清楚市场会有多大。

# 20250709  How to Spend Your 20s in the AI Era（上）
+ [https://www.youtube.com/watch?v=ShYKkPPhOoc](https://www.youtube.com/watch?v=ShYKkPPhOoc)
+ **AGI**（通用人工智能）到来后，金钱可能会不复存在。
+ 过去的情况是，如果你是计算机专业（CS）学生，就会有一条非常明确的道路通向稳定的中上阶层生活，你会找到一份很稳定的程序员工作。
+ 所有计算机专业学生的一般情况——在今年2月的失业率为6.1%。相比之下，艺术史专业的失业率仅为3.0%。
+ 如何自主行动，以及如何拥有主观能动性和独立性。在AI时代之后，这些能力才是真正重要的。
+ 我不认为人们在恐惧之下能够发挥出最佳的工作表现。真正优秀的工作往往来自更积极的动机，是因为你对所做的事情感到兴奋。
+ 获得 A 轮融资就像是获得一个象征身份的凭证，这种凭证往往由开着法拉利驰骋在 **Sand Hill Road** 上的风投大佬所授予。这种凭证与实际结果无关，更像是赛跑发令枪响，而不是真正值得庆祝的成就。
+ 这是一个非常好的观点，与其因为害怕错过机会而冒险行动，不如积极主动地追求目标；这真的是一个建设者们大显身手的激动人心的时代。
+ 曾经出现高速增长的往往是一些消费类社交公司，而 **B2B SaaS** 公司过去通常发展缓慢。现在出现了一种奇怪的逆转：如今高速增长的反而是 **B2B SaaS** 公司。
+ 随着 AI 的兴起，情况出现了转机：它不再只是普通软件，而更像能代替人类工作的魔法。然而要稳定实现这种功能其实很困难，于是现在技术专长反而变成了许多项目中的关键缺失部分。
+ 实际上，真正理解如何使用这些模型并持续压榨出最佳性能，甚至连博士和经验丰富的人也不一定掌握。
+ 实际上真正的专业技能来自于实际的工程实践，投入具体的项目并创造出实实在在的产品。
+ **OpenAI** 和 **SpaceX** 等公司印象深刻，它们的起源其实都源于兴趣和直觉，而非明确的商业意图。然而，这种初始动机反而吸引了全球最聪明的人才和资本，最终创造了世界上最持久的企业。
+ 人们可能没有充分意识到这一点：只要你足够聪明、学习速度快并且足够专注，就能迅速在某个领域成为专家。现在比以往任何时候机会都更多。
+ 当你要真正开始构建并解决一个重大问题时，面对的是一片广阔、开放的空间。这里没有规则，而规则需要你自己去创造。
+ 创业的好处和坏处在于，你有自主权（agency）决定追求什么、设定目标，而不是听从某个权威告诉你必须做这个或那个。

# 20250708 Optimizing inference for voice models in production - Philip Kiely, Baseten
+ [https://www.youtube.com/watch?v=gmTHs5T_YAE](https://www.youtube.com/watch?v=gmTHs5T_YAE)
+ 如果我们客户端代码没写对，可能又会把所有的延迟（latency）重新加回来。
+ everything is an LLM，模型大致可以分为两类
    - 自回归（autoregressive）Transformer模型，这类模型属于LLM或与LLM非常接近。
    - 扩散模型（diffuser），通常用于图像生成，这类模型有着截然不同的优化问题
+ 由于TTS模型在架构上与LLM极为相似，或经常直接从LLM演变而来，我们就可以使用丰富的LLM工具生态。
+ Orpheus TTS是基于Llama的因果语言模型（causal LM）架构
+ LLM模型的性能指标：
    - time to first token， time to first byte， time to first sentence
    - 每秒生成的token数量（tokens per second）
    - 吞吐量（throughput），也就是在特定时间内，我们能服务多少个请求
+ 如何优化
    - **TensorRT LLM**: NVIDIA开发的专门针对大语言模型推理进行加速优化的引擎
    - 对模型进行量化（quantize）；尽管模型本身规模较小，但进一步缩小模型总能提升运行速度。使用Hopper架构，我们已经成功地将模型量化到FP8精度。
    - 在音频领域面临的一个重大挑战是，你需要处理音频数据、音频编解码（codec）、解码（decoding）等大量复杂任务。
        * 用torch.compile去编译模型权重（model weights）以提升运行速度
        * 连续批处理（continuous batching），动态批处理（dynamic batching），即尽可能打包更多token，但每15毫秒会立即发出一批。
        * 们使用Orpheus的TTS实现很多时候性能瓶颈是CPU（CPU-bound），但这其实是个不错的状态。
    - 使用MIG和H100上的TensorRT（TRT）实现后，我们在实际测试中实现了低至150毫秒的“生成首个字节的延迟”（time to first byte）。
    - 对于这些小规模模型和多模态（multimodal）系统来说，非运行时因素（non-runtime factors）可能比运行时优化本身更重要。
    - 当我思考语音代理（voice agents）时，我认为它包含三个部分：倾听（listening）、思考（thinking）、表达（talking）。
    - 仅是DNS绕行（hairpinning）就可能让你损失40到50毫秒，这可能占到你语音模型服务等级协议（SLA）延迟目标的10%。
    - 

# 20250707 The Challenge with AI Voice Agents 1
+ [https://www.youtube.com/watch?v=IuRlGCBSqR8](https://www.youtube.com/watch?v=IuRlGCBSqR8)
+ 记忆方面非常重要，你如何在不丢失重要内容和通话线索的情况下将不同的事物保持在上下文中。
+ 我们在大语言模型中某种程度上解决的这个问题，在语音模型世界中又回来了，就像它只是在编造东西。
+ 与单纯的文字聊天相比，这种（语音）媒介能传递更丰富的信息。正如你所说的，因为你可以检测说话人的情绪、语调、口音等等各种信息。利用这些信息更好地生成回答，这本身也涉及全新的挑战
+ 些领域大致可以分成两类：第一类不太具有能动性，而第二类则非常具有能动性。
+ 你真正开始看到语音AI发挥作用的地方，就是当你可以与AI来回互动，获取信息或让AI执行某个任务时。

# 20250706 The Model Context Protocol (MCP)
+ [https://www.youtube.com/watch?v=CQywdSdi5iA](https://www.youtube.com/watch?v=CQywdSdi5iA)
+ **MCP** 其实就是一种能够非常简单地把我的工作流程放到AI应用程序中的方法。
+ 归根结底，这只是一种为使用大型语言模型（**LLM**）的应用程序提供上下文的方法。
+ 核心的部分是，这是一个协议，位于使用大语言模型（LLM）的人工智能应用程序之间，主要暴露了三个基本要素。
    - 工具（tools），模型可以在现实世界中采取的行动
    - 资源（resources）的东西（也就是你可以摄取到 **RAG** 管道或其他用途的原始数据）
    - 提示（prompts）。用户自己想要放进上下文窗口（context window）里的内容，由用户触发放入窗口中，之后用户还可以随意进行编辑。
        * 提示的真正作用，本质上也就是提示模板（prompt templates）
        * 通常我们会看到这种实现方式是以斜杠命令（slash command）出现的。
+ **MCP** 最根本的起源：如何解决我最关心的那些内容，在两个应用程序之间不断复制粘贴的问题。
+ 标准化层（standardization layer）让给应用程序添加上下文变得简单得多
+ 再回顾一下当初发布的决定，其中一个关键点就是我们最终选择让它开源（open source）。
+ 构建一个人工智能应用的真正价值不一定取决于你能使用哪些集成，而在于模型本身的智能水平以及你在模型之上构建的工作流。
+ 我们只需要做出人们真正想用的东西，并与那些真正关心它的人共同开发即可。没必要把它和 **HTTP** 或其他东西比较
+ 这种方式带来的可能性是无限的。任何可以通过 **API** 访问的东西，你都能用 **MCP** 服务器封装起来，然后通过 **Claude** 或其他 **LLM** 控制。
+ 状态保持（statefulness）相关的功能，以及实际进行采样（sampling）之类的功能，这些都是我们最初就考虑过的基本功能，它们在智能代理的场景中确实有帮助，但也需要模型达到一定的智能水平，才能执行更长周期的任务。
+ 未来的三个feature:
    - registry API：它能让模型主动搜索其他服务器，并将其引入到大型语言模型（LLM）中
    - long running tasks
    - elicitation（主动引导）：即作为服务器，如果你需要更多信息，如何主动向用户请求这些信息

# 20250705 François Chollet: How We Get to AGI（下）
+ [https://www.youtube.com/watch?v=5QcCeSsNRks](https://www.youtube.com/watch?v=5QcCeSsNRks)
+ 只要我们很容易想出人类可以轻松完成，但AI无法解决的任务，那么我们就还没有达到真正的通用人工智能（AGI）。
+ 我们正在评估智能主体性，即探索能力、互动式学习能力，以及自主设定并实现目标的能力。
+ 智能，就是你将过去的经验高效地转化为行动，以应对持续变化的未来的能力。
+ 但关键在于，没有什么东西是完全新颖的。你周围的世界由很多彼此相似的不同事物组成。
+ “kaleidoscope hypothesis（万花筒假说）”：我们的周围充满了同构现象，我们所感知的世界似乎充满了永无止境的新奇与复杂。但要描述这些现象，你实际需要的独特意义原子数量却很少。
+ 智能就是你能够从经验中挖掘出这些可以在多种不同情境中重复使用的意义原子的能力。
    - 首先是抽象概念的获取，即你需要高效地从过去经验或数据流中提取可重复利用的抽象概念。
    - 其次是即时重组，即你需要高效地选择并组合这些基本单元，以形成适合当前情境的模型。
        * TTA，Test-time Adaptation（测试时适应）为我们的AI增加了即时重组的能力，这实际上是朝通用人工智能（AGI）迈出的一大步。
    - 另一个问题是这些模型的效率仍然非常低下。
        * 梯度下降需要巨量的数据来提取简单的抽象概念，这比人类所需的数据量要多出几个数量级，大约多三到四个数量级。
+ 根本问题在于深度学习模型缺乏组合泛化能力。
+ 抽象不止一种类型。智能就是从数据中挖掘抽象概念，然后再将其重新组合。两种抽象都是由类比驱动的：要么是数值类比，要么是程序类比。
    - 一种作用于连续域。也就是以数值为中心的抽象，使用连续的距离函数来比较事物。这种抽象方式支持了感知、模式认知、直觉，当然也包括现代机器学习。
    - 另一种作用于离散域。你要寻找精确的同构或子图同构。而这正是大部分人类推理的基础。这也是软件工程师在重构代码时所做的事情。
+ 所有认知都源于这两种抽象形式的结合。
+ 可以用左右脑的比喻记住它们：一半负责感知和直觉，另一半则负责推理、规划和严谨性。
+ 搜索才是开启超越简单自动化，达到发明创造的关键。当今所有具备某种发明或创造力的AI系统，都依赖于离散搜索。深度学习本身不具备发明创造能力，但搜索具备这种能力。
+ 什么是离散程序搜索呢？它本质上是对来自某种语言或领域特定语言（DSL）的运算符所组成的图，进行组合搜索。
+ 要真正发挥它们的潜力，你必须将二者结合起来。而这正是人类智能特别擅长的地方，也是让我们变得特别的关键所在。感知与直觉和明确的逐步推理结合在一起，在我们所有的思想、行动以及各个方面，都融合了这两种抽象方式。
+ 关键思想是利用这些快速但近似的判断来抵抗组合爆炸，从而使程序搜索变得可行。
+ AI将随着时间推移持续自我完善，一方面扩展抽象库，另一方面不断精细化它对程序空间结构的直觉。

# 20250704 François Chollet: How We Get to AGI
+ [https://www.youtube.com/watch?v=5QcCeSsNRks](https://www.youtube.com/watch?v=5QcCeSsNRks)
+ 世界上最重要的事实之一：计算成本自1940年以来，每十年持续下降两个数量级。
+ the scaling laws：当我们仅靠增加模型规模和训练数据量，保持完全相同的架构和训练流程时，其基准测试结果能够以可预测的方式持续提升。
+ 静态且针对特定任务的“记忆型技能”，与“流动型通用智能”——即迅速理解以前从未见过的新事物的能力之间，有着巨大差异。
+ AI研究界开始转向一种全新的、完全不同的模式——测试时适应（Test Adaptation），创造出能在测试时主动调整自身状态以适应新情况的模型。
+ 所谓“测试时适应”，关键在于模型根据其在推理时所遇到的具体数据，动态地修改自身行为的能力。它涵盖了测试时训练、程序合成和思路合成等技术，模型试图在处理当前任务时自行重新编程。
+ 智能的定义
    - 一种是明斯基（Minsky）风格的观点：认为AI旨在制造能够执行通常由人类完成任务的机器。
    - 而另一种则是MAC观点：认为AI应该使机器能够处理那些事先未做准备的问题。
+ 智能是一种过程，而技能则是这一过程的产物。智能就是处理新情况的能力。它是一种开辟新道路、创造新路径的能力。智能就是你有效利用过去信息来应对未来的效率。
    - 静态技能和流动智力之间的差异
    - 某项技能的适用范围。
    - 某个技能的信息效率。
+ 定义之所以非常重要，是因为作为工程师，我们只能创造出我们能衡量的东西。
+ “the shortcut rule（捷径法则）”：当你专注于实现单一成功指标时，你可能会成功，但会以牺牲所有未被该指标捕捉到的其他方面为代价。
    - 所以你虽然击中了目标，但却错过了真正的意义
    - 对AGI的定义仅仅实现自动化，这种定义虽然增加了经济生产力，显然非常有价值，但可能也会增加失业率。
+ 但另一种定义则能够激发创新并加速科学的发展进程。只有衡量我们真正关心的东西，我们才能取得进步。
+ ARC实际上是一个工具，目的是引导研究界关注我们认为在通向AGI过程中最重要且尚未解决的瓶颈问题。
+ 我们可以明确地得出结论：流动智力不会因预训练规模的扩大而自然产生。
+ 在2019年，ARC1旨在挑战当时的深度学习模式，即模型只是一种用于静态推理的大型参数曲线。而如今，ARC2挑战的是推理系统。

# 20250703 Ilya Sutskever's SHOCKING Superintelligence Warning "extremely unpredictable and unimaginable"
+ [https://www.youtube.com/watch?v=G-kPqsJycsc](https://www.youtube.com/watch?v=G-kPqsJycsc)
+ **Dr. Ilia Suskiver** 一直在幕后默默地进行着超级智能的研究。他是一个非常有趣的人物，因为虽然他很少公开露面，但似乎他所做的几乎每件事都会变成一种网络迷因。
+ 而现在他再次回到聚光灯下，声称人工智能将极度不可预测且难以想象。
+ 正如**Sam Alman**在《gentle singularity》中所说的，我们正在进入递归自我改进的“幼虫阶段”。
+ 如果你拥有一家公司，做的东西你明知道是虚假的，或者明知道不会有什么发展前景，或许能赚点钱但不具革命性，这时有人过来对你说：“我给你320亿美元，让你加入我的公司，继续做同样的事。”
+ 并不是要你停止这项工作，而是直接把320亿美元（或其中属于**Ilia**股份的那部分）放进口袋，同时还能获得像**Meta**这样一个科技巨头的资本和资源支持。
+ Ilia 发现了开放大学，从八年级开始，我就在那儿上课了。我拿到那些书并读了它们，我的理解程度达到了那种清晰的分界点，以至于我清楚记得那是一个前后的分水岭。我开始相信，只要我慢慢地阅读某样东西，最终总能理解它。
+ 电脑能学习吗？我隐约觉得，如果能解决学习的问题，其他一切都会迎刃而解。
+ 大型神经网络可以完成任何任务的观点，在我们谷歌期间做的一些研究中进一步得到了印证。
+ AI的一个挑战在于，它将同时变得极其不可预测和超出人类的想象，甚至难以想象。

# 20250702 The Internet DIES as Gen AI Takes Over | The Dead Internet Theory is now true...
+ [https://www.youtube.com/watch?v=rrNCx4qXvJs](https://www.youtube.com/watch?v=rrNCx4qXvJs)
+ dead internet theory，这是一个阴谋论，声称互联网，尤其在 2016 或 2017 之后，不再主要由人类活动驱动。相反，它由机器人程序和算法驱动，这些算法旨在操纵线上话语、减少真实的人类互动。
+ 在五月份，订阅量排名前十的 YouTube 频道中，有四个在每条视频里都使用了 AI 生成内容。
+ 由于是虚拟机操作，仍然有一些蛛丝马迹可被公司用来判断它并非真实流量，也不是人类用户。但这种界限正在变得越来越模糊，未来要区分并过滤自动化流量会越来越困难。
+ 我们往往倾向于点击那些令人愤怒或激起情绪的内容。我们有时也会看些傻乎乎的内容，事后还不好意思承认。
+ 下一个重大进展将是这些AI代理能够像我刚刚展示的那个操作工具一样自主浏览网页

# 20250701 How to Make AI More Accurate: Top Techniques for Reliable Results
+ [https://www.youtube.com/watch?v=pNbU1vGkIK4](https://www.youtube.com/watch?v=pNbU1vGkIK4)
+ 我们拥有一个可信的数据源，可能是一个向量数据库，我们可以使用一个检索器（retriever，这正是RAG中“R”的含义），来查询这个向量数据库，并检索与特定用户查询相关的文档。
+ 一个了解多个不同领域的大模型在面对宽泛的问题时更不容易产生“幻觉”，而一个带有更专业信息的小模型则相反。你要为特定目的选择正确的模型。
+ COT，即“思维链提示”。它涉及要求大型语言模型明确地生成中间推理步骤，然后再给出最终答案。这能帮助减少在需要逻辑一致性的情境下出现的错误，比如数学问题。
    - 零示例思维链处理，它只是简单地向提示中添加一个触发短语
    - 少样本（few-shot）的思维链提示，在提示中包含问题示例或数学题示例，以及逐步解答的过程。
+ RAR 修改（revise）和反思（reflect），不是依靠单个模型，而是拥有了所有三个模型的集体智慧。
+ MoE，也就是“专家混合”。gating network (门控网络）。作用类似于路由器，用来决定应由哪个专家模型来处理输入内容。
    - 我们不是使用三个大脑，而是只使用一个大脑，但将问题路由到不同的大脑区域。
+ 改变模型的“温度”设置
+ 系统提示词（System prompt），这样做成功程度可能会有所不同，但仍值得尝试。
+ RLHF人类反馈的强化学习，通过这种方式，我们再次对模型进行微调，使其表现得更好一些。

