# 20250706 The Model Context Protocol (MCP)
+ [https://www.youtube.com/watch?v=CQywdSdi5iA](https://www.youtube.com/watch?v=CQywdSdi5iA)
+ **MCP** 其实就是一种能够非常简单地把我的工作流程放到AI应用程序中的方法。
+ 归根结底，这只是一种为使用大型语言模型（**LLM**）的应用程序提供上下文的方法。
+ 核心的部分是，这是一个协议，位于使用大语言模型（LLM）的人工智能应用程序之间，主要暴露了三个基本要素。
    - 工具（tools），模型可以在现实世界中采取的行动
    - 资源（resources）的东西（也就是你可以摄取到 **RAG** 管道或其他用途的原始数据）
    - 提示（prompts）。用户自己想要放进上下文窗口（context window）里的内容，由用户触发放入窗口中，之后用户还可以随意进行编辑。
        * 提示的真正作用，本质上也就是提示模板（prompt templates）
        * 通常我们会看到这种实现方式是以斜杠命令（slash command）出现的。
+ **MCP** 最根本的起源：如何解决我最关心的那些内容，在两个应用程序之间不断复制粘贴的问题。
+ 标准化层（standardization layer）让给应用程序添加上下文变得简单得多
+ 再回顾一下当初发布的决定，其中一个关键点就是我们最终选择让它开源（open source）。
+ 构建一个人工智能应用的真正价值不一定取决于你能使用哪些集成，而在于模型本身的智能水平以及你在模型之上构建的工作流。
+ 我们只需要做出人们真正想用的东西，并与那些真正关心它的人共同开发即可。没必要把它和 **HTTP** 或其他东西比较
+ 这种方式带来的可能性是无限的。任何可以通过 **API** 访问的东西，你都能用 **MCP** 服务器封装起来，然后通过 **Claude** 或其他 **LLM** 控制。
+ 状态保持（statefulness）相关的功能，以及实际进行采样（sampling）之类的功能，这些都是我们最初就考虑过的基本功能，它们在智能代理的场景中确实有帮助，但也需要模型达到一定的智能水平，才能执行更长周期的任务。
+ 未来的三个feature:
    - registry API：它能让模型主动搜索其他服务器，并将其引入到大型语言模型（LLM）中
    - long running tasks
    - elicitation（主动引导）：即作为服务器，如果你需要更多信息，如何主动向用户请求这些信息

# 20250705 François Chollet: How We Get to AGI（下）
+ [https://www.youtube.com/watch?v=5QcCeSsNRks](https://www.youtube.com/watch?v=5QcCeSsNRks)
+ 只要我们很容易想出人类可以轻松完成，但AI无法解决的任务，那么我们就还没有达到真正的通用人工智能（AGI）。
+ 我们正在评估智能主体性，即探索能力、互动式学习能力，以及自主设定并实现目标的能力。
+ 智能，就是你将过去的经验高效地转化为行动，以应对持续变化的未来的能力。
+ 但关键在于，没有什么东西是完全新颖的。你周围的世界由很多彼此相似的不同事物组成。
+ “kaleidoscope hypothesis（万花筒假说）”：我们的周围充满了同构现象，我们所感知的世界似乎充满了永无止境的新奇与复杂。但要描述这些现象，你实际需要的独特意义原子数量却很少。
+ 智能就是你能够从经验中挖掘出这些可以在多种不同情境中重复使用的意义原子的能力。
    - 首先是抽象概念的获取，即你需要高效地从过去经验或数据流中提取可重复利用的抽象概念。
    - 其次是即时重组，即你需要高效地选择并组合这些基本单元，以形成适合当前情境的模型。
        * TTA，Test-time Adaptation（测试时适应）为我们的AI增加了即时重组的能力，这实际上是朝通用人工智能（AGI）迈出的一大步。
    - 另一个问题是这些模型的效率仍然非常低下。
        * 梯度下降需要巨量的数据来提取简单的抽象概念，这比人类所需的数据量要多出几个数量级，大约多三到四个数量级。
+ 根本问题在于深度学习模型缺乏组合泛化能力。
+ 抽象不止一种类型。智能就是从数据中挖掘抽象概念，然后再将其重新组合。两种抽象都是由类比驱动的：要么是数值类比，要么是程序类比。
    - 一种作用于连续域。也就是以数值为中心的抽象，使用连续的距离函数来比较事物。这种抽象方式支持了感知、模式认知、直觉，当然也包括现代机器学习。
    - 另一种作用于离散域。你要寻找精确的同构或子图同构。而这正是大部分人类推理的基础。这也是软件工程师在重构代码时所做的事情。
+ 所有认知都源于这两种抽象形式的结合。
+ 可以用左右脑的比喻记住它们：一半负责感知和直觉，另一半则负责推理、规划和严谨性。
+ 搜索才是开启超越简单自动化，达到发明创造的关键。当今所有具备某种发明或创造力的AI系统，都依赖于离散搜索。深度学习本身不具备发明创造能力，但搜索具备这种能力。
+ 什么是离散程序搜索呢？它本质上是对来自某种语言或领域特定语言（DSL）的运算符所组成的图，进行组合搜索。
+ 要真正发挥它们的潜力，你必须将二者结合起来。而这正是人类智能特别擅长的地方，也是让我们变得特别的关键所在。感知与直觉和明确的逐步推理结合在一起，在我们所有的思想、行动以及各个方面，都融合了这两种抽象方式。
+ 关键思想是利用这些快速但近似的判断来抵抗组合爆炸，从而使程序搜索变得可行。
+ AI将随着时间推移持续自我完善，一方面扩展抽象库，另一方面不断精细化它对程序空间结构的直觉。

# 20250704 François Chollet: How We Get to AGI
+ [https://www.youtube.com/watch?v=5QcCeSsNRks](https://www.youtube.com/watch?v=5QcCeSsNRks)
+ 世界上最重要的事实之一：计算成本自1940年以来，每十年持续下降两个数量级。
+ the scaling laws：当我们仅靠增加模型规模和训练数据量，保持完全相同的架构和训练流程时，其基准测试结果能够以可预测的方式持续提升。
+ 静态且针对特定任务的“记忆型技能”，与“流动型通用智能”——即迅速理解以前从未见过的新事物的能力之间，有着巨大差异。
+ AI研究界开始转向一种全新的、完全不同的模式——测试时适应（Test Adaptation），创造出能在测试时主动调整自身状态以适应新情况的模型。
+ 所谓“测试时适应”，关键在于模型根据其在推理时所遇到的具体数据，动态地修改自身行为的能力。它涵盖了测试时训练、程序合成和思路合成等技术，模型试图在处理当前任务时自行重新编程。
+ 智能的定义
    - 一种是明斯基（Minsky）风格的观点：认为AI旨在制造能够执行通常由人类完成任务的机器。
    - 而另一种则是MAC观点：认为AI应该使机器能够处理那些事先未做准备的问题。
+ 智能是一种过程，而技能则是这一过程的产物。智能就是处理新情况的能力。它是一种开辟新道路、创造新路径的能力。智能就是你有效利用过去信息来应对未来的效率。
    - 静态技能和流动智力之间的差异
    - 某项技能的适用范围。
    - 某个技能的信息效率。
+ 定义之所以非常重要，是因为作为工程师，我们只能创造出我们能衡量的东西。
+ “the shortcut rule（捷径法则）”：当你专注于实现单一成功指标时，你可能会成功，但会以牺牲所有未被该指标捕捉到的其他方面为代价。
    - 所以你虽然击中了目标，但却错过了真正的意义
    - 对AGI的定义仅仅实现自动化，这种定义虽然增加了经济生产力，显然非常有价值，但可能也会增加失业率。
+ 但另一种定义则能够激发创新并加速科学的发展进程。只有衡量我们真正关心的东西，我们才能取得进步。
+ ARC实际上是一个工具，目的是引导研究界关注我们认为在通向AGI过程中最重要且尚未解决的瓶颈问题。
+ 我们可以明确地得出结论：流动智力不会因预训练规模的扩大而自然产生。
+ 在2019年，ARC1旨在挑战当时的深度学习模式，即模型只是一种用于静态推理的大型参数曲线。而如今，ARC2挑战的是推理系统。

# 20250703 Ilya Sutskever's SHOCKING Superintelligence Warning "extremely unpredictable and unimaginable"
+ [https://www.youtube.com/watch?v=G-kPqsJycsc](https://www.youtube.com/watch?v=G-kPqsJycsc)
+ **Dr. Ilia Suskiver** 一直在幕后默默地进行着超级智能的研究。他是一个非常有趣的人物，因为虽然他很少公开露面，但似乎他所做的几乎每件事都会变成一种网络迷因。
+ 而现在他再次回到聚光灯下，声称人工智能将极度不可预测且难以想象。
+ 正如**Sam Alman**在《gentle singularity》中所说的，我们正在进入递归自我改进的“幼虫阶段”。
+ 如果你拥有一家公司，做的东西你明知道是虚假的，或者明知道不会有什么发展前景，或许能赚点钱但不具革命性，这时有人过来对你说：“我给你320亿美元，让你加入我的公司，继续做同样的事。”
+ 并不是要你停止这项工作，而是直接把320亿美元（或其中属于**Ilia**股份的那部分）放进口袋，同时还能获得像**Meta**这样一个科技巨头的资本和资源支持。
+ Ilia 发现了开放大学，从八年级开始，我就在那儿上课了。我拿到那些书并读了它们，我的理解程度达到了那种清晰的分界点，以至于我清楚记得那是一个前后的分水岭。我开始相信，只要我慢慢地阅读某样东西，最终总能理解它。
+ 电脑能学习吗？我隐约觉得，如果能解决学习的问题，其他一切都会迎刃而解。
+ 大型神经网络可以完成任何任务的观点，在我们谷歌期间做的一些研究中进一步得到了印证。
+ AI的一个挑战在于，它将同时变得极其不可预测和超出人类的想象，甚至难以想象。

# 20250702 The Internet DIES as Gen AI Takes Over | The Dead Internet Theory is now true...
+ [https://www.youtube.com/watch?v=rrNCx4qXvJs](https://www.youtube.com/watch?v=rrNCx4qXvJs)
+ dead internet theory，这是一个阴谋论，声称互联网，尤其在 2016 或 2017 之后，不再主要由人类活动驱动。相反，它由机器人程序和算法驱动，这些算法旨在操纵线上话语、减少真实的人类互动。
+ 在五月份，订阅量排名前十的 YouTube 频道中，有四个在每条视频里都使用了 AI 生成内容。
+ 由于是虚拟机操作，仍然有一些蛛丝马迹可被公司用来判断它并非真实流量，也不是人类用户。但这种界限正在变得越来越模糊，未来要区分并过滤自动化流量会越来越困难。
+ 我们往往倾向于点击那些令人愤怒或激起情绪的内容。我们有时也会看些傻乎乎的内容，事后还不好意思承认。
+ 下一个重大进展将是这些AI代理能够像我刚刚展示的那个操作工具一样自主浏览网页

# 20250701 How to Make AI More Accurate: Top Techniques for Reliable Results
+ [https://www.youtube.com/watch?v=pNbU1vGkIK4](https://www.youtube.com/watch?v=pNbU1vGkIK4)
+ 我们拥有一个可信的数据源，可能是一个向量数据库，我们可以使用一个检索器（retriever，这正是RAG中“R”的含义），来查询这个向量数据库，并检索与特定用户查询相关的文档。
+ 一个了解多个不同领域的大模型在面对宽泛的问题时更不容易产生“幻觉”，而一个带有更专业信息的小模型则相反。你要为特定目的选择正确的模型。
+ COT，即“思维链提示”。它涉及要求大型语言模型明确地生成中间推理步骤，然后再给出最终答案。这能帮助减少在需要逻辑一致性的情境下出现的错误，比如数学问题。
    - 零示例思维链处理，它只是简单地向提示中添加一个触发短语
    - 少样本（few-shot）的思维链提示，在提示中包含问题示例或数学题示例，以及逐步解答的过程。
+ RAR 修改（revise）和反思（reflect），不是依靠单个模型，而是拥有了所有三个模型的集体智慧。
+ MoE，也就是“专家混合”。gating network (门控网络）。作用类似于路由器，用来决定应由哪个专家模型来处理输入内容。
    - 我们不是使用三个大脑，而是只使用一个大脑，但将问题路由到不同的大脑区域。
+ 改变模型的“温度”设置
+ 系统提示词（System prompt），这样做成功程度可能会有所不同，但仍值得尝试。
+ RLHF人类反馈的强化学习，通过这种方式，我们再次对模型进行微调，使其表现得更好一些。

